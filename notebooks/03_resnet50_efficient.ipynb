{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87334838",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7c8d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: gorina6\n",
      "CUDA: True\n",
      "Fri Oct  3 14:24:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n"
     ]
    }
   ],
   "source": [
    "import platform, torch, subprocess\n",
    "print(\"Host:\", platform.node())               # gorina6\n",
    "print(\"CUDA:\", torch.cuda.is_available())     # True\n",
    "print(subprocess.getoutput(\"nvidia-smi | head -n 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: gorina6\n",
      "Torch: 2.7.1+cu118\n",
      "CUDA (build): 11.8\n",
      "CUDA available: True\n",
      "cuDNN: 90100\n",
      "GPU count: 8\n",
      "0 Tesla V100-PCIE-32GB\n",
      "1 Tesla V100-PCIE-32GB\n",
      "2 Tesla V100-PCIE-32GB\n",
      "3 Tesla V100-PCIE-32GB\n",
      "4 Tesla V100-PCIE-32GB\n",
      "5 Tesla V100-PCIE-32GB\n",
      "6 Tesla V100-PCIE-32GB\n",
      "7 Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "print(\"Host:\", platform.node())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA (build):\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN:\", torch.backends.cudnn.version())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627da106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU mem free/total: 15.83 / 34.07 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "free, total = torch.cuda.mem_get_info()\n",
    "print(f\"GPU mem free/total: {free/1e9:.2f} / {total/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c696d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe05eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES = None\n",
      "Visible count = 8\n",
      "Using: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "print(\"Visible count =\", torch.cuda.device_count())\n",
    "print(\"Using:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11289a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()  # should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580e99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 786 / 47248\n",
      "                       filename          video_id  frame_number  \\\n",
      "6865  eb0203196e284797_1157.jpg  eb0203196e284797          1157   \n",
      "6866  eb0203196e284797_1158.jpg  eb0203196e284797          1158   \n",
      "6867  eb0203196e284797_1160.jpg  eb0203196e284797          1160   \n",
      "6868  eb0203196e284797_1167.jpg  eb0203196e284797          1167   \n",
      "6869  eb0203196e284797_1168.jpg  eb0203196e284797          1168   \n",
      "\n",
      "     finding_category     finding_class     x1     y1     x2     y2     x3  \\\n",
      "6865          Anatomy  Ampulla of Vater  238.0  196.0  327.0  196.0  327.0   \n",
      "6866          Anatomy  Ampulla of Vater  138.0    0.0  251.0    0.0  251.0   \n",
      "6867          Anatomy  Ampulla of Vater   69.0    0.0  153.0    0.0  153.0   \n",
      "6868          Anatomy  Ampulla of Vater    4.0  115.0   56.0  115.0   56.0   \n",
      "6869          Anatomy  Ampulla of Vater   57.0  182.0  137.0  182.0  137.0   \n",
      "\n",
      "         y3     x4     y4                                  image_path  \n",
      "6865  289.0  238.0  289.0  Ampulla of Vater/eb0203196e284797_1157.jpg  \n",
      "6866   66.0  138.0   66.0  Ampulla of Vater/eb0203196e284797_1158.jpg  \n",
      "6867   45.0   69.0   45.0  Ampulla of Vater/eb0203196e284797_1160.jpg  \n",
      "6868  190.0    4.0  190.0  Ampulla of Vater/eb0203196e284797_1167.jpg  \n",
      "6869  258.0   57.0  258.0  Ampulla of Vater/eb0203196e284797_1168.jpg  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "metadata_csv = Path(\"/home/stud/fwag/bhome/ele670_project/data/raw/metadata.csv\")\n",
    "dataset_root = Path(\"/home/stud/fwag/bhome/ele670_project/data/raw/labelled_images\")\n",
    "\n",
    "df = pd.read_csv(metadata_csv, sep=\";\")\n",
    "df[\"finding_class\"] = df[\"finding_class\"].astype(str).str.strip()\n",
    "df[\"filename\"] = df[\"filename\"].astype(str).str.strip()\n",
    "# Build relative image_path that matches your folder layout\n",
    "# labelled_images/<finding_class>/<filename>\n",
    "df[\"image_path\"] = df.apply(\n",
    "    lambda r: str(Path(r[\"finding_class\"]) / r[\"filename\"]), axis=1\n",
    ")\n",
    "\n",
    "bad = df[~df[\"image_path\"].apply(lambda p: (dataset_root / p).exists())]\n",
    "print(f\"Missing: {len(bad)} / {len(df)}\")\n",
    "print(bad.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a1398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Class names with no folder match (case-insensitive): 0\n",
      "[]\n",
      "[CHECK] Missing after folder mapping: 0 / 47248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>finding_category</th>\n",
       "      <th>finding_class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, video_id, frame_number, finding_category, finding_class, x1, y1, x2, y2, x3, y3, x4, y4, image_path]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Processed DataFrame with image_path → /home/stud/fwag/bhome/ele670_project/data/processed/metadata_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: SCAN + NORMALIZE + SAVE PROCESSED DF\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- config / paths ---\n",
    "dataset_root = Path(\"/home/stud/fwag/bhome/ele670_project/data/raw/labelled_images\")\n",
    "processed_df_pkl = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_cleaned.pkl\")\n",
    "metadata_csv = Path(\"/home/stud/fwag/bhome/ele670_project/data/raw/metadata.csv\")\n",
    "\n",
    "df = pd.read_csv(metadata_csv, sep=\";\")\n",
    "n_videos = df[\"video_id\"].nunique()\n",
    "print(f\"Total distinct videos: {n_videos}\")\n",
    "\n",
    "# --- preconditions ---\n",
    "if \"df\" not in globals():\n",
    "    raise NameError(\"df is not defined. Load your original CSV/DataFrame into `df` before running this cell.\")\n",
    "required_cols = {\"finding_class\", \"filename\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"`df` is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "# --- build case-insensitive map of class folders on disk (SLOW) ---\n",
    "classes_on_disk = {p.name.lower().strip(): p.name for p in dataset_root.iterdir() if p.is_dir()}\n",
    "\n",
    "# --- check CSV classes vs folders ---\n",
    "csv_classes = sorted(df[\"finding_class\"].astype(str).str.strip().unique())\n",
    "no_match = [c for c in csv_classes if c.lower().strip() not in classes_on_disk]\n",
    "print(f\"[INFO] Class names with no folder match (case-insensitive): {len(no_match)}\")\n",
    "print(no_match[:20])\n",
    "\n",
    "# --- optional manual fixes for known variants ---\n",
    "manual_map = {\n",
    "    # \"CSV value\": \"Exact folder name on disk\"\n",
    "    # e.g., \"Reduced Mucosal View\": \"Reduced mucosal view\",\n",
    "}\n",
    "\n",
    "def resolve_class_folder(name: str) -> str:\n",
    "    name = str(name).strip()\n",
    "    if name in manual_map:\n",
    "        return manual_map[name]\n",
    "    return classes_on_disk.get(name.lower().strip(), name)  # fallback to original (will be flagged if missing)\n",
    "\n",
    "# --- rebuild image_path using resolved folder name ---\n",
    "df[\"image_path\"] = df.apply(\n",
    "    lambda r: str(Path(resolve_class_folder(r[\"finding_class\"])) / r[\"filename\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- validate paths on disk ---\n",
    "bad = df[~df[\"image_path\"].apply(lambda p: (dataset_root / p).exists())]\n",
    "print(f\"[CHECK] Missing after folder mapping: {len(bad)} / {len(df)}\")\n",
    "display(bad.head(10))\n",
    "\n",
    "# --- persist the processed df so Cell 2 can run without rescanning ---\n",
    "processed_df_pkl.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_pickle(processed_df_pkl)\n",
    "print(f\"[SAVED] Processed DataFrame with image_path → {processed_df_pkl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8954c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Normalized metadata CSV → /home/stud/fwag/bhome/ele670_project/data/processed/metadata_cleaned.csv\n",
      "[SAVED] Label classes (.npy)     → /home/stud/fwag/bhome/ele670_project/data/processed/label_classes_cleaned.npy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>finding_class</th>\n",
       "      <th>video_id</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal clean mucosa/0728084c8da942d9_22803.jpg</td>\n",
       "      <td>Normal clean mucosa</td>\n",
       "      <td>0728084c8da942d9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal clean mucosa/0728084c8da942d9_22804.jpg</td>\n",
       "      <td>Normal clean mucosa</td>\n",
       "      <td>0728084c8da942d9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal clean mucosa/0728084c8da942d9_22805.jpg</td>\n",
       "      <td>Normal clean mucosa</td>\n",
       "      <td>0728084c8da942d9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal clean mucosa/0728084c8da942d9_22806.jpg</td>\n",
       "      <td>Normal clean mucosa</td>\n",
       "      <td>0728084c8da942d9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal clean mucosa/0728084c8da942d9_22807.jpg</td>\n",
       "      <td>Normal clean mucosa</td>\n",
       "      <td>0728084c8da942d9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_path        finding_class  \\\n",
       "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
       "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
       "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
       "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
       "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
       "\n",
       "           video_id  encoded_label  \n",
       "0  0728084c8da942d9              9  \n",
       "1  0728084c8da942d9              9  \n",
       "2  0728084c8da942d9              9  \n",
       "3  0728084c8da942d9              9  \n",
       "4  0728084c8da942d9              9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 2: EXPORT METADATA + LABELS (NO RESCAN)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "processed_df_pkl = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_cleaned.pkl\")\n",
    "out_csv          = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_cleaned.csv\")\n",
    "out_classes      = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes_cleaned.npy\")\n",
    "\n",
    "# Prefer loading the persisted df (so we don't re-run the slow scan)\n",
    "if processed_df_pkl.exists():\n",
    "    df_proc = pd.read_pickle(processed_df_pkl)\n",
    "elif \"df\" in globals():\n",
    "    # Fallback: use in-memory df if it already has image_path (e.g., you just ran Cell 1)\n",
    "    if \"image_path\" not in df.columns:\n",
    "        raise ValueError(\"In-memory `df` has no 'image_path'. Run Cell 1 or load the processed df.\")\n",
    "    df_proc = df\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Processed df not found at {processed_df_pkl}. Run Cell 1 first to generate it.\"\n",
    "    )\n",
    "\n",
    "# Keep only columns needed for training\n",
    "keep_cols = [\"image_path\", \"finding_class\", \"video_id\"]\n",
    "missing_keep = [c for c in keep_cols if c not in df_proc.columns]\n",
    "if missing_keep:\n",
    "    raise ValueError(f\"Processed df missing required columns {missing_keep}. Ensure Cell 1 ran on the correct input.\")\n",
    "\n",
    "df_out = df_proc[keep_cols].copy()\n",
    "\n",
    "# Encode labels and persist artifacts\n",
    "lb = LabelEncoder()\n",
    "df_out[\"encoded_label\"] = lb.fit_transform(df_out[\"finding_class\"])\n",
    "np.save(\"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes.npy\", lb.classes_)\n",
    "\n",
    "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(out_csv, index=False)\n",
    "np.save(out_classes, lb.classes_)\n",
    "\n",
    "print(f\"[SAVED] Normalized metadata CSV → {out_csv}\")\n",
    "print(f\"[SAVED] Label classes (.npy)     → {out_classes}\")\n",
    "display(df_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d0fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATS] Distinct videos and frame counts per class (before filtering):\n",
      "       finding_class  frames  videos\n",
      "    Ampulla of Vater      10       1\n",
      "     Blood - hematin      12       1\n",
      "               Polyp      55       1\n",
      "       Blood - fresh     446       2\n",
      "            Erythema     159       3\n",
      "    Lymphangiectasia     592       3\n",
      "               Ulcer     854       3\n",
      "        Foreign Body     776       4\n",
      "         Angiectasia     866       6\n",
      "Reduced Mucosal View    2906       7\n",
      "             Erosion     507       9\n",
      "             Pylorus    1538      32\n",
      "     Ileocecal valve    4189      34\n",
      " Normal clean mucosa   34338      37\n",
      "\n",
      "[INFO] How many classes each video has (top 10):\n",
      "video_id\n",
      "04a78ef00c5245e0    6\n",
      "48579eec79784294    6\n",
      "64440803f87b4843    6\n",
      "8ebf0e483cac48d6    6\n",
      "8885668afb844852    5\n",
      "5e59c7fdb16c4228    5\n",
      "eb0203196e284797    5\n",
      "3ada4222967f421d    4\n",
      "131368cc17e44240    4\n",
      "7a47e8eacea04e64    4\n",
      "\n",
      "[INFO] Distribution of 'number of classes per video':\n",
      "Classes_per_video | Num_videos\n",
      " Classes_per_video  Num_videos\n",
      "                 1           2\n",
      "                 2           8\n",
      "                 3          18\n",
      "                 4           8\n",
      "                 5           3\n",
      "                 6           4\n",
      "\n",
      "[INFO] Videos containing only ONE class: 2 found\n",
      "[INFO] Example single-class videos (up to 10 shown):\n",
      "['2fc3db471f9d44c0', '4aebc5cb2d4847aa']\n",
      "[SAVED] Full list of single-class videos → /home/stud/fwag/bhome/ele670_project/data/processed/single_class_videos.csv\n",
      "\n",
      "[INFO] Classes found in video 04a78ef00c5245e0:\n",
      "['Angiectasia' 'Blood - fresh' 'Ileocecal valve' 'Lymphangiectasia'\n",
      " 'Normal clean mucosa' 'Pylorus']\n",
      "\n",
      "[CONFIG] min_videos_per_class = 2, min_frames_per_class = 20\n",
      "[FILTER] Too few videos (<2): 3 classes\n",
      "['Ampulla of Vater', 'Blood - hematin', 'Polyp']\n",
      "[FILTER] Too few frames (<20): 2 classes\n",
      "['Ampulla of Vater', 'Blood - hematin']\n",
      "[FILTER] Total unique classes removed: 3\n",
      "\n",
      "[SUMMARY] Frames before: 47,248 | after: 47,171\n",
      "[SUMMARY] Classes before: 14 | after: 11\n",
      "\n",
      "[SAVED] Filtered metadata CSV  → /home/stud/fwag/bhome/ele670_project/data/processed/metadata_filtered.csv\n",
      "[SAVED] Filtered label classes → /home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\n",
      "[SAVED] Per-video class counts → /home/stud/fwag/bhome/ele670_project/data/processed/per_video_class_counts.csv\n",
      "[SAVED] Per-video class-count distribution → /home/stud/fwag/bhome/ele670_project/data/processed/per_video_class_count_distribution.csv\n",
      "\n",
      "[HEAD]\n",
      "                                    image_path       finding_class         video_id  encoded_label\n",
      "Normal clean mucosa/0728084c8da942d9_22803.jpg Normal clean mucosa 0728084c8da942d9              7\n",
      "Normal clean mucosa/0728084c8da942d9_22804.jpg Normal clean mucosa 0728084c8da942d9              7\n",
      "Normal clean mucosa/0728084c8da942d9_22805.jpg Normal clean mucosa 0728084c8da942d9              7\n",
      "Normal clean mucosa/0728084c8da942d9_22806.jpg Normal clean mucosa 0728084c8da942d9              7\n",
      "Normal clean mucosa/0728084c8da942d9_22807.jpg Normal clean mucosa 0728084c8da942d9              7\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: FILTER SMALL / SINGLE-VIDEO CLASSES + PRINT STATS + EXPORT + PER-VIDEO INSIGHTS\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- config / thresholds ---\n",
    "min_videos_per_class = 2     # threshold 1: a class must appear in at least this many DISTINCT videos\n",
    "min_frames_per_class = 20    # threshold 2: a class must have at least this many frames overall\n",
    "\n",
    "# --- standardized file paths ---\n",
    "processed_df_pkl = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_cleaned.pkl\")  # cleaned df from Cell 1\n",
    "out_csv_filtered  = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_filtered.csv\")  # final filtered metadata\n",
    "out_classes       = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\")  # label names after filtering\n",
    "out_stats_csv     = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/class_stats_before_filter.csv\")  # class-level stats BEFORE filtering\n",
    "out_per_video_csv = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/per_video_class_counts.csv\")  # n_classes per video (pre-filter)\n",
    "out_per_video_dist_csv = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/per_video_class_count_distribution.csv\")  # distribution over n_classes per video (pre-filter)\n",
    "out_single_class_videos = Path(\"/home/stud/fwag/bhome/ele670_project/data/processed/single_class_videos.csv\")  # list of videos that contain exactly one class (pre-filter)\n",
    "\n",
    "# --- load cleaned DataFrame (output of Cell 1) ---\n",
    "if processed_df_pkl.exists():\n",
    "    # preferred path: load the persisted, cleaned dataframe so we don't rescan the filesystem\n",
    "    df_proc = pd.read_pickle(processed_df_pkl)\n",
    "elif \"df\" in globals():\n",
    "    # fallback: use in-memory df only if it already has 'image_path' (implies Cell 1 ran in this session)\n",
    "    if \"image_path\" not in df.columns:\n",
    "        raise ValueError(\"In-memory `df` has no 'image_path'. Run Cell 1 or load the cleaned df.\")\n",
    "    df_proc = df\n",
    "else:\n",
    "    # neither persisted nor in-memory cleaned df exists → instruct user to run Cell 1\n",
    "    raise FileNotFoundError(f\"Cleaned df not found at {processed_df_pkl}. Run Cell 1 first.\")\n",
    "\n",
    "# --- sanity check ---\n",
    "for c in [\"finding_class\", \"video_id\", \"image_path\"]:\n",
    "    # ensure the key columns exist; otherwise the following stats/filters would fail\n",
    "    if c not in df_proc.columns:\n",
    "        raise ValueError(f\"Column '{c}' missing in df_proc — ensure Cell 1 ran correctly.\")\n",
    "\n",
    "# ===================================================\n",
    "# 1) PER-CLASS STATS\n",
    "# ===================================================\n",
    "# Build per-class aggregates:\n",
    "# - frames: total number of rows/images belonging to the class\n",
    "# - videos: number of DISTINCT video_id values where the class appears\n",
    "stats = (\n",
    "    df_proc.groupby(\"finding_class\")\n",
    "           .agg(frames=(\"image_path\", \"size\"),\n",
    "                videos=(\"video_id\", lambda s: s.nunique(dropna=True)))  # nunique over video_id counts distinct videos with that class\n",
    "           .reset_index()\n",
    "           .sort_values([\"videos\", \"frames\", \"finding_class\"])\n",
    ")\n",
    "\n",
    "# Persist these pre-filter stats for auditing/repro\n",
    "out_stats_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "stats.to_csv(out_stats_csv, index=False)\n",
    "\n",
    "print(\"[STATS] Distinct videos and frame counts per class (before filtering):\")\n",
    "print(stats.to_string(index=False, max_rows=40))  # print a readable table (truncate beyond 40 rows)\n",
    "\n",
    "# ===================================================\n",
    "# 2) PER-VIDEO CLASS DIVERSITY\n",
    "# ===================================================\n",
    "# For each video_id, count how many DISTINCT classes appear in that video\n",
    "per_video_classes = (\n",
    "    df_proc.groupby(\"video_id\")[\"finding_class\"]\n",
    "           .nunique(dropna=True)\n",
    "           .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Save per-video class counts and the distribution (how many videos have 1,2,3,... classes)\n",
    "per_video_classes.to_csv(out_per_video_csv, header=[\"n_classes\"])\n",
    "\n",
    "per_video_dist = per_video_classes.value_counts().sort_index()\n",
    "per_video_dist.to_csv(out_per_video_dist_csv, header=[\"n_videos\"])\n",
    "\n",
    "print(\"\\n[INFO] How many classes each video has (top 10):\")\n",
    "print(per_video_classes.head(10).to_string())  # show the 'busiest' videos by class diversity\n",
    "\n",
    "print(\"\\n[INFO] Distribution of 'number of classes per video':\")\n",
    "print(\"Classes_per_video | Num_videos\")\n",
    "print(per_video_dist.rename_axis(\"Classes_per_video\")\n",
    "                     .reset_index(name=\"Num_videos\")\n",
    "                     .to_string(index=False))\n",
    "\n",
    "# ===================================================\n",
    "# 3) NEW: IDENTIFY SINGLE-CLASS VIDEOS\n",
    "# ===================================================\n",
    "# Find videos where only ONE class appears (diagnostic only; not filtering them out here)\n",
    "single_class_videos = per_video_classes[per_video_classes == 1].index.tolist()\n",
    "print(f\"\\n[INFO] Videos containing only ONE class: {len(single_class_videos)} found\")\n",
    "if single_class_videos:\n",
    "    print(\"[INFO] Example single-class videos (up to 10 shown):\")\n",
    "    print(single_class_videos[:10])\n",
    "\n",
    "    # For those videos, also record WHICH class they contain (array per video)\n",
    "    single_class_info = (\n",
    "        df_proc[df_proc[\"video_id\"].isin(single_class_videos)]\n",
    "        .groupby(\"video_id\")[\"finding_class\"]\n",
    "        .unique()\n",
    "        .reset_index()\n",
    "    )\n",
    "    single_class_info.to_csv(out_single_class_videos, index=False)\n",
    "    print(f\"[SAVED] Full list of single-class videos → {out_single_class_videos}\")\n",
    "\n",
    "# Pick one example video (the one with most classes) and list its classes (sanity check)\n",
    "example_video = per_video_classes.index[0]  # video with most distinct classes\n",
    "classes_in_example = (\n",
    "    df_proc.loc[df_proc[\"video_id\"] == example_video, \"finding_class\"]\n",
    "          .dropna().unique()\n",
    ")\n",
    "print(f\"\\n[INFO] Classes found in video {example_video}:\")\n",
    "print(np.sort(classes_in_example))\n",
    "\n",
    "# ===================================================\n",
    "# 4) FILTERING BY CLASS SIZE / VIDEO COUNT\n",
    "# ===================================================\n",
    "# Identify classes that FAIL either threshold:\n",
    "# - 'removed_by_videos': classes that appear in fewer than min_videos_per_class distinct videos\n",
    "# - 'removed_by_frames': classes that have fewer than min_frames_per_class total frames\n",
    "removed_by_videos = stats.loc[stats[\"videos\"] < min_videos_per_class, \"finding_class\"]\n",
    "removed_by_frames = stats.loc[stats[\"frames\"] < min_frames_per_class, \"finding_class\"]\n",
    "\n",
    "# Union of both failure sets → final set of classes to remove\n",
    "to_remove = set(removed_by_videos) | set(removed_by_frames)\n",
    "\n",
    "# Log what will be removed and why\n",
    "print(f\"\\n[CONFIG] min_videos_per_class = {min_videos_per_class}, min_frames_per_class = {min_frames_per_class}\")\n",
    "print(f\"[FILTER] Too few videos (<{min_videos_per_class}): {len(removed_by_videos)} classes\")\n",
    "if len(removed_by_videos): print(sorted(removed_by_videos.tolist())[:40])\n",
    "print(f\"[FILTER] Too few frames (<{min_frames_per_class}): {len(removed_by_frames)} classes\")\n",
    "if len(removed_by_frames): print(sorted(removed_by_frames.tolist())[:40])\n",
    "print(f\"[FILTER] Total unique classes removed: {len(to_remove)}\")\n",
    "\n",
    "# Apply class-level filter: DROP ALL ROWS whose 'finding_class' is in 'to_remove'\n",
    "# (i.e., remove every frame belonging to low-support classes)\n",
    "df_filt = df_proc[~df_proc[\"finding_class\"].isin(to_remove)].copy()\n",
    "\n",
    "# Summaries pre vs post\n",
    "print(f\"\\n[SUMMARY] Frames before: {len(df_proc):,} | after: {len(df_filt):,}\")\n",
    "print(f\"[SUMMARY] Classes before: {stats.shape[0]} | after: {df_filt['finding_class'].nunique()}\")\n",
    "\n",
    "# ===================================================\n",
    "# 5) ENCODE + SAVE FILTERED DATA\n",
    "# ===================================================\n",
    "# Keep just the columns needed downstream and add an integer label encoding for 'finding_class'\n",
    "df_out = df_filt[[\"image_path\", \"finding_class\", \"video_id\"]].copy()\n",
    "lb = LabelEncoder()\n",
    "df_out[\"encoded_label\"] = lb.fit_transform(df_out[\"finding_class\"])\n",
    "\n",
    "# Save filtered metadata (CSV) and the label names (NPY)\n",
    "out_csv_filtered.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(out_csv_filtered, index=False)\n",
    "np.save(out_classes, lb.classes_)\n",
    "\n",
    "print(f\"\\n[SAVED] Filtered metadata CSV  → {out_csv_filtered}\")\n",
    "print(f\"[SAVED] Filtered label classes → {out_classes}\")\n",
    "print(\"[SAVED] Per-video class counts →\", out_per_video_csv)\n",
    "print(\"[SAVED] Per-video class-count distribution →\", out_per_video_dist_csv)\n",
    "print(\"\\n[HEAD]\")\n",
    "print(df_out.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22296fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 47248 rows from /bhome/fwag/ele670_project/data/processed/metadata_normalized.csv\n",
      "[INFO] Columns: ['image_path', 'finding_class', 'video_id', 'encoded_label']\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              9  \n",
      "1  0728084c8da942d9              9  \n",
      "2  0728084c8da942d9              9  \n",
      "3  0728084c8da942d9              9  \n",
      "4  0728084c8da942d9              9  \n",
      "\n",
      "[INFO] Number of DISTINCT videos per class:\n",
      "finding_class\n",
      "Normal clean mucosa     37\n",
      "Ileocecal valve         34\n",
      "Pylorus                 32\n",
      "Erosion                  9\n",
      "Reduced Mucosal View     7\n",
      "Angiectasia              6\n",
      "Foreign Body             4\n",
      "Lymphangiectasia         3\n",
      "Ulcer                    3\n",
      "Erythema                 3\n",
      "Blood - fresh            2\n",
      "Ampulla of Vater         1\n",
      "Blood - hematin          1\n",
      "Polyp                    1\n",
      "Name: video_id, dtype: int64\n",
      "\n",
      "[INFO] Per-class stats (frames, distinct videos, single-video flag):\n",
      "                      n_frames  n_videos  only_one_video\n",
      "finding_class                                           \n",
      "Normal clean mucosa      34338        37           False\n",
      "Ileocecal valve           4189        34           False\n",
      "Pylorus                   1538        32           False\n",
      "Erosion                    507         9           False\n",
      "Reduced Mucosal View      2906         7           False\n",
      "Angiectasia                866         6           False\n",
      "Foreign Body               776         4           False\n",
      "Ulcer                      854         3           False\n",
      "Lymphangiectasia           592         3           False\n",
      "Erythema                   159         3           False\n",
      "Blood - fresh              446         2           False\n",
      "Polyp                       55         1            True\n",
      "Blood - hematin             12         1            True\n",
      "Ampulla of Vater            10         1            True\n",
      "\n",
      "[INFO] Classes with frames coming from ONLY ONE video:\n",
      "                  n_frames  n_videos  only_one_video\n",
      "finding_class                                       \n",
      "Polyp                   55         1            True\n",
      "Blood - hematin         12         1            True\n",
      "Ampulla of Vater        10         1            True\n",
      "\n",
      "[INFO] Distinct video_ids for ALL classes:\n",
      "- Normal clean mucosa: 37 video(s) → ['04a78ef00c5245e0', '0531325b64674948', '0728084c8da942d9', '07c1fa15a20a4398', '131368cc17e44240', '39960e5e099a45ca', '3ada4222967f421d', '3c8d5f0b90d7475d', '4560e83f9afc4685', '48579eec79784294', '495f16498db34d3c', '5bb1d3cc7dc64cec', '5e59c7fdb16c4228', '5e9beaf4e66142c8', '64440803f87b4843', '6cb700585c4f4070', '7ad22d50ebaf4596', '8885668afb844852', '89cdd41258c542c5', '8a00709108cd4e2b', '8ebf0e483cac48d6', 'b2134f4a6f864613', 'bc84479c66fe4da6', 'bca26705313a4644', 'c11b28a8b2344716', 'c7084b3556e34619', 'd369e4f163df4aba', 'd7a271f233ba4a40', 'dac1e27f7e4d4ef5', 'dc221ccc65d34010', 'dca1377dec974312', 'df6b47bafe5143f5', 'eb0203196e284797', 'ed02f27ef36f483e', 'fb86bc87d3874cd7', 'fc32def0e7194981', 'fe5d372e43f94f68']\n",
      "- Ileocecal valve: 34 video(s) → ['04a78ef00c5245e0', '0728084c8da942d9', '07c1fa15a20a4398', '131368cc17e44240', '39960e5e099a45ca', '3ada4222967f421d', '3c8d5f0b90d7475d', '4560e83f9afc4685', '48579eec79784294', '495f16498db34d3c', '4aebc5cb2d4847aa', '5bb1d3cc7dc64cec', '5e59c7fdb16c4228', '5e9beaf4e66142c8', '64440803f87b4843', '6cb700585c4f4070', '7a47e8eacea04e64', '7ad22d50ebaf4596', '8885668afb844852', '8a00709108cd4e2b', '8ebf0e483cac48d6', 'ad91cf7ca91440aa', 'af9bd7d0e43741e3', 'bc84479c66fe4da6', 'bca26705313a4644', 'c7084b3556e34619', 'd7a271f233ba4a40', 'dac1e27f7e4d4ef5', 'dc221ccc65d34010', 'dca1377dec974312', 'df6b47bafe5143f5', 'ed02f27ef36f483e', 'fc32def0e7194981', 'fe5d372e43f94f68']\n",
      "- Pylorus: 32 video(s) → ['04a78ef00c5245e0', '0531325b64674948', '0728084c8da942d9', '131368cc17e44240', '39960e5e099a45ca', '3ada4222967f421d', '4560e83f9afc4685', '48579eec79784294', '5e59c7fdb16c4228', '64440803f87b4843', '7a47e8eacea04e64', '7ad22d50ebaf4596', '8885668afb844852', '89cdd41258c542c5', '8ebf0e483cac48d6', 'ad91cf7ca91440aa', 'af9bd7d0e43741e3', 'b2134f4a6f864613', 'bc84479c66fe4da6', 'bca26705313a4644', 'c11b28a8b2344716', 'c7084b3556e34619', 'd369e4f163df4aba', 'd626f4f4a5ac4785', 'd7a271f233ba4a40', 'dac1e27f7e4d4ef5', 'dca1377dec974312', 'df6b47bafe5143f5', 'eb0203196e284797', 'ed02f27ef36f483e', 'fb86bc87d3874cd7', 'fe5d372e43f94f68']\n",
      "- Erosion: 9 video(s) → ['0531325b64674948', '0728084c8da942d9', '5e59c7fdb16c4228', '8ebf0e483cac48d6', 'bca26705313a4644', 'd626f4f4a5ac4785', 'dac1e27f7e4d4ef5', 'eb0203196e284797', 'fb86bc87d3874cd7']\n",
      "- Reduced Mucosal View: 7 video(s) → ['48579eec79784294', '5bb1d3cc7dc64cec', '8885668afb844852', '8ebf0e483cac48d6', 'af9bd7d0e43741e3', 'c11b28a8b2344716', 'dc221ccc65d34010']\n",
      "- Angiectasia: 6 video(s) → ['04a78ef00c5245e0', '64440803f87b4843', 'ad91cf7ca91440aa', 'b2134f4a6f864613', 'd369e4f163df4aba', 'eb0203196e284797']\n",
      "- Foreign Body: 4 video(s) → ['3ada4222967f421d', '48579eec79784294', '7a47e8eacea04e64', '8885668afb844852']\n",
      "- Ulcer: 3 video(s) → ['2fc3db471f9d44c0', '7a47e8eacea04e64', 'd626f4f4a5ac4785']\n",
      "- Lymphangiectasia: 3 video(s) → ['04a78ef00c5245e0', '64440803f87b4843', '7ad22d50ebaf4596']\n",
      "- Erythema: 3 video(s) → ['48579eec79784294', '5e59c7fdb16c4228', '64440803f87b4843']\n",
      "- Blood - fresh: 2 video(s) → ['04a78ef00c5245e0', 'd369e4f163df4aba']\n",
      "- Polyp: 1 video(s) → ['131368cc17e44240']\n",
      "- Blood - hematin: 1 video(s) → ['8ebf0e483cac48d6']\n",
      "- Ampulla of Vater: 1 video(s) → ['eb0203196e284797']\n",
      "\n",
      "[INFO] Breakdown for single-video classes:\n",
      "\n",
      "Class: Polyp\n",
      "        video_id finding_class  n_frames\n",
      "131368cc17e44240         Polyp        55\n",
      "\n",
      "Class: Blood - hematin\n",
      "        video_id   finding_class  n_frames\n",
      "8ebf0e483cac48d6 Blood - hematin        12\n",
      "\n",
      "Class: Ampulla of Vater\n",
      "        video_id    finding_class  n_frames\n",
      "eb0203196e284797 Ampulla of Vater        10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Load the dataset ---\n",
    "csv_path = \"/bhome/fwag/ele670_project/data/processed/metadata_normalized.csv\"  # <-- change this to your file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"[INFO] Loaded {len(df)} rows from {csv_path}\")\n",
    "print(\"[INFO] Columns:\", list(df.columns))\n",
    "print(df.head())\n",
    "\n",
    "# --- Safety check ---\n",
    "required_cols = {\"video_id\", \"finding_class\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "assert not missing, f\"DataFrame is missing required columns: {missing}\"\n",
    "\n",
    "# --- Per-class ↔ videos stats ---\n",
    "class_to_n_videos = (\n",
    "    df.groupby(\"finding_class\")[\"video_id\"]\n",
    "      .nunique()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] Number of DISTINCT videos per class:\")\n",
    "print(class_to_n_videos)\n",
    "\n",
    "# Full stats table per class\n",
    "class_stats = (\n",
    "    df.groupby(\"finding_class\")\n",
    "      .agg(\n",
    "          n_frames=(\"finding_class\", \"size\"),\n",
    "          n_videos=(\"video_id\", \"nunique\"),\n",
    "      )\n",
    "      .sort_values([\"n_videos\", \"n_frames\"], ascending=[False, False])\n",
    ")\n",
    "class_stats[\"only_one_video\"] = class_stats[\"n_videos\"] == 1\n",
    "\n",
    "print(\"\\n[INFO] Per-class stats (frames, distinct videos, single-video flag):\")\n",
    "print(class_stats)\n",
    "\n",
    "# Which classes are only in a single video?\n",
    "single_video_classes = class_stats[class_stats[\"only_one_video\"]].copy()\n",
    "print(\"\\n[INFO] Classes with frames coming from ONLY ONE video:\")\n",
    "if single_video_classes.empty:\n",
    "    print(\"None 🎉\")\n",
    "else:\n",
    "    print(single_video_classes)\n",
    "\n",
    "# Map each class -> list of distinct video_ids\n",
    "videos_list_per_class = (\n",
    "    df.groupby(\"finding_class\")[\"video_id\"]\n",
    "      .apply(lambda s: sorted(s.unique()))\n",
    "      .to_dict()\n",
    ")\n",
    "\n",
    "# 🔹 NEW: print ALL classes, not just top-10\n",
    "print(\"\\n[INFO] Distinct video_ids for ALL classes:\")\n",
    "for cls in class_stats.index:  # <-- removed .head(10)\n",
    "    vids = videos_list_per_class.get(cls, [])\n",
    "    print(f\"- {cls}: {len(vids)} video(s) → {vids}\")\n",
    "\n",
    "# --- Optional: per (video_id, class) breakdown ---\n",
    "per_video_class_counts = (\n",
    "    df.groupby([\"video_id\", \"finding_class\"])\n",
    "      .size()\n",
    "      .rename(\"n_frames\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "if not single_video_classes.empty:\n",
    "    print(\"\\n[INFO] Breakdown for single-video classes:\")\n",
    "    for cls in single_video_classes.index:\n",
    "        rows = per_video_class_counts[per_video_class_counts[\"finding_class\"] == cls]\n",
    "        print(f\"\\nClass: {cls}\")\n",
    "        print(rows.sort_values(\"n_frames\", ascending=False).head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f36011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA visible devices: 1\n",
      "Using GPU: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import torch\n",
    "print(\"CUDA visible devices:\", torch.cuda.device_count())\n",
    "print(\"Using GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9787aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check done ✅ | Batch size: 8, Loss: 3.3002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ==== CONFIG ====\n",
    "CSV_PATH = \"/bhome/fwag/ele670_project/data/processed/metadata_normalized.csv\"\n",
    "IMG_ROOT = \"/bhome/fwag/ele670_project/data/raw/labelled_images\"\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# ==== DATASET ====\n",
    "class KvasirDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_root, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_root, row[\"image_path\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(row[\"encoded_label\"])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Simple transforms for sanity check\n",
    "transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = KvasirDataset(CSV_PATH, IMG_ROOT, transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "# ==== MODEL ====\n",
    "num_classes = dataset.df[\"encoded_label\"].nunique()\n",
    "model = models.resnet50(weights=None)   # no pretrained, just sanity check\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# ==== SANITY TRAIN LOOP (1 batch only) ====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# forward\n",
    "outputs = model(images)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# backward\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Sanity check done ✅ | Batch size: {images.size(0)}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6402707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory allocated: 0.38 GB\n",
      "First rows of metadata.csv:\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              9  \n",
      "1  0728084c8da942d9              9  \n",
      "2  0728084c8da942d9              9  \n",
      "3  0728084c8da942d9              9  \n",
      "4  0728084c8da942d9              9  \n",
      "Number of classes: 14\n",
      "Train samples: 37430 | Val samples: 9818\n",
      "Train videos: 34 | Val videos: 9\n",
      "One training batch (images, labels):\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Label batch shape: torch.Size([32])\n",
      "\n",
      "==== START TRAINING ====\n",
      "\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3190418/2432252680.py:126: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_3190418/2432252680.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1/1170 | Loss: 2.7401 | Batch acc: 0.00\n",
      "  Step 10/1170 | Loss: 0.9073 | Batch acc: 0.75\n",
      "  Step 20/1170 | Loss: 0.5375 | Batch acc: 0.84\n",
      "  Step 30/1170 | Loss: 1.3675 | Batch acc: 0.69\n",
      "  Step 40/1170 | Loss: 1.3706 | Batch acc: 0.62\n",
      "  Step 50/1170 | Loss: 0.9294 | Batch acc: 0.75\n",
      "  Step 60/1170 | Loss: 0.6208 | Batch acc: 0.78\n",
      "  Step 70/1170 | Loss: 1.0341 | Batch acc: 0.59\n",
      "  Step 80/1170 | Loss: 0.5050 | Batch acc: 0.88\n",
      "  Step 90/1170 | Loss: 0.6382 | Batch acc: 0.84\n",
      "  Step 100/1170 | Loss: 0.4670 | Batch acc: 0.84\n",
      "  Step 110/1170 | Loss: 0.3199 | Batch acc: 0.94\n",
      "  Step 120/1170 | Loss: 0.6109 | Batch acc: 0.78\n",
      "  Step 130/1170 | Loss: 0.3193 | Batch acc: 0.94\n",
      "  Step 140/1170 | Loss: 0.5663 | Batch acc: 0.81\n",
      "  Step 150/1170 | Loss: 0.4441 | Batch acc: 0.84\n",
      "  Step 160/1170 | Loss: 0.6226 | Batch acc: 0.81\n",
      "  Step 170/1170 | Loss: 0.3706 | Batch acc: 0.94\n",
      "  Step 180/1170 | Loss: 0.4049 | Batch acc: 0.97\n",
      "  Step 190/1170 | Loss: 0.4931 | Batch acc: 0.84\n",
      "  Step 200/1170 | Loss: 0.1632 | Batch acc: 0.97\n",
      "  Step 210/1170 | Loss: 0.4126 | Batch acc: 0.78\n",
      "  Step 220/1170 | Loss: 0.6373 | Batch acc: 0.78\n",
      "  Step 230/1170 | Loss: 0.5492 | Batch acc: 0.84\n",
      "  Step 240/1170 | Loss: 0.5981 | Batch acc: 0.81\n",
      "  Step 250/1170 | Loss: 0.6370 | Batch acc: 0.84\n",
      "  Step 260/1170 | Loss: 0.6786 | Batch acc: 0.78\n",
      "  Step 270/1170 | Loss: 0.4745 | Batch acc: 0.88\n",
      "  Step 280/1170 | Loss: 0.4842 | Batch acc: 0.94\n",
      "  Step 290/1170 | Loss: 0.4380 | Batch acc: 0.91\n",
      "  Step 300/1170 | Loss: 0.1687 | Batch acc: 0.97\n",
      "  Step 310/1170 | Loss: 0.3805 | Batch acc: 0.91\n",
      "  Step 320/1170 | Loss: 0.2664 | Batch acc: 0.94\n",
      "  Step 330/1170 | Loss: 0.2141 | Batch acc: 0.94\n",
      "  Step 340/1170 | Loss: 0.2777 | Batch acc: 0.97\n",
      "  Step 350/1170 | Loss: 0.3091 | Batch acc: 0.88\n",
      "  Step 360/1170 | Loss: 0.2249 | Batch acc: 0.94\n",
      "  Step 370/1170 | Loss: 0.4003 | Batch acc: 0.84\n",
      "  Step 380/1170 | Loss: 0.4517 | Batch acc: 0.88\n",
      "  Step 390/1170 | Loss: 0.3130 | Batch acc: 0.91\n",
      "  Step 400/1170 | Loss: 0.8656 | Batch acc: 0.84\n",
      "  Step 410/1170 | Loss: 0.3821 | Batch acc: 0.91\n",
      "  Step 420/1170 | Loss: 0.3958 | Batch acc: 0.81\n",
      "  Step 430/1170 | Loss: 0.2929 | Batch acc: 0.84\n",
      "  Step 440/1170 | Loss: 0.5165 | Batch acc: 0.88\n",
      "  Step 450/1170 | Loss: 0.3159 | Batch acc: 0.88\n",
      "  Step 460/1170 | Loss: 0.3719 | Batch acc: 0.97\n",
      "  Step 470/1170 | Loss: 0.4839 | Batch acc: 0.88\n",
      "  Step 480/1170 | Loss: 0.1268 | Batch acc: 0.97\n",
      "  Step 490/1170 | Loss: 0.0888 | Batch acc: 1.00\n",
      "  Step 500/1170 | Loss: 0.2672 | Batch acc: 0.91\n",
      "  Step 510/1170 | Loss: 0.2020 | Batch acc: 0.94\n",
      "  Step 520/1170 | Loss: 0.2766 | Batch acc: 0.91\n",
      "  Step 530/1170 | Loss: 0.0954 | Batch acc: 0.97\n",
      "  Step 540/1170 | Loss: 0.3133 | Batch acc: 0.84\n",
      "  Step 550/1170 | Loss: 0.1501 | Batch acc: 0.94\n",
      "  Step 560/1170 | Loss: 0.4750 | Batch acc: 0.81\n",
      "  Step 570/1170 | Loss: 0.4003 | Batch acc: 0.91\n",
      "  Step 580/1170 | Loss: 0.0754 | Batch acc: 1.00\n",
      "  Step 590/1170 | Loss: 0.2187 | Batch acc: 0.91\n",
      "  Step 600/1170 | Loss: 0.3067 | Batch acc: 0.91\n",
      "  Step 610/1170 | Loss: 0.3444 | Batch acc: 0.88\n",
      "  Step 620/1170 | Loss: 0.2338 | Batch acc: 0.97\n",
      "  Step 630/1170 | Loss: 0.2647 | Batch acc: 0.94\n",
      "  Step 640/1170 | Loss: 0.0409 | Batch acc: 1.00\n",
      "  Step 650/1170 | Loss: 0.1695 | Batch acc: 0.97\n",
      "  Step 660/1170 | Loss: 0.1780 | Batch acc: 0.94\n",
      "  Step 670/1170 | Loss: 0.0670 | Batch acc: 1.00\n",
      "  Step 680/1170 | Loss: 0.1702 | Batch acc: 0.94\n",
      "  Step 690/1170 | Loss: 0.2318 | Batch acc: 0.91\n",
      "  Step 700/1170 | Loss: 0.3792 | Batch acc: 0.88\n",
      "  Step 710/1170 | Loss: 0.1884 | Batch acc: 0.91\n",
      "  Step 720/1170 | Loss: 0.4390 | Batch acc: 0.88\n",
      "  Step 730/1170 | Loss: 0.2949 | Batch acc: 0.91\n",
      "  Step 740/1170 | Loss: 0.3494 | Batch acc: 0.88\n",
      "  Step 750/1170 | Loss: 0.1610 | Batch acc: 0.94\n",
      "  Step 760/1170 | Loss: 0.1003 | Batch acc: 0.97\n",
      "  Step 770/1170 | Loss: 0.0838 | Batch acc: 0.97\n",
      "  Step 780/1170 | Loss: 0.1739 | Batch acc: 0.94\n",
      "  Step 790/1170 | Loss: 0.4317 | Batch acc: 0.84\n",
      "  Step 800/1170 | Loss: 0.4819 | Batch acc: 0.84\n",
      "  Step 810/1170 | Loss: 0.1751 | Batch acc: 0.94\n",
      "  Step 820/1170 | Loss: 0.1797 | Batch acc: 0.94\n",
      "  Step 830/1170 | Loss: 0.2215 | Batch acc: 0.91\n",
      "  Step 840/1170 | Loss: 0.3197 | Batch acc: 0.91\n",
      "  Step 850/1170 | Loss: 0.1629 | Batch acc: 0.97\n",
      "  Step 860/1170 | Loss: 0.0991 | Batch acc: 1.00\n",
      "  Step 870/1170 | Loss: 0.3195 | Batch acc: 0.91\n",
      "  Step 880/1170 | Loss: 0.2964 | Batch acc: 0.88\n",
      "  Step 890/1170 | Loss: 0.2123 | Batch acc: 0.91\n",
      "  Step 900/1170 | Loss: 0.1945 | Batch acc: 0.91\n",
      "  Step 910/1170 | Loss: 0.0595 | Batch acc: 1.00\n",
      "  Step 920/1170 | Loss: 0.0716 | Batch acc: 1.00\n",
      "  Step 930/1170 | Loss: 0.1825 | Batch acc: 0.91\n",
      "  Step 940/1170 | Loss: 0.0758 | Batch acc: 0.97\n",
      "  Step 950/1170 | Loss: 0.0916 | Batch acc: 0.97\n",
      "  Step 960/1170 | Loss: 0.0396 | Batch acc: 1.00\n",
      "  Step 970/1170 | Loss: 0.0826 | Batch acc: 0.97\n",
      "  Step 980/1170 | Loss: 0.0236 | Batch acc: 1.00\n",
      "  Step 990/1170 | Loss: 0.0961 | Batch acc: 0.97\n",
      "  Step 1000/1170 | Loss: 0.3154 | Batch acc: 0.91\n",
      "  Step 1010/1170 | Loss: 0.2250 | Batch acc: 0.94\n",
      "  Step 1020/1170 | Loss: 0.0580 | Batch acc: 1.00\n",
      "  Step 1030/1170 | Loss: 0.1520 | Batch acc: 0.94\n",
      "  Step 1040/1170 | Loss: 0.2079 | Batch acc: 0.94\n",
      "  Step 1050/1170 | Loss: 0.1855 | Batch acc: 0.91\n",
      "  Step 1060/1170 | Loss: 0.0693 | Batch acc: 1.00\n",
      "  Step 1070/1170 | Loss: 0.0602 | Batch acc: 1.00\n",
      "  Step 1080/1170 | Loss: 0.0623 | Batch acc: 1.00\n",
      "  Step 1090/1170 | Loss: 0.0334 | Batch acc: 1.00\n",
      "  Step 1100/1170 | Loss: 0.2256 | Batch acc: 0.94\n",
      "  Step 1110/1170 | Loss: 0.3222 | Batch acc: 0.84\n",
      "  Step 1120/1170 | Loss: 0.5678 | Batch acc: 0.81\n",
      "  Step 1130/1170 | Loss: 0.1160 | Batch acc: 0.97\n",
      "  Step 1140/1170 | Loss: 0.1365 | Batch acc: 0.94\n",
      "  Step 1150/1170 | Loss: 0.1182 | Batch acc: 0.97\n",
      "  Step 1160/1170 | Loss: 0.2714 | Batch acc: 0.91\n",
      "  Step 1170/1170 | Loss: 0.2812 | Batch acc: 0.86\n",
      "Train: loss=0.3513, acc=0.893\n",
      "  Step 1/307 | Loss: 2.1775 | Batch acc: 0.34\n",
      "  Step 10/307 | Loss: 0.5127 | Batch acc: 0.75\n",
      "  Step 20/307 | Loss: 0.0545 | Batch acc: 1.00\n",
      "  Step 30/307 | Loss: 0.0000 | Batch acc: 1.00\n",
      "  Step 40/307 | Loss: 0.0007 | Batch acc: 1.00\n",
      "  Step 50/307 | Loss: 1.1852 | Batch acc: 0.12\n",
      "  Step 60/307 | Loss: 1.2073 | Batch acc: 0.22\n",
      "  Step 70/307 | Loss: 0.1274 | Batch acc: 0.94\n",
      "  Step 80/307 | Loss: 0.0000 | Batch acc: 1.00\n",
      "  Step 90/307 | Loss: 1.3156 | Batch acc: 0.38\n",
      "  Step 100/307 | Loss: 0.8684 | Batch acc: 0.66\n",
      "  Step 110/307 | Loss: 1.3657 | Batch acc: 0.22\n",
      "  Step 120/307 | Loss: 2.1352 | Batch acc: 0.31\n",
      "  Step 130/307 | Loss: 10.5238 | Batch acc: 0.06\n",
      "  Step 140/307 | Loss: 0.3774 | Batch acc: 0.91\n",
      "  Step 150/307 | Loss: 0.0160 | Batch acc: 1.00\n",
      "  Step 160/307 | Loss: 0.3693 | Batch acc: 0.91\n",
      "  Step 170/307 | Loss: 0.1077 | Batch acc: 1.00\n",
      "  Step 180/307 | Loss: 0.0807 | Batch acc: 1.00\n",
      "  Step 190/307 | Loss: 0.1949 | Batch acc: 0.94\n",
      "  Step 200/307 | Loss: 0.0066 | Batch acc: 1.00\n",
      "  Step 210/307 | Loss: 0.0001 | Batch acc: 1.00\n",
      "  Step 220/307 | Loss: 0.6276 | Batch acc: 0.59\n",
      "  Step 230/307 | Loss: 0.2586 | Batch acc: 0.97\n",
      "  Step 240/307 | Loss: 3.2949 | Batch acc: 0.03\n",
      "  Step 250/307 | Loss: 8.4422 | Batch acc: 0.16\n",
      "  Step 260/307 | Loss: 0.0340 | Batch acc: 1.00\n",
      "  Step 270/307 | Loss: 0.0120 | Batch acc: 1.00\n",
      "  Step 280/307 | Loss: 0.0065 | Batch acc: 1.00\n",
      "  Step 290/307 | Loss: 0.0001 | Batch acc: 1.00\n",
      "  Step 300/307 | Loss: 0.0006 | Batch acc: 1.00\n",
      "Val:   loss=0.7413, acc=0.763\n",
      "  ✅ New best model saved (acc=0.763)\n",
      "\n",
      "Epoch 2/2\n",
      "  Step 1/1170 | Loss: 0.2772 | Batch acc: 0.91\n",
      "  Step 10/1170 | Loss: 0.1243 | Batch acc: 0.94\n",
      "  Step 20/1170 | Loss: 0.1291 | Batch acc: 0.97\n",
      "  Step 30/1170 | Loss: 0.1804 | Batch acc: 0.97\n",
      "  Step 40/1170 | Loss: 0.1640 | Batch acc: 0.88\n",
      "  Step 50/1170 | Loss: 0.0968 | Batch acc: 1.00\n",
      "  Step 60/1170 | Loss: 0.0343 | Batch acc: 1.00\n",
      "  Step 70/1170 | Loss: 0.1438 | Batch acc: 0.97\n",
      "  Step 80/1170 | Loss: 0.1343 | Batch acc: 0.94\n",
      "  Step 90/1170 | Loss: 0.0458 | Batch acc: 1.00\n",
      "  Step 100/1170 | Loss: 0.0676 | Batch acc: 0.97\n",
      "  Step 110/1170 | Loss: 0.0789 | Batch acc: 0.97\n",
      "  Step 120/1170 | Loss: 0.0523 | Batch acc: 1.00\n",
      "  Step 130/1170 | Loss: 0.2447 | Batch acc: 0.88\n",
      "  Step 140/1170 | Loss: 0.1811 | Batch acc: 0.97\n",
      "  Step 150/1170 | Loss: 0.1683 | Batch acc: 0.94\n",
      "  Step 160/1170 | Loss: 0.0911 | Batch acc: 0.97\n",
      "  Step 170/1170 | Loss: 0.2470 | Batch acc: 0.94\n",
      "  Step 180/1170 | Loss: 0.2093 | Batch acc: 0.88\n",
      "  Step 190/1170 | Loss: 0.0623 | Batch acc: 0.97\n",
      "  Step 200/1170 | Loss: 0.0073 | Batch acc: 1.00\n",
      "  Step 210/1170 | Loss: 0.1928 | Batch acc: 0.94\n",
      "  Step 220/1170 | Loss: 0.2091 | Batch acc: 0.88\n",
      "  Step 230/1170 | Loss: 0.2281 | Batch acc: 0.91\n",
      "  Step 240/1170 | Loss: 0.0469 | Batch acc: 1.00\n",
      "  Step 250/1170 | Loss: 0.2818 | Batch acc: 0.94\n",
      "  Step 260/1170 | Loss: 0.2606 | Batch acc: 0.94\n",
      "  Step 270/1170 | Loss: 0.1717 | Batch acc: 0.91\n",
      "  Step 280/1170 | Loss: 0.1001 | Batch acc: 0.97\n",
      "  Step 290/1170 | Loss: 0.3420 | Batch acc: 0.88\n",
      "  Step 300/1170 | Loss: 0.0886 | Batch acc: 0.97\n",
      "  Step 310/1170 | Loss: 0.0377 | Batch acc: 0.97\n",
      "  Step 320/1170 | Loss: 0.0372 | Batch acc: 1.00\n",
      "  Step 330/1170 | Loss: 0.1668 | Batch acc: 0.94\n",
      "  Step 340/1170 | Loss: 0.4895 | Batch acc: 0.91\n",
      "  Step 350/1170 | Loss: 0.0616 | Batch acc: 0.97\n",
      "  Step 360/1170 | Loss: 0.0717 | Batch acc: 1.00\n",
      "  Step 370/1170 | Loss: 0.0444 | Batch acc: 1.00\n",
      "  Step 380/1170 | Loss: 0.1393 | Batch acc: 0.91\n",
      "  Step 390/1170 | Loss: 0.1778 | Batch acc: 0.97\n",
      "  Step 400/1170 | Loss: 0.0644 | Batch acc: 1.00\n",
      "  Step 410/1170 | Loss: 0.2175 | Batch acc: 0.94\n",
      "  Step 420/1170 | Loss: 0.1692 | Batch acc: 0.97\n",
      "  Step 430/1170 | Loss: 0.1073 | Batch acc: 0.94\n",
      "  Step 440/1170 | Loss: 0.0793 | Batch acc: 0.97\n",
      "  Step 450/1170 | Loss: 0.0657 | Batch acc: 0.97\n",
      "  Step 460/1170 | Loss: 0.0979 | Batch acc: 0.94\n",
      "  Step 470/1170 | Loss: 0.1018 | Batch acc: 0.97\n",
      "  Step 480/1170 | Loss: 0.0279 | Batch acc: 1.00\n",
      "  Step 490/1170 | Loss: 0.0794 | Batch acc: 0.97\n",
      "  Step 500/1170 | Loss: 0.0096 | Batch acc: 1.00\n",
      "  Step 510/1170 | Loss: 0.0670 | Batch acc: 0.97\n",
      "  Step 520/1170 | Loss: 0.0199 | Batch acc: 1.00\n",
      "  Step 530/1170 | Loss: 0.3532 | Batch acc: 0.88\n",
      "  Step 540/1170 | Loss: 0.0313 | Batch acc: 0.97\n",
      "  Step 550/1170 | Loss: 0.0468 | Batch acc: 1.00\n",
      "  Step 560/1170 | Loss: 0.2141 | Batch acc: 0.94\n",
      "  Step 570/1170 | Loss: 0.1454 | Batch acc: 0.94\n",
      "  Step 580/1170 | Loss: 0.1049 | Batch acc: 0.97\n",
      "  Step 590/1170 | Loss: 0.0371 | Batch acc: 1.00\n",
      "  Step 600/1170 | Loss: 0.0305 | Batch acc: 1.00\n",
      "  Step 610/1170 | Loss: 0.0163 | Batch acc: 1.00\n",
      "  Step 620/1170 | Loss: 0.0360 | Batch acc: 1.00\n",
      "  Step 630/1170 | Loss: 0.0633 | Batch acc: 0.97\n",
      "  Step 640/1170 | Loss: 0.0480 | Batch acc: 0.97\n",
      "  Step 650/1170 | Loss: 0.1358 | Batch acc: 0.97\n",
      "  Step 660/1170 | Loss: 0.5439 | Batch acc: 0.84\n",
      "  Step 670/1170 | Loss: 0.0926 | Batch acc: 0.97\n",
      "  Step 680/1170 | Loss: 0.1707 | Batch acc: 0.91\n",
      "  Step 690/1170 | Loss: 0.1565 | Batch acc: 0.97\n",
      "  Step 700/1170 | Loss: 0.0439 | Batch acc: 1.00\n",
      "  Step 710/1170 | Loss: 0.1239 | Batch acc: 0.94\n",
      "  Step 720/1170 | Loss: 0.0389 | Batch acc: 1.00\n",
      "  Step 730/1170 | Loss: 0.0685 | Batch acc: 0.97\n",
      "  Step 740/1170 | Loss: 0.3070 | Batch acc: 0.91\n",
      "  Step 750/1170 | Loss: 0.0116 | Batch acc: 1.00\n",
      "  Step 760/1170 | Loss: 0.1042 | Batch acc: 0.97\n",
      "  Step 770/1170 | Loss: 0.0937 | Batch acc: 0.97\n",
      "  Step 780/1170 | Loss: 0.3124 | Batch acc: 0.91\n",
      "  Step 790/1170 | Loss: 0.1240 | Batch acc: 0.94\n",
      "  Step 800/1170 | Loss: 0.1657 | Batch acc: 0.97\n",
      "  Step 810/1170 | Loss: 0.0694 | Batch acc: 0.97\n",
      "  Step 820/1170 | Loss: 0.2379 | Batch acc: 0.91\n",
      "  Step 830/1170 | Loss: 0.0871 | Batch acc: 0.97\n",
      "  Step 840/1170 | Loss: 0.0494 | Batch acc: 1.00\n",
      "  Step 850/1170 | Loss: 0.0624 | Batch acc: 1.00\n",
      "  Step 860/1170 | Loss: 0.0836 | Batch acc: 0.97\n",
      "  Step 870/1170 | Loss: 0.3403 | Batch acc: 0.91\n",
      "  Step 880/1170 | Loss: 0.0588 | Batch acc: 0.97\n",
      "  Step 890/1170 | Loss: 0.2916 | Batch acc: 0.91\n",
      "  Step 900/1170 | Loss: 0.1632 | Batch acc: 0.94\n",
      "  Step 910/1170 | Loss: 0.1125 | Batch acc: 0.97\n",
      "  Step 920/1170 | Loss: 0.1887 | Batch acc: 0.91\n",
      "  Step 930/1170 | Loss: 0.0432 | Batch acc: 1.00\n",
      "  Step 940/1170 | Loss: 0.1010 | Batch acc: 0.97\n",
      "  Step 950/1170 | Loss: 0.0363 | Batch acc: 1.00\n",
      "  Step 960/1170 | Loss: 0.0264 | Batch acc: 1.00\n",
      "  Step 970/1170 | Loss: 0.0238 | Batch acc: 1.00\n",
      "  Step 980/1170 | Loss: 0.1933 | Batch acc: 0.97\n",
      "  Step 990/1170 | Loss: 0.0567 | Batch acc: 1.00\n",
      "  Step 1000/1170 | Loss: 0.0148 | Batch acc: 1.00\n",
      "  Step 1010/1170 | Loss: 0.3080 | Batch acc: 0.94\n",
      "  Step 1020/1170 | Loss: 0.2011 | Batch acc: 0.91\n",
      "  Step 1030/1170 | Loss: 0.1345 | Batch acc: 0.94\n",
      "  Step 1040/1170 | Loss: 0.1371 | Batch acc: 0.97\n",
      "  Step 1050/1170 | Loss: 0.0788 | Batch acc: 1.00\n",
      "  Step 1060/1170 | Loss: 0.1700 | Batch acc: 0.94\n",
      "  Step 1070/1170 | Loss: 0.1999 | Batch acc: 0.94\n",
      "  Step 1080/1170 | Loss: 0.1010 | Batch acc: 0.97\n",
      "  Step 1090/1170 | Loss: 0.0837 | Batch acc: 0.97\n",
      "  Step 1100/1170 | Loss: 0.2506 | Batch acc: 0.94\n",
      "  Step 1110/1170 | Loss: 0.0497 | Batch acc: 1.00\n",
      "  Step 1120/1170 | Loss: 0.0383 | Batch acc: 1.00\n",
      "  Step 1130/1170 | Loss: 0.1251 | Batch acc: 0.94\n",
      "  Step 1140/1170 | Loss: 0.2429 | Batch acc: 0.91\n",
      "  Step 1150/1170 | Loss: 0.1197 | Batch acc: 0.97\n",
      "  Step 1160/1170 | Loss: 0.1550 | Batch acc: 0.94\n",
      "  Step 1170/1170 | Loss: 0.1394 | Batch acc: 0.95\n",
      "Train: loss=0.1413, acc=0.955\n",
      "  Step 1/307 | Loss: 2.3800 | Batch acc: 0.34\n",
      "  Step 10/307 | Loss: 0.2010 | Batch acc: 0.94\n",
      "  Step 20/307 | Loss: 0.0158 | Batch acc: 1.00\n",
      "  Step 30/307 | Loss: 0.0001 | Batch acc: 1.00\n",
      "  Step 40/307 | Loss: 0.0027 | Batch acc: 1.00\n",
      "  Step 50/307 | Loss: 5.7866 | Batch acc: 0.00\n",
      "  Step 60/307 | Loss: 4.8996 | Batch acc: 0.00\n",
      "  Step 70/307 | Loss: 0.1524 | Batch acc: 0.94\n",
      "  Step 80/307 | Loss: 0.0001 | Batch acc: 1.00\n",
      "  Step 90/307 | Loss: 3.0749 | Batch acc: 0.06\n",
      "  Step 100/307 | Loss: 0.6330 | Batch acc: 0.75\n",
      "  Step 110/307 | Loss: 3.9887 | Batch acc: 0.00\n",
      "  Step 120/307 | Loss: 1.8790 | Batch acc: 0.28\n",
      "  Step 130/307 | Loss: 8.3719 | Batch acc: 0.09\n",
      "  Step 140/307 | Loss: 0.9286 | Batch acc: 0.66\n",
      "  Step 150/307 | Loss: 0.1422 | Batch acc: 0.97\n",
      "  Step 160/307 | Loss: 0.3676 | Batch acc: 0.84\n",
      "  Step 170/307 | Loss: 0.4183 | Batch acc: 0.84\n",
      "  Step 180/307 | Loss: 0.1831 | Batch acc: 1.00\n",
      "  Step 190/307 | Loss: 0.5663 | Batch acc: 0.88\n",
      "  Step 200/307 | Loss: 0.0025 | Batch acc: 1.00\n",
      "  Step 210/307 | Loss: 0.0001 | Batch acc: 1.00\n",
      "  Step 220/307 | Loss: 0.1728 | Batch acc: 1.00\n",
      "  Step 230/307 | Loss: 0.1694 | Batch acc: 0.94\n",
      "  Step 240/307 | Loss: 9.8961 | Batch acc: 0.00\n",
      "  Step 250/307 | Loss: 4.9444 | Batch acc: 0.16\n",
      "  Step 260/307 | Loss: 0.0211 | Batch acc: 1.00\n",
      "  Step 270/307 | Loss: 0.0050 | Batch acc: 1.00\n",
      "  Step 280/307 | Loss: 0.0097 | Batch acc: 1.00\n",
      "  Step 290/307 | Loss: 0.0000 | Batch acc: 1.00\n",
      "  Step 300/307 | Loss: 0.0036 | Batch acc: 1.00\n",
      "Val:   loss=1.3308, acc=0.707\n",
      "\n",
      "Training finished!\n",
      "Best validation accuracy: 0.763\n",
      "Elapsed time: 403.7 sec\n"
     ]
    }
   ],
   "source": [
    "# ==== Tiny ResNet50 sanity trainer for Kvasir-Capsule ====\n",
    "# - Beginner-friendly, step-by-step\n",
    "# - Prints debug info along the way\n",
    "# - Optimized for Tesla V100 (mixed precision, pinned memory, etc.)\n",
    "# =========================================================\n",
    "\n",
    "import os, time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from collections import Counter\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CSV_PATH = \"/bhome/fwag/ele670_project/data/processed/metadata_normalized.csv\"\n",
    "IMG_ROOT   = \"/bhome/fwag/ele670_project/data/raw/labelled_images\"\n",
    "IMG_SIZE   = 224\n",
    "BATCH_SIZE = 32     # safe for V100 (can go higher if memory allows)\n",
    "NUM_WORKERS = 4     # adjust depending on system\n",
    "EPOCHS     = 2      # keep small for quick sanity check\n",
    "LR         = 1e-3\n",
    "SEED       = 42\n",
    "\n",
    "# ----------------------------------------\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"Memory allocated:\", round(torch.cuda.memory_allocated(0)/1024**3, 2), \"GB\")\n",
    "\n",
    "# --------------- DATASET ----------------\n",
    "class KvasirDataset(Dataset):\n",
    "    \"\"\"Custom dataset to read image paths + labels from CSV.\"\"\"\n",
    "    def __init__(self, df, img_root, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Join root with relative path from CSV\n",
    "        img_path = os.path.join(self.img_root, row[\"image_path\"])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Failed to open {img_path}: {e}\")\n",
    "            # use black image as fallback\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0,0,0))\n",
    "        img = self.transform(img)\n",
    "        label = int(row[\"encoded_label\"])\n",
    "        return img, label\n",
    "\n",
    "# --------------- LOAD CSV ----------------\n",
    "df = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "print(\"First rows of metadata_processed.csv:\")\n",
    "print(df.head())\n",
    "\n",
    "# How many unique classes?\n",
    "num_classes = df[\"encoded_label\"].nunique()\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# --------------- TRAIN/VAL SPLIT ----------------\n",
    "# Keep videos separated (no leakage between train/val)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"video_id\"]))\n",
    "df_train, df_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "\n",
    "print(f\"Train samples: {len(df_train)} | Val samples: {len(df_val)}\")\n",
    "print(f\"Train videos: {df_train['video_id'].nunique()} | Val videos: {df_val['video_id'].nunique()}\")\n",
    "\n",
    "# --------------- TRANSFORMS ----------------\n",
    "# Simple transforms for sanity check\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# --------------- DATA LOADERS ----------------\n",
    "train_ds = KvasirDataset(df_train, IMG_ROOT, train_tf)\n",
    "val_ds   = KvasirDataset(df_val,   IMG_ROOT, val_tf)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"One training batch (images, labels):\")\n",
    "sample_imgs, sample_labels = next(iter(train_loader))\n",
    "print(\"Image batch shape:\", sample_imgs.shape)\n",
    "print(\"Label batch shape:\", sample_labels.shape)\n",
    "\n",
    "# --------------- MODEL ----------------\n",
    "# Load ResNet50 with ImageNet weights (helps it train faster)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # replace classifier\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss + optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Mixed precision (faster on V100)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# --------------- TRAINING LOOP ----------------\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "\n",
    "    for step, (imgs, labels) in enumerate(loader, start=1):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Print debug info every 10 steps\n",
    "        if step % 10 == 0 or step == 1:\n",
    "            print(f\"  Step {step}/{len(loader)} | Loss: {loss.item():.4f} | \"\n",
    "                  f\"Batch acc: {correct/labels.size(0):.2f}\")\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# --------------- TRAIN FOR A FEW EPOCHS ----------------\n",
    "print(\"\\n==== START TRAINING ====\\n\")\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = run_epoch(train_loader, train=True)\n",
    "    print(f\"Train: loss={train_loss:.4f}, acc={train_acc:.3f}\")\n",
    "\n",
    "    val_loss, val_acc = run_epoch(val_loader, train=False)\n",
    "    print(f\"Val:   loss={val_loss:.4f}, acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"tiny_resnet50_best.pt\")\n",
    "        print(f\"  ✅ New best model saved (acc={best_val_acc:.3f})\")\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(\"Best validation accuracy:\", round(best_val_acc, 3))\n",
    "print(\"Elapsed time: %.1f sec\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd260f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce100be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla V100-PCIE-32GB\n",
      "Allocated: 0.56 GB\n",
      "Reserved:  3.44 GB\n",
      "First rows of metadata_normalized.csv:\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              9  \n",
      "1  0728084c8da942d9              9  \n",
      "2  0728084c8da942d9              9  \n",
      "3  0728084c8da942d9              9  \n",
      "4  0728084c8da942d9              9  \n",
      "Number of classes: 14\n",
      "Train samples: 37430 | Val samples: 9818\n",
      "Train videos: 34 | Val videos: 9\n",
      "One training batch (images, labels):\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Label batch shape: torch.Size([32])\n",
      "\n",
      "==== START TRAINING ====\n",
      "\n",
      "\n",
      "Epoch 1/2\n",
      "  Step 1/1169 | Loss: 2.7060 | Batch acc: 0.03\n",
      "  Step 10/1169 | Loss: 1.1464 | Batch acc: 0.78\n",
      "  Step 20/1169 | Loss: 2.0793 | Batch acc: 0.56\n",
      "  Step 30/1169 | Loss: 1.2360 | Batch acc: 0.69\n",
      "  Step 40/1169 | Loss: 1.3910 | Batch acc: 0.62\n",
      "  Step 50/1169 | Loss: 1.2361 | Batch acc: 0.72\n",
      "  Step 60/1169 | Loss: 1.1189 | Batch acc: 0.75\n",
      "  Step 70/1169 | Loss: 0.9773 | Batch acc: 0.81\n",
      "  Step 80/1169 | Loss: 0.9523 | Batch acc: 0.78\n",
      "  Step 90/1169 | Loss: 1.3639 | Batch acc: 0.59\n",
      "  Step 100/1169 | Loss: 1.0276 | Batch acc: 0.75\n",
      "  Step 110/1169 | Loss: 0.8167 | Batch acc: 0.88\n",
      "  Step 120/1169 | Loss: 0.9579 | Batch acc: 0.75\n",
      "  Step 130/1169 | Loss: 0.9642 | Batch acc: 0.84\n",
      "  Step 140/1169 | Loss: 1.1073 | Batch acc: 0.78\n",
      "  Step 150/1169 | Loss: 0.7302 | Batch acc: 0.88\n",
      "  Step 160/1169 | Loss: 1.3628 | Batch acc: 0.59\n",
      "  Step 170/1169 | Loss: 0.9289 | Batch acc: 0.81\n",
      "  Step 180/1169 | Loss: 0.7257 | Batch acc: 0.88\n",
      "  Step 190/1169 | Loss: 0.7274 | Batch acc: 0.84\n",
      "  Step 200/1169 | Loss: 0.9095 | Batch acc: 0.78\n",
      "  Step 210/1169 | Loss: 0.8077 | Batch acc: 0.78\n",
      "  Step 220/1169 | Loss: 0.9365 | Batch acc: 0.78\n",
      "  Step 230/1169 | Loss: 0.9867 | Batch acc: 0.75\n",
      "  Step 240/1169 | Loss: 0.8396 | Batch acc: 0.78\n",
      "  Step 250/1169 | Loss: 0.8777 | Batch acc: 0.84\n",
      "  Step 260/1169 | Loss: 0.7974 | Batch acc: 0.88\n",
      "  Step 270/1169 | Loss: 0.7858 | Batch acc: 0.88\n",
      "  Step 280/1169 | Loss: 0.8213 | Batch acc: 0.84\n",
      "  Step 290/1169 | Loss: 0.9496 | Batch acc: 0.81\n",
      "  Step 300/1169 | Loss: 1.1069 | Batch acc: 0.66\n",
      "  Step 310/1169 | Loss: 0.6433 | Batch acc: 0.88\n",
      "  Step 320/1169 | Loss: 0.5208 | Batch acc: 1.00\n",
      "  Step 330/1169 | Loss: 0.6260 | Batch acc: 0.91\n",
      "  Step 340/1169 | Loss: 1.1711 | Batch acc: 0.72\n",
      "  Step 350/1169 | Loss: 0.7984 | Batch acc: 0.78\n",
      "  Step 360/1169 | Loss: 0.6885 | Batch acc: 0.94\n",
      "  Step 370/1169 | Loss: 0.9485 | Batch acc: 0.81\n",
      "  Step 380/1169 | Loss: 0.7774 | Batch acc: 0.84\n",
      "  Step 390/1169 | Loss: 0.8924 | Batch acc: 0.75\n",
      "  Step 400/1169 | Loss: 0.6733 | Batch acc: 0.88\n",
      "  Step 410/1169 | Loss: 0.8423 | Batch acc: 0.78\n",
      "  Step 420/1169 | Loss: 0.9955 | Batch acc: 0.72\n",
      "  Step 430/1169 | Loss: 0.6317 | Batch acc: 0.91\n",
      "  Step 440/1169 | Loss: 0.6166 | Batch acc: 0.94\n",
      "  Step 450/1169 | Loss: 0.5852 | Batch acc: 0.91\n",
      "  Step 460/1169 | Loss: 0.7134 | Batch acc: 0.81\n",
      "  Step 470/1169 | Loss: 0.9394 | Batch acc: 0.78\n",
      "  Step 480/1169 | Loss: 0.9142 | Batch acc: 0.72\n",
      "  Step 490/1169 | Loss: 0.8555 | Batch acc: 0.84\n",
      "  Step 500/1169 | Loss: 0.8311 | Batch acc: 0.88\n",
      "  Step 510/1169 | Loss: 0.6724 | Batch acc: 0.88\n",
      "  Step 520/1169 | Loss: 0.6830 | Batch acc: 0.88\n",
      "  Step 530/1169 | Loss: 0.7150 | Batch acc: 0.84\n",
      "  Step 540/1169 | Loss: 0.5653 | Batch acc: 0.91\n",
      "  Step 550/1169 | Loss: 0.8096 | Batch acc: 0.81\n",
      "  Step 560/1169 | Loss: 0.8922 | Batch acc: 0.78\n",
      "  Step 570/1169 | Loss: 0.7692 | Batch acc: 0.88\n",
      "  Step 580/1169 | Loss: 0.7491 | Batch acc: 0.84\n",
      "  Step 590/1169 | Loss: 0.7248 | Batch acc: 0.88\n",
      "  Step 600/1169 | Loss: 0.9536 | Batch acc: 0.81\n",
      "  Step 610/1169 | Loss: 0.7266 | Batch acc: 0.88\n",
      "  Step 620/1169 | Loss: 0.9706 | Batch acc: 0.78\n",
      "  Step 630/1169 | Loss: 0.5183 | Batch acc: 0.94\n",
      "  Step 640/1169 | Loss: 0.5797 | Batch acc: 0.94\n",
      "  Step 650/1169 | Loss: 0.6028 | Batch acc: 0.88\n",
      "  Step 660/1169 | Loss: 0.6686 | Batch acc: 0.88\n",
      "  Step 670/1169 | Loss: 0.7816 | Batch acc: 0.91\n",
      "  Step 680/1169 | Loss: 0.5842 | Batch acc: 0.97\n",
      "  Step 690/1169 | Loss: 0.7380 | Batch acc: 0.88\n",
      "  Step 700/1169 | Loss: 0.7544 | Batch acc: 0.88\n",
      "  Step 710/1169 | Loss: 0.7953 | Batch acc: 0.91\n",
      "  Step 720/1169 | Loss: 0.7423 | Batch acc: 0.88\n",
      "  Step 730/1169 | Loss: 0.8360 | Batch acc: 0.78\n",
      "  Step 740/1169 | Loss: 0.7925 | Batch acc: 0.84\n",
      "  Step 750/1169 | Loss: 0.6496 | Batch acc: 0.88\n",
      "  Step 760/1169 | Loss: 0.7625 | Batch acc: 0.88\n",
      "  Step 770/1169 | Loss: 0.6289 | Batch acc: 0.91\n",
      "  Step 780/1169 | Loss: 1.0365 | Batch acc: 0.78\n",
      "  Step 790/1169 | Loss: 0.7365 | Batch acc: 0.84\n",
      "  Step 800/1169 | Loss: 0.7272 | Batch acc: 0.84\n",
      "  Step 810/1169 | Loss: 0.7772 | Batch acc: 0.81\n",
      "  Step 820/1169 | Loss: 0.6202 | Batch acc: 0.84\n",
      "  Step 830/1169 | Loss: 0.6488 | Batch acc: 0.91\n",
      "  Step 840/1169 | Loss: 0.6319 | Batch acc: 0.91\n",
      "  Step 850/1169 | Loss: 0.7612 | Batch acc: 0.88\n",
      "  Step 860/1169 | Loss: 0.5988 | Batch acc: 0.97\n",
      "  Step 870/1169 | Loss: 0.7321 | Batch acc: 0.88\n",
      "  Step 880/1169 | Loss: 0.9290 | Batch acc: 0.78\n",
      "  Step 890/1169 | Loss: 0.4831 | Batch acc: 0.97\n",
      "  Step 900/1169 | Loss: 0.8097 | Batch acc: 0.78\n",
      "  Step 910/1169 | Loss: 0.7557 | Batch acc: 0.88\n",
      "  Step 920/1169 | Loss: 0.6286 | Batch acc: 0.88\n",
      "  Step 930/1169 | Loss: 0.5861 | Batch acc: 0.91\n",
      "  Step 940/1169 | Loss: 0.7810 | Batch acc: 0.84\n",
      "  Step 950/1169 | Loss: 0.5232 | Batch acc: 0.94\n",
      "  Step 960/1169 | Loss: 0.6420 | Batch acc: 0.88\n",
      "  Step 970/1169 | Loss: 0.7110 | Batch acc: 0.88\n",
      "  Step 980/1169 | Loss: 0.8085 | Batch acc: 0.88\n",
      "  Step 990/1169 | Loss: 0.8574 | Batch acc: 0.78\n",
      "  Step 1000/1169 | Loss: 0.6370 | Batch acc: 0.88\n",
      "  Step 1010/1169 | Loss: 0.6104 | Batch acc: 0.94\n",
      "  Step 1020/1169 | Loss: 0.5862 | Batch acc: 0.91\n",
      "  Step 1030/1169 | Loss: 0.7270 | Batch acc: 0.88\n",
      "  Step 1040/1169 | Loss: 0.5953 | Batch acc: 0.94\n",
      "  Step 1050/1169 | Loss: 0.5379 | Batch acc: 0.94\n",
      "  Step 1060/1169 | Loss: 0.9549 | Batch acc: 0.78\n",
      "  Step 1070/1169 | Loss: 0.6003 | Batch acc: 0.91\n",
      "  Step 1080/1169 | Loss: 0.7011 | Batch acc: 0.88\n",
      "  Step 1090/1169 | Loss: 0.5173 | Batch acc: 0.94\n",
      "  Step 1100/1169 | Loss: 0.5076 | Batch acc: 0.97\n",
      "  Step 1110/1169 | Loss: 0.8430 | Batch acc: 0.84\n",
      "  Step 1120/1169 | Loss: 0.7982 | Batch acc: 0.84\n",
      "  Step 1130/1169 | Loss: 0.5252 | Batch acc: 0.91\n",
      "  Step 1140/1169 | Loss: 0.5714 | Batch acc: 0.94\n",
      "  Step 1150/1169 | Loss: 0.8356 | Batch acc: 0.84\n",
      "  Step 1160/1169 | Loss: 0.5616 | Batch acc: 0.91\n",
      "Train: loss=0.7997, acc=0.839\n",
      "  Step 1/307 | Loss: 1.7948 | Batch acc: 0.34\n",
      "  Step 10/307 | Loss: 0.7074 | Batch acc: 0.84\n",
      "  Step 20/307 | Loss: 0.3601 | Batch acc: 1.00\n",
      "  Step 30/307 | Loss: 0.3456 | Batch acc: 1.00\n",
      "  Step 40/307 | Loss: 0.3537 | Batch acc: 1.00\n",
      "  Step 50/307 | Loss: 1.1481 | Batch acc: 0.38\n",
      "  Step 60/307 | Loss: 1.1434 | Batch acc: 0.44\n",
      "  Step 70/307 | Loss: 0.4093 | Batch acc: 1.00\n",
      "  Step 80/307 | Loss: 0.3646 | Batch acc: 1.00\n",
      "  Step 90/307 | Loss: 2.2921 | Batch acc: 0.09\n",
      "  Step 100/307 | Loss: 1.3469 | Batch acc: 0.50\n",
      "  Step 110/307 | Loss: 2.1229 | Batch acc: 0.16\n",
      "  Step 120/307 | Loss: 1.7761 | Batch acc: 0.41\n",
      "  Step 130/307 | Loss: 5.1214 | Batch acc: 0.09\n",
      "  Step 140/307 | Loss: 0.4234 | Batch acc: 1.00\n",
      "  Step 150/307 | Loss: 0.3863 | Batch acc: 1.00\n",
      "  Step 160/307 | Loss: 0.3927 | Batch acc: 1.00\n",
      "  Step 170/307 | Loss: 0.8214 | Batch acc: 0.78\n",
      "  Step 180/307 | Loss: 0.5415 | Batch acc: 1.00\n",
      "  Step 190/307 | Loss: 0.9559 | Batch acc: 0.75\n",
      "  Step 200/307 | Loss: 0.4228 | Batch acc: 0.97\n",
      "  Step 210/307 | Loss: 0.3493 | Batch acc: 1.00\n",
      "  Step 220/307 | Loss: 0.7700 | Batch acc: 0.81\n",
      "  Step 230/307 | Loss: 0.4999 | Batch acc: 0.97\n",
      "  Step 240/307 | Loss: 2.8191 | Batch acc: 0.09\n",
      "  Step 250/307 | Loss: 3.7511 | Batch acc: 0.12\n",
      "  Step 260/307 | Loss: 0.4461 | Batch acc: 1.00\n",
      "  Step 270/307 | Loss: 0.3504 | Batch acc: 1.00\n",
      "  Step 280/307 | Loss: 0.3573 | Batch acc: 1.00\n",
      "  Step 290/307 | Loss: 0.3799 | Batch acc: 1.00\n",
      "  Step 300/307 | Loss: 0.3740 | Batch acc: 1.00\n",
      "Val:   loss=0.9487, acc=0.746\n",
      "  ✅ New best model saved → /bhome/fwag/ele670_project/results/tiny_resnet50_best.pt (acc=0.746)\n",
      "\n",
      "Validation Confusion Matrix (rows=true, cols=pred):\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0   11    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    3    0   15    0   18    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    2    8    0    3    0  410  460    1  600    0    2   76   85]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0   30    0    0    1    0   23  114   12 6769    0  537   58   23]\n",
      " [   0    1    0    0    0    0   18    1    0   34    0    0    0    1]\n",
      " [   0    3    1    0    0    0   21    7    0  127    0   81   17    6]\n",
      " [   0    0    0    0    0    0    2  191    0   19    0    0   17   10]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Ampulla of Vater      0.000     0.000     0.000         0\n",
      "         Angiectasia      0.000     0.000     0.000        11\n",
      "       Blood - fresh      0.000     0.000     0.000         0\n",
      "     Blood - hematin      0.000     0.000     0.000         0\n",
      "             Erosion      0.000     0.000     0.000        36\n",
      "            Erythema      0.000     0.000     0.000         0\n",
      "        Foreign Body      0.000     0.000     0.000         0\n",
      "     Ileocecal valve      0.593     0.279     0.380      1647\n",
      "    Lymphangiectasia      0.000     0.000     0.000         0\n",
      " Normal clean mucosa      0.894     0.895     0.894      7567\n",
      "            class_10      0.000     0.000     0.000        55\n",
      "             Pylorus      0.127     0.308     0.180       263\n",
      "Reduced Mucosal View      0.101     0.071     0.084       239\n",
      "               Ulcer      0.000     0.000     0.000         0\n",
      "\n",
      "            accuracy                          0.746      9818\n",
      "           macro avg      0.122     0.111     0.110      9818\n",
      "        weighted avg      0.794     0.746     0.760      9818\n",
      "\n",
      "\n",
      "Epoch 2/2\n",
      "  Step 1/1169 | Loss: 0.8468 | Batch acc: 0.81\n",
      "  Step 10/1169 | Loss: 0.5508 | Batch acc: 0.94\n",
      "  Step 20/1169 | Loss: 0.7293 | Batch acc: 0.81\n",
      "  Step 30/1169 | Loss: 0.6812 | Batch acc: 0.88\n",
      "  Step 40/1169 | Loss: 0.6169 | Batch acc: 0.84\n",
      "  Step 50/1169 | Loss: 0.6556 | Batch acc: 0.94\n",
      "  Step 60/1169 | Loss: 0.6241 | Batch acc: 0.97\n",
      "  Step 70/1169 | Loss: 0.5211 | Batch acc: 0.94\n",
      "  Step 80/1169 | Loss: 0.6190 | Batch acc: 0.91\n",
      "  Step 90/1169 | Loss: 0.5234 | Batch acc: 0.94\n",
      "  Step 100/1169 | Loss: 0.6207 | Batch acc: 0.97\n",
      "  Step 110/1169 | Loss: 0.5154 | Batch acc: 0.91\n",
      "  Step 120/1169 | Loss: 0.5046 | Batch acc: 0.94\n",
      "  Step 130/1169 | Loss: 0.4785 | Batch acc: 1.00\n",
      "  Step 140/1169 | Loss: 0.5123 | Batch acc: 0.94\n",
      "  Step 150/1169 | Loss: 0.7085 | Batch acc: 0.91\n",
      "  Step 160/1169 | Loss: 0.6429 | Batch acc: 0.88\n",
      "  Step 170/1169 | Loss: 0.8848 | Batch acc: 0.72\n",
      "  Step 180/1169 | Loss: 0.7075 | Batch acc: 0.81\n",
      "  Step 190/1169 | Loss: 0.5458 | Batch acc: 0.94\n",
      "  Step 200/1169 | Loss: 0.5814 | Batch acc: 0.91\n",
      "  Step 210/1169 | Loss: 0.6697 | Batch acc: 0.84\n",
      "  Step 220/1169 | Loss: 0.4838 | Batch acc: 1.00\n",
      "  Step 230/1169 | Loss: 0.4734 | Batch acc: 0.94\n",
      "  Step 240/1169 | Loss: 0.5837 | Batch acc: 0.88\n",
      "  Step 250/1169 | Loss: 0.7906 | Batch acc: 0.84\n",
      "  Step 260/1169 | Loss: 0.5058 | Batch acc: 0.97\n",
      "  Step 270/1169 | Loss: 0.6165 | Batch acc: 0.88\n",
      "  Step 280/1169 | Loss: 0.5212 | Batch acc: 0.94\n",
      "  Step 290/1169 | Loss: 0.4751 | Batch acc: 1.00\n",
      "  Step 300/1169 | Loss: 0.5083 | Batch acc: 0.97\n",
      "  Step 310/1169 | Loss: 0.4795 | Batch acc: 0.97\n",
      "  Step 320/1169 | Loss: 0.4793 | Batch acc: 0.97\n",
      "  Step 330/1169 | Loss: 0.5279 | Batch acc: 0.94\n",
      "  Step 340/1169 | Loss: 0.6518 | Batch acc: 0.91\n",
      "  Step 350/1169 | Loss: 0.4640 | Batch acc: 0.97\n",
      "  Step 360/1169 | Loss: 0.6794 | Batch acc: 0.94\n",
      "  Step 370/1169 | Loss: 0.5424 | Batch acc: 0.94\n",
      "  Step 380/1169 | Loss: 0.6615 | Batch acc: 0.84\n",
      "  Step 390/1169 | Loss: 0.5845 | Batch acc: 0.94\n",
      "  Step 400/1169 | Loss: 0.5316 | Batch acc: 0.91\n",
      "  Step 410/1169 | Loss: 0.6867 | Batch acc: 0.88\n",
      "  Step 420/1169 | Loss: 0.6426 | Batch acc: 0.94\n",
      "  Step 430/1169 | Loss: 0.4620 | Batch acc: 0.97\n",
      "  Step 440/1169 | Loss: 0.6392 | Batch acc: 0.94\n",
      "  Step 450/1169 | Loss: 0.8226 | Batch acc: 0.75\n",
      "  Step 460/1169 | Loss: 0.5799 | Batch acc: 0.94\n",
      "  Step 470/1169 | Loss: 0.4300 | Batch acc: 1.00\n",
      "  Step 480/1169 | Loss: 0.4946 | Batch acc: 0.94\n",
      "  Step 490/1169 | Loss: 0.4982 | Batch acc: 0.97\n",
      "  Step 500/1169 | Loss: 0.4830 | Batch acc: 1.00\n",
      "  Step 510/1169 | Loss: 0.5428 | Batch acc: 0.94\n",
      "  Step 520/1169 | Loss: 0.6766 | Batch acc: 0.91\n",
      "  Step 530/1169 | Loss: 0.6072 | Batch acc: 0.84\n",
      "  Step 540/1169 | Loss: 0.5875 | Batch acc: 0.94\n",
      "  Step 550/1169 | Loss: 0.7346 | Batch acc: 0.88\n",
      "  Step 560/1169 | Loss: 0.5606 | Batch acc: 0.94\n",
      "  Step 570/1169 | Loss: 0.5901 | Batch acc: 0.94\n",
      "  Step 580/1169 | Loss: 0.5896 | Batch acc: 0.94\n",
      "  Step 590/1169 | Loss: 0.6095 | Batch acc: 0.88\n",
      "  Step 600/1169 | Loss: 0.5521 | Batch acc: 0.91\n",
      "  Step 610/1169 | Loss: 0.4517 | Batch acc: 0.94\n",
      "  Step 620/1169 | Loss: 0.5998 | Batch acc: 0.94\n",
      "  Step 630/1169 | Loss: 0.6607 | Batch acc: 0.84\n",
      "  Step 640/1169 | Loss: 0.5206 | Batch acc: 0.91\n",
      "  Step 650/1169 | Loss: 0.4532 | Batch acc: 1.00\n",
      "  Step 660/1169 | Loss: 0.5985 | Batch acc: 0.88\n",
      "  Step 670/1169 | Loss: 0.6059 | Batch acc: 0.91\n",
      "  Step 680/1169 | Loss: 0.4285 | Batch acc: 0.97\n",
      "  Step 690/1169 | Loss: 0.5716 | Batch acc: 0.94\n",
      "  Step 700/1169 | Loss: 0.5669 | Batch acc: 0.91\n",
      "  Step 710/1169 | Loss: 0.4611 | Batch acc: 0.97\n",
      "  Step 720/1169 | Loss: 0.4730 | Batch acc: 0.97\n",
      "  Step 730/1169 | Loss: 0.5763 | Batch acc: 0.91\n",
      "  Step 740/1169 | Loss: 0.6177 | Batch acc: 0.91\n",
      "  Step 750/1169 | Loss: 0.7120 | Batch acc: 0.84\n",
      "  Step 760/1169 | Loss: 0.4820 | Batch acc: 1.00\n",
      "  Step 770/1169 | Loss: 0.4644 | Batch acc: 0.97\n",
      "  Step 780/1169 | Loss: 0.5423 | Batch acc: 0.94\n",
      "  Step 790/1169 | Loss: 0.7398 | Batch acc: 0.84\n",
      "  Step 800/1169 | Loss: 0.5299 | Batch acc: 0.94\n",
      "  Step 810/1169 | Loss: 0.6315 | Batch acc: 0.81\n",
      "  Step 820/1169 | Loss: 0.5785 | Batch acc: 0.94\n",
      "  Step 830/1169 | Loss: 0.6543 | Batch acc: 0.88\n",
      "  Step 840/1169 | Loss: 0.5485 | Batch acc: 0.91\n",
      "  Step 850/1169 | Loss: 0.5871 | Batch acc: 0.91\n",
      "  Step 860/1169 | Loss: 0.6900 | Batch acc: 0.88\n",
      "  Step 870/1169 | Loss: 0.5113 | Batch acc: 0.94\n",
      "  Step 880/1169 | Loss: 0.5825 | Batch acc: 0.94\n",
      "  Step 890/1169 | Loss: 0.4847 | Batch acc: 1.00\n",
      "  Step 900/1169 | Loss: 0.5325 | Batch acc: 0.97\n",
      "  Step 910/1169 | Loss: 0.6525 | Batch acc: 0.91\n",
      "  Step 920/1169 | Loss: 0.4729 | Batch acc: 0.97\n",
      "  Step 930/1169 | Loss: 0.6878 | Batch acc: 0.84\n",
      "  Step 940/1169 | Loss: 0.6039 | Batch acc: 0.91\n",
      "  Step 950/1169 | Loss: 0.4333 | Batch acc: 1.00\n",
      "  Step 960/1169 | Loss: 0.4892 | Batch acc: 0.94\n",
      "  Step 970/1169 | Loss: 0.5612 | Batch acc: 0.91\n",
      "  Step 980/1169 | Loss: 0.4785 | Batch acc: 0.97\n",
      "  Step 990/1169 | Loss: 0.7986 | Batch acc: 0.84\n",
      "  Step 1000/1169 | Loss: 0.6397 | Batch acc: 0.91\n",
      "  Step 1010/1169 | Loss: 0.6831 | Batch acc: 0.88\n",
      "  Step 1020/1169 | Loss: 0.7763 | Batch acc: 0.78\n",
      "  Step 1030/1169 | Loss: 0.4706 | Batch acc: 0.97\n",
      "  Step 1040/1169 | Loss: 0.6343 | Batch acc: 0.88\n",
      "  Step 1050/1169 | Loss: 0.5761 | Batch acc: 0.94\n",
      "  Step 1060/1169 | Loss: 0.5023 | Batch acc: 0.97\n",
      "  Step 1070/1169 | Loss: 0.6283 | Batch acc: 0.91\n",
      "  Step 1080/1169 | Loss: 0.5793 | Batch acc: 0.88\n",
      "  Step 1090/1169 | Loss: 0.5876 | Batch acc: 0.94\n",
      "  Step 1100/1169 | Loss: 0.5444 | Batch acc: 0.91\n",
      "  Step 1110/1169 | Loss: 0.4679 | Batch acc: 1.00\n",
      "  Step 1120/1169 | Loss: 0.7051 | Batch acc: 0.84\n",
      "  Step 1130/1169 | Loss: 0.8100 | Batch acc: 0.84\n",
      "  Step 1140/1169 | Loss: 0.8569 | Batch acc: 0.75\n",
      "  Step 1150/1169 | Loss: 0.5919 | Batch acc: 0.91\n",
      "  Step 1160/1169 | Loss: 0.4696 | Batch acc: 0.97\n",
      "Train: loss=0.6030, acc=0.906\n",
      "  Step 1/307 | Loss: 1.7031 | Batch acc: 0.38\n",
      "  Step 10/307 | Loss: 0.6332 | Batch acc: 0.84\n",
      "  Step 20/307 | Loss: 0.3557 | Batch acc: 1.00\n",
      "  Step 30/307 | Loss: 0.3472 | Batch acc: 1.00\n",
      "  Step 40/307 | Loss: 0.3492 | Batch acc: 1.00\n",
      "  Step 50/307 | Loss: 1.5667 | Batch acc: 0.06\n",
      "  Step 60/307 | Loss: 1.3082 | Batch acc: 0.31\n",
      "  Step 70/307 | Loss: 0.3913 | Batch acc: 1.00\n",
      "  Step 80/307 | Loss: 0.3494 | Batch acc: 1.00\n",
      "  Step 90/307 | Loss: 1.8215 | Batch acc: 0.28\n",
      "  Step 100/307 | Loss: 1.2676 | Batch acc: 0.56\n",
      "  Step 110/307 | Loss: 1.9532 | Batch acc: 0.16\n",
      "  Step 120/307 | Loss: 1.4482 | Batch acc: 0.62\n",
      "  Step 130/307 | Loss: 5.1213 | Batch acc: 0.09\n",
      "  Step 140/307 | Loss: 0.3966 | Batch acc: 1.00\n",
      "  Step 150/307 | Loss: 0.3787 | Batch acc: 1.00\n",
      "  Step 160/307 | Loss: 0.3878 | Batch acc: 1.00\n",
      "  Step 170/307 | Loss: 0.6906 | Batch acc: 0.81\n",
      "  Step 180/307 | Loss: 0.4399 | Batch acc: 1.00\n",
      "  Step 190/307 | Loss: 1.0456 | Batch acc: 0.81\n",
      "  Step 200/307 | Loss: 0.4394 | Batch acc: 0.97\n",
      "  Step 210/307 | Loss: 0.3401 | Batch acc: 1.00\n",
      "  Step 220/307 | Loss: 0.7325 | Batch acc: 0.84\n",
      "  Step 230/307 | Loss: 0.4288 | Batch acc: 0.97\n",
      "  Step 240/307 | Loss: 3.2030 | Batch acc: 0.06\n",
      "  Step 250/307 | Loss: 3.8944 | Batch acc: 0.16\n",
      "  Step 260/307 | Loss: 0.4510 | Batch acc: 1.00\n",
      "  Step 270/307 | Loss: 0.3637 | Batch acc: 1.00\n",
      "  Step 280/307 | Loss: 0.3551 | Batch acc: 1.00\n",
      "  Step 290/307 | Loss: 0.3597 | Batch acc: 1.00\n",
      "  Step 300/307 | Loss: 0.3585 | Batch acc: 1.00\n",
      "Val:   loss=0.9173, acc=0.761\n",
      "  ✅ New best model saved → /bhome/fwag/ele670_project/results/tiny_resnet50_best.pt (acc=0.761)\n",
      "\n",
      "Validation Confusion Matrix (rows=true, cols=pred):\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0   11    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    3    0    7    0   26    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    2    3    0    2    0  220  629    3  701    0    9   63   15]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0   18    0    0    0    0    8  131   11 6712    0  624   50   13]\n",
      " [   0    0    0    0    0    0   12    8    0   35    0    0    0    0]\n",
      " [   0    2    0    0    0    0    3   13    0  107    0  122   15    1]\n",
      " [   0    0    0    0    0    0    1  211    0   14    0    0   12    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Ampulla of Vater      0.000     0.000     0.000         0\n",
      "         Angiectasia      0.000     0.000     0.000        11\n",
      "       Blood - fresh      0.000     0.000     0.000         0\n",
      "     Blood - hematin      0.000     0.000     0.000         0\n",
      "             Erosion      0.000     0.000     0.000        36\n",
      "            Erythema      0.000     0.000     0.000         0\n",
      "        Foreign Body      0.000     0.000     0.000         0\n",
      "     Ileocecal valve      0.632     0.382     0.476      1647\n",
      "    Lymphangiectasia      0.000     0.000     0.000         0\n",
      " Normal clean mucosa      0.885     0.887     0.886      7567\n",
      "            class_10      0.000     0.000     0.000        55\n",
      "             Pylorus      0.156     0.464     0.234       263\n",
      "Reduced Mucosal View      0.086     0.050     0.063       239\n",
      "               Ulcer      0.000     0.000     0.000         0\n",
      "\n",
      "            accuracy                          0.761      9818\n",
      "           macro avg      0.126     0.127     0.119      9818\n",
      "        weighted avg      0.794     0.761     0.770      9818\n",
      "\n",
      "\n",
      "Training finished!\n",
      "Best validation accuracy: 0.761\n",
      "Elapsed time: 604.6 sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Tiny ResNet50 sanity trainer for Kvasir-Capsule (debug-friendly)\n",
    "# \n",
    "# * Beginner-friendly, heavily commented\n",
    "# * Safe, small training run (2 epochs) to check end-to-end wiring\n",
    "# * Works well on Tesla V100 (uses mixed precision)\n",
    "# * Video-independent split (by `video_id`) to avoid leakage\n",
    "# * Extra debug prints (device, memory, batch shapes, step logs)\n",
    "# * Optional: freeze backbone for very fast convergence of the classifier head\n",
    "# * Validation summary includes confusion matrix + per-class metrics\n",
    "# \n",
    "# ➕ Changes vs earlier cell:\n",
    "# - Uses **new AMP API**: `from torch import amp; amp.autocast('cuda')` to avoid deprecation warnings\n",
    "# - Adds **label smoothing** + optional **weight decay** for stability\n",
    "# - Adds **GPU-2 pinning** (can be disabled by setting GPU_INDEX=None)\n",
    "# - Adds **confusion matrix** + **classification report** after validation\n",
    "# \n",
    "# ---\n",
    "\n",
    "# %%\n",
    "import os, time, math, warnings\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch import amp\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CSV_PATH      = \"/bhome/fwag/ele670_project/data/processed/metadata_normalized.csv\"\n",
    "IMG_ROOT      = \"/bhome/fwag/ele670_project/data/raw/labelled_images\"\n",
    "RESULTS_DIR   = \"/bhome/fwag/ele670_project/results\"\n",
    "SAVE_PATH     = os.path.join(RESULTS_DIR, \"tiny_resnet50_best.pt\")\n",
    "\n",
    "IMG_SIZE      = 224\n",
    "BATCH_SIZE    = 32          # Try 64 or 96 if you want to use more VRAM\n",
    "NUM_WORKERS   = 6           # Tune for your server (4-12 typically fine)\n",
    "EPOCHS        = 2           # Keep it short for sanity checks\n",
    "LR            = 1e-3\n",
    "WEIGHT_DECAY  = 1e-4        # small regularization\n",
    "LABEL_SMOOTH  = 0.05        # improves stability a bit\n",
    "FREEZE_BACKBONE = True     # set True for super-fast head-only training\n",
    "USE_PRETRAINED = True       # use ImageNet weights to converge fast\n",
    "SEED          = 42\n",
    "\n",
    "# If you want to lock to a specific GPU (e.g., GPU 2), set this to an int.\n",
    "# Set to None to use the default CUDA device.\n",
    "GPU_INDEX     = 2\n",
    "\n",
    "# Log every N steps for train/val loops\n",
    "LOG_EVERY     = 10\n",
    "\n",
    "# ----------------------------------------\n",
    "# (1) Reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# (2) Pin to a specific GPU before creating tensors/models\n",
    "if torch.cuda.is_available() and GPU_INDEX is not None:\n",
    "    # Option A (recommended for notebooks): hide other GPUs so chosen one is cuda:0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "# After potentially setting CUDA_VISIBLE_DEVICES, re-check availability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"Allocated:\", round(torch.cuda.memory_allocated()/1024**3, 2), \"GB\")\n",
    "    print(\"Reserved: \", round(torch.cuda.memory_reserved()/1024**3, 2), \"GB\")\n",
    "\n",
    "# Create results directory if missing\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Enable cuDNN heuristics (faster for fixed shapes)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --------------- DATASET ----------------\n",
    "class KvasirDataset(Dataset):\n",
    "    \"\"\"Reads image paths + encoded labels from a dataframe.\n",
    "    \n",
    "    Returns (image_tensor, label_int).\n",
    "    If an image fails to load, returns a black placeholder and prints a warning.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        rel = row[\"image_path\"]\n",
    "        path = os.path.join(self.img_root, rel)\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, UnidentifiedImageError) as e:\n",
    "            print(f\"[WARNING] Failed to open {path}: {e}\")\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        x = self.transform(img)\n",
    "        y = int(row[\"encoded_label\"])  # already numeric\n",
    "        return x, y\n",
    "\n",
    "# --------------- LOAD CSV ----------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"First rows of metadata_normalized.csv:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic validations\n",
    "required_cols = {\"image_path\", \"encoded_label\", \"video_id\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "assert not missing, f\"CSV is missing required columns: {missing}\"\n",
    "\n",
    "num_classes = df[\"encoded_label\"].nunique()\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Try to recover (optional) human-readable names per label for metrics display\n",
    "# If multiple names map to same label, we pick the most frequent one in train split later.\n",
    "if \"finding_class\" in df.columns:\n",
    "    # Placeholder; will finalize names after split so we use train frequency\n",
    "    label_to_names = None\n",
    "else:\n",
    "    label_to_names = None\n",
    "\n",
    "# --------------- TRAIN/VAL SPLIT (video-independent) ----------------\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"video_id\"]))\n",
    "df_train, df_val = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()\n",
    "\n",
    "print(f\"Train samples: {len(df_train)} | Val samples: {len(df_val)}\")\n",
    "print(f\"Train videos: {df_train['video_id'].nunique()} | Val videos: {df_val['video_id'].nunique()}\")\n",
    "\n",
    "# Now finalize readable class names if available\n",
    "if \"finding_class\" in df.columns:\n",
    "    # Map each encoded_label to its most common finding_class in the TRAIN set\n",
    "    names = (\n",
    "        df_train.groupby([\"encoded_label\", \"finding_class\"]).size()\n",
    "        .reset_index(name=\"count\")\n",
    "        .sort_values([\"encoded_label\", \"count\"], ascending=[True, False])\n",
    "        .drop_duplicates(subset=[\"encoded_label\"])\n",
    "    )\n",
    "    label_to_names = dict(zip(names[\"encoded_label\"].astype(int), names[\"finding_class\"].astype(str)))\n",
    "else:\n",
    "    label_to_names = {i: f\"class_{i}\" for i in range(num_classes)}\n",
    "\n",
    "# --------------- TRANSFORMS ----------------\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# --------------- DATA LOADERS ----------------\n",
    "train_ds = KvasirDataset(df_train, IMG_ROOT, train_tf)\n",
    "val_ds   = KvasirDataset(df_val,   IMG_ROOT, val_tf)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=False\n",
    ")\n",
    "\n",
    "print(\"One training batch (images, labels):\")\n",
    "sample_imgs, sample_labels = next(iter(train_loader))\n",
    "print(\"Image batch shape:\", sample_imgs.shape)   # [B, 3, H, W]\n",
    "print(\"Label batch shape:\", sample_labels.shape) # [B]\n",
    "\n",
    "# --------------- MODEL ----------------\n",
    "if USE_PRETRAINED:\n",
    "    try:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "    except AttributeError:\n",
    "        weights = \"IMAGENET1K_V2\"\n",
    "    model = models.resnet50(weights=weights)\n",
    "else:\n",
    "    model = models.resnet50(weights=None)\n",
    "\n",
    "# Replace the classifier head to match your dataset\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Optionally freeze the backbone (train only the final classifier layer)\n",
    "if FREEZE_BACKBONE:\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# --------------- LOSS & OPTIMIZER ---------------\n",
    "# Label smoothing helps generalization slightly and prevents over-confident spikes\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Mixed precision scaler (new API)\n",
    "scaler = amp.GradScaler('cuda') if DEVICE == 'cuda' else None\n",
    "\n",
    "# --------------- TRAIN / EVAL HELPERS ---------------\n",
    "@torch.no_grad()\n",
    "def _accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    return (logits.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "def run_epoch(loader, train: bool = True, desc: str = \"train\"):\n",
    "    model.train(train)\n",
    "\n",
    "    total_loss, total_correct, total_seen = 0.0, 0, 0\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader, 1):\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        # Forward (mixed precision if on CUDA)\n",
    "        if DEVICE == 'cuda':\n",
    "            autocast_ctx = amp.autocast('cuda', enabled=True)\n",
    "        else:\n",
    "            # No AMP on CPU\n",
    "            from contextlib import nullcontext\n",
    "            autocast_ctx = nullcontext()\n",
    "\n",
    "        with autocast_ctx:\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler is not None:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Statistics (computed in full precision)\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct = (preds == labels).sum().item()\n",
    "            batch_sz = labels.size(0)\n",
    "            total_correct += correct\n",
    "            total_seen += batch_sz\n",
    "            total_loss += float(loss.item()) * batch_sz\n",
    "\n",
    "        # Debug print\n",
    "        if step % LOG_EVERY == 0 or step == 1:\n",
    "            batch_acc = correct / batch_sz\n",
    "            print(f\"  Step {step}/{len(loader)} | Loss: {loss.item():.4f} | Batch acc: {batch_acc:.2f}\")\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_seen)\n",
    "    avg_acc  = total_correct / max(1, total_seen)\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def collect_predictions(loader):\n",
    "    \"\"\"Run model in eval mode and collect logits/labels for metrics.\n",
    "    Returns: y_true (np.array), y_pred (np.array)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            if DEVICE == 'cuda':\n",
    "                with amp.autocast('cuda', enabled=True):\n",
    "                    logits = model(images)\n",
    "            else:\n",
    "                logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_labels)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    return y_true, y_pred\n",
    "\n",
    "# --------------- TRAIN FOR A FEW EPOCHS ---------------\n",
    "print(\"\\n==== START TRAINING ====\\n\")\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True, desc=\"train\")\n",
    "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.3f}\")\n",
    "\n",
    "    vl_loss, vl_acc = run_epoch(val_loader, train=False, desc=\"val\")\n",
    "    print(f\"Val:   loss={vl_loss:.4f}, acc={vl_acc:.3f}\")\n",
    "\n",
    "    # Save best checkpoint\n",
    "    if vl_acc > best_val_acc:\n",
    "        best_val_acc = vl_acc\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  ✅ New best model saved → {SAVE_PATH} (acc={best_val_acc:.3f})\")\n",
    "\n",
    "    # After each epoch, print confusion matrix + classification report\n",
    "    y_true, y_pred = collect_predictions(val_loader)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    print(\"\\nValidation Confusion Matrix (rows=true, cols=pred):\")\n",
    "    # Pretty-print small CM; for large, you might want to save to file\n",
    "    with np.printoptions(threshold=200, linewidth=200):\n",
    "        print(cm)\n",
    "\n",
    "    target_names = [label_to_names.get(i, f\"class_{i}\") for i in range(num_classes)]\n",
    "    print(\"\\nPer-class metrics (validation):\")\n",
    "    print(classification_report(y_true, y_pred, labels=list(range(num_classes)), target_names=target_names, digits=3))\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(\"Best validation accuracy:\", round(best_val_acc, 3))\n",
    "print(\"Elapsed time: %.1f sec\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab3012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla V100-PCIE-32GB\n",
      "Allocated: 0.1 GB\n",
      "Reserved:  0.41 GB\n",
      "First rows of metadata_normalized.csv:\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              7  \n",
      "1  0728084c8da942d9              7  \n",
      "2  0728084c8da942d9              7  \n",
      "3  0728084c8da942d9              7  \n",
      "4  0728084c8da942d9              7  \n",
      "Number of classes: 11\n",
      "Train samples: 37408 | Val samples: 9763\n",
      "Train videos: 34 | Val videos: 9\n",
      "Loaded 11 class names from /home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\n",
      "One training batch (images, labels):\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Label batch shape: torch.Size([32])\n",
      "\n",
      "==== START TRAINING ====\n",
      "\n",
      "\n",
      "Epoch 1/2\n",
      "  Step 1/1169 | Loss: 2.5986 | Batch acc: 0.03\n",
      "  Step 10/1169 | Loss: 0.9513 | Batch acc: 0.84\n",
      "  Step 20/1169 | Loss: 0.9631 | Batch acc: 0.84\n",
      "  Step 30/1169 | Loss: 1.2371 | Batch acc: 0.75\n",
      "  Step 40/1169 | Loss: 0.8889 | Batch acc: 0.88\n",
      "  Step 50/1169 | Loss: 1.3224 | Batch acc: 0.69\n",
      "  Step 60/1169 | Loss: 1.2462 | Batch acc: 0.69\n",
      "  Step 70/1169 | Loss: 1.1595 | Batch acc: 0.72\n",
      "  Step 80/1169 | Loss: 1.4152 | Batch acc: 0.66\n",
      "  Step 90/1169 | Loss: 1.3908 | Batch acc: 0.62\n",
      "  Step 100/1169 | Loss: 0.7551 | Batch acc: 0.91\n",
      "  Step 110/1169 | Loss: 0.8768 | Batch acc: 0.81\n",
      "  Step 120/1169 | Loss: 0.9027 | Batch acc: 0.81\n",
      "  Step 130/1169 | Loss: 0.9441 | Batch acc: 0.72\n",
      "  Step 140/1169 | Loss: 0.8187 | Batch acc: 0.75\n",
      "  Step 150/1169 | Loss: 0.8277 | Batch acc: 0.88\n",
      "  Step 160/1169 | Loss: 0.9141 | Batch acc: 0.78\n",
      "  Step 170/1169 | Loss: 0.7697 | Batch acc: 0.84\n",
      "  Step 180/1169 | Loss: 0.7732 | Batch acc: 0.78\n",
      "  Step 190/1169 | Loss: 0.7971 | Batch acc: 0.81\n",
      "  Step 200/1169 | Loss: 0.8423 | Batch acc: 0.84\n",
      "  Step 210/1169 | Loss: 0.8377 | Batch acc: 0.78\n",
      "  Step 220/1169 | Loss: 1.2076 | Batch acc: 0.56\n",
      "  Step 230/1169 | Loss: 0.9440 | Batch acc: 0.69\n",
      "  Step 240/1169 | Loss: 1.1873 | Batch acc: 0.56\n",
      "  Step 250/1169 | Loss: 0.7519 | Batch acc: 0.91\n",
      "  Step 260/1169 | Loss: 0.6536 | Batch acc: 0.88\n",
      "  Step 270/1169 | Loss: 0.8539 | Batch acc: 0.81\n",
      "  Step 280/1169 | Loss: 0.7006 | Batch acc: 0.88\n",
      "  Step 290/1169 | Loss: 0.7458 | Batch acc: 0.91\n",
      "  Step 300/1169 | Loss: 0.6896 | Batch acc: 0.81\n",
      "  Step 310/1169 | Loss: 0.8741 | Batch acc: 0.81\n",
      "  Step 320/1169 | Loss: 0.9013 | Batch acc: 0.72\n",
      "  Step 330/1169 | Loss: 0.7289 | Batch acc: 0.84\n",
      "  Step 340/1169 | Loss: 0.7062 | Batch acc: 0.88\n",
      "  Step 350/1169 | Loss: 0.6512 | Batch acc: 0.91\n",
      "  Step 360/1169 | Loss: 0.6537 | Batch acc: 0.88\n",
      "  Step 370/1169 | Loss: 0.7245 | Batch acc: 0.81\n",
      "  Step 380/1169 | Loss: 0.7499 | Batch acc: 0.81\n",
      "  Step 390/1169 | Loss: 0.7732 | Batch acc: 0.81\n",
      "  Step 400/1169 | Loss: 0.5116 | Batch acc: 0.94\n",
      "  Step 410/1169 | Loss: 0.6908 | Batch acc: 0.88\n",
      "  Step 420/1169 | Loss: 0.6338 | Batch acc: 0.88\n",
      "  Step 430/1169 | Loss: 0.5842 | Batch acc: 0.94\n",
      "  Step 440/1169 | Loss: 0.5884 | Batch acc: 0.91\n",
      "  Step 450/1169 | Loss: 0.8397 | Batch acc: 0.78\n",
      "  Step 460/1169 | Loss: 0.6986 | Batch acc: 0.88\n",
      "  Step 470/1169 | Loss: 0.6048 | Batch acc: 0.91\n",
      "  Step 480/1169 | Loss: 0.7068 | Batch acc: 0.84\n",
      "  Step 490/1169 | Loss: 0.7571 | Batch acc: 0.81\n",
      "  Step 500/1169 | Loss: 0.6742 | Batch acc: 0.84\n",
      "  Step 510/1169 | Loss: 0.5759 | Batch acc: 0.91\n",
      "  Step 520/1169 | Loss: 0.7327 | Batch acc: 0.88\n",
      "  Step 530/1169 | Loss: 0.9768 | Batch acc: 0.69\n",
      "  Step 540/1169 | Loss: 0.7171 | Batch acc: 0.91\n",
      "  Step 550/1169 | Loss: 0.6504 | Batch acc: 0.84\n",
      "  Step 560/1169 | Loss: 0.6615 | Batch acc: 0.88\n",
      "  Step 570/1169 | Loss: 0.7840 | Batch acc: 0.75\n",
      "  Step 580/1169 | Loss: 0.7041 | Batch acc: 0.84\n",
      "  Step 590/1169 | Loss: 0.8416 | Batch acc: 0.84\n",
      "  Step 600/1169 | Loss: 0.7519 | Batch acc: 0.81\n",
      "  Step 610/1169 | Loss: 0.7894 | Batch acc: 0.78\n",
      "  Step 620/1169 | Loss: 0.7400 | Batch acc: 0.84\n",
      "  Step 630/1169 | Loss: 0.8401 | Batch acc: 0.78\n",
      "  Step 640/1169 | Loss: 1.0388 | Batch acc: 0.69\n",
      "  Step 650/1169 | Loss: 0.5251 | Batch acc: 0.91\n",
      "  Step 660/1169 | Loss: 0.6007 | Batch acc: 0.84\n",
      "  Step 670/1169 | Loss: 0.9898 | Batch acc: 0.78\n",
      "  Step 680/1169 | Loss: 0.6974 | Batch acc: 0.81\n",
      "  Step 690/1169 | Loss: 0.8627 | Batch acc: 0.78\n",
      "  Step 700/1169 | Loss: 0.6515 | Batch acc: 0.94\n",
      "  Step 710/1169 | Loss: 0.7650 | Batch acc: 0.78\n",
      "  Step 720/1169 | Loss: 0.9319 | Batch acc: 0.84\n",
      "  Step 730/1169 | Loss: 0.5297 | Batch acc: 0.97\n",
      "  Step 740/1169 | Loss: 0.9044 | Batch acc: 0.72\n",
      "  Step 750/1169 | Loss: 0.8072 | Batch acc: 0.78\n",
      "  Step 760/1169 | Loss: 0.6709 | Batch acc: 0.84\n",
      "  Step 770/1169 | Loss: 0.5710 | Batch acc: 0.94\n",
      "  Step 780/1169 | Loss: 0.8377 | Batch acc: 0.72\n",
      "  Step 790/1169 | Loss: 0.6338 | Batch acc: 0.84\n",
      "  Step 800/1169 | Loss: 0.7187 | Batch acc: 0.81\n",
      "  Step 810/1169 | Loss: 0.5693 | Batch acc: 0.97\n",
      "  Step 820/1169 | Loss: 0.6458 | Batch acc: 0.91\n",
      "  Step 830/1169 | Loss: 0.6442 | Batch acc: 0.81\n",
      "  Step 840/1169 | Loss: 0.6510 | Batch acc: 0.88\n",
      "  Step 850/1169 | Loss: 0.6727 | Batch acc: 0.84\n",
      "  Step 860/1169 | Loss: 0.7114 | Batch acc: 0.91\n",
      "  Step 870/1169 | Loss: 0.6673 | Batch acc: 0.88\n",
      "  Step 880/1169 | Loss: 0.6362 | Batch acc: 0.88\n",
      "  Step 890/1169 | Loss: 0.5638 | Batch acc: 0.91\n",
      "  Step 900/1169 | Loss: 0.5410 | Batch acc: 0.94\n",
      "  Step 910/1169 | Loss: 0.4856 | Batch acc: 1.00\n",
      "  Step 920/1169 | Loss: 0.5251 | Batch acc: 0.94\n",
      "  Step 930/1169 | Loss: 0.8100 | Batch acc: 0.81\n",
      "  Step 940/1169 | Loss: 0.6323 | Batch acc: 0.91\n",
      "  Step 950/1169 | Loss: 0.4792 | Batch acc: 0.94\n",
      "  Step 960/1169 | Loss: 0.6123 | Batch acc: 0.88\n",
      "  Step 970/1169 | Loss: 0.6523 | Batch acc: 0.91\n",
      "  Step 980/1169 | Loss: 0.6004 | Batch acc: 0.81\n",
      "  Step 990/1169 | Loss: 0.8642 | Batch acc: 0.78\n",
      "  Step 1000/1169 | Loss: 0.5774 | Batch acc: 0.91\n",
      "  Step 1010/1169 | Loss: 0.6340 | Batch acc: 0.88\n",
      "  Step 1020/1169 | Loss: 0.7606 | Batch acc: 0.84\n",
      "  Step 1030/1169 | Loss: 0.6052 | Batch acc: 0.94\n",
      "  Step 1040/1169 | Loss: 0.6914 | Batch acc: 0.84\n",
      "  Step 1050/1169 | Loss: 0.4899 | Batch acc: 0.94\n",
      "  Step 1060/1169 | Loss: 0.5378 | Batch acc: 0.88\n",
      "  Step 1070/1169 | Loss: 0.7250 | Batch acc: 0.88\n",
      "  Step 1080/1169 | Loss: 0.5717 | Batch acc: 0.91\n",
      "  Step 1090/1169 | Loss: 0.5584 | Batch acc: 0.91\n",
      "  Step 1100/1169 | Loss: 0.6720 | Batch acc: 0.94\n",
      "  Step 1110/1169 | Loss: 0.7366 | Batch acc: 0.84\n",
      "  Step 1120/1169 | Loss: 0.4440 | Batch acc: 0.97\n",
      "  Step 1130/1169 | Loss: 0.5727 | Batch acc: 0.88\n",
      "  Step 1140/1169 | Loss: 0.7850 | Batch acc: 0.78\n",
      "  Step 1150/1169 | Loss: 0.5372 | Batch acc: 0.97\n",
      "  Step 1160/1169 | Loss: 0.5854 | Batch acc: 0.91\n",
      "Train: loss=0.7678, acc=0.839\n",
      "  Step 1/306 | Loss: 1.7083 | Batch acc: 0.38\n",
      "  Step 10/306 | Loss: 0.6412 | Batch acc: 0.88\n",
      "  Step 20/306 | Loss: 0.3348 | Batch acc: 1.00\n",
      "  Step 30/306 | Loss: 0.3313 | Batch acc: 1.00\n",
      "  Step 40/306 | Loss: 0.3389 | Batch acc: 1.00\n",
      "  Step 50/306 | Loss: 0.9675 | Batch acc: 0.66\n",
      "  Step 60/306 | Loss: 1.0873 | Batch acc: 0.50\n",
      "  Step 70/306 | Loss: 0.3867 | Batch acc: 1.00\n",
      "  Step 80/306 | Loss: 0.3319 | Batch acc: 1.00\n",
      "  Step 90/306 | Loss: 2.1648 | Batch acc: 0.06\n",
      "  Step 100/306 | Loss: 1.2979 | Batch acc: 0.66\n",
      "  Step 110/306 | Loss: 1.9222 | Batch acc: 0.22\n",
      "  Step 120/306 | Loss: 1.6266 | Batch acc: 0.44\n",
      "  Step 130/306 | Loss: 1.0588 | Batch acc: 0.69\n",
      "  Step 140/306 | Loss: 0.5774 | Batch acc: 0.94\n",
      "  Step 150/306 | Loss: 0.4190 | Batch acc: 0.97\n",
      "  Step 160/306 | Loss: 0.3691 | Batch acc: 1.00\n",
      "  Step 170/306 | Loss: 0.7915 | Batch acc: 0.75\n",
      "  Step 180/306 | Loss: 0.4716 | Batch acc: 1.00\n",
      "  Step 190/306 | Loss: 0.8984 | Batch acc: 0.75\n",
      "  Step 200/306 | Loss: 0.4285 | Batch acc: 1.00\n",
      "  Step 210/306 | Loss: 0.3419 | Batch acc: 1.00\n",
      "  Step 220/306 | Loss: 0.7129 | Batch acc: 0.88\n",
      "  Step 230/306 | Loss: 0.5579 | Batch acc: 0.97\n",
      "  Step 240/306 | Loss: 2.6023 | Batch acc: 0.03\n",
      "  Step 250/306 | Loss: 3.0413 | Batch acc: 0.00\n",
      "  Step 260/306 | Loss: 0.3955 | Batch acc: 1.00\n",
      "  Step 270/306 | Loss: 0.3785 | Batch acc: 1.00\n",
      "  Step 280/306 | Loss: 0.3643 | Batch acc: 1.00\n",
      "  Step 290/306 | Loss: 0.3324 | Batch acc: 1.00\n",
      "  Step 300/306 | Loss: 0.3393 | Batch acc: 1.00\n",
      "Val:   loss=0.8789, acc=0.757\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best.pt (acc=0.757)\n",
      "\n",
      "Validation Confusion Matrix (rows=true, cols=pred):\n",
      "[[   0    0    0    0    0    0    0   11    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    1    4    0   18   12    0    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3    1    0    0  376  497    3  662    1   59   45]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  15    0    0    0   35  116   23 6821  489   54   14]\n",
      " [   1    0    0    0   36   14    0  125   67   17    3]\n",
      " [   0    0    0    0    5  203    0   17    0   10    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         Angiectasia      0.000     0.000     0.000        11\n",
      "       Blood - fresh      0.000     0.000     0.000         0\n",
      "             Erosion      0.000     0.000     0.000        36\n",
      "            Erythema      0.000     0.000     0.000         0\n",
      "        Foreign Body      0.000     0.000     0.000         0\n",
      "     Ileocecal valve      0.596     0.302     0.401      1647\n",
      "    Lymphangiectasia      0.000     0.000     0.000         0\n",
      " Normal clean mucosa      0.891     0.901     0.896      7567\n",
      "             Pylorus      0.118     0.255     0.161       263\n",
      "Reduced Mucosal View      0.071     0.042     0.053       239\n",
      "               Ulcer      0.000     0.000     0.000         0\n",
      "\n",
      "            accuracy                          0.757      9763\n",
      "           macro avg      0.152     0.136     0.137      9763\n",
      "        weighted avg      0.796     0.757     0.768      9763\n",
      "\n",
      "\n",
      "Epoch 2/2\n",
      "  Step 1/1169 | Loss: 0.5882 | Batch acc: 0.84\n",
      "  Step 10/1169 | Loss: 0.6664 | Batch acc: 0.88\n",
      "  Step 20/1169 | Loss: 0.5070 | Batch acc: 0.94\n",
      "  Step 30/1169 | Loss: 0.6282 | Batch acc: 0.84\n",
      "  Step 40/1169 | Loss: 0.4660 | Batch acc: 0.97\n",
      "  Step 50/1169 | Loss: 0.4440 | Batch acc: 0.94\n",
      "  Step 60/1169 | Loss: 0.5836 | Batch acc: 0.94\n",
      "  Step 70/1169 | Loss: 0.6036 | Batch acc: 0.84\n",
      "  Step 80/1169 | Loss: 0.6775 | Batch acc: 0.88\n",
      "  Step 90/1169 | Loss: 0.5401 | Batch acc: 0.94\n",
      "  Step 100/1169 | Loss: 0.5312 | Batch acc: 0.94\n",
      "  Step 110/1169 | Loss: 0.6764 | Batch acc: 0.81\n",
      "  Step 120/1169 | Loss: 0.6598 | Batch acc: 0.91\n",
      "  Step 130/1169 | Loss: 0.4753 | Batch acc: 0.94\n",
      "  Step 140/1169 | Loss: 0.4117 | Batch acc: 1.00\n",
      "  Step 150/1169 | Loss: 0.7853 | Batch acc: 0.81\n",
      "  Step 160/1169 | Loss: 0.5883 | Batch acc: 0.94\n",
      "  Step 170/1169 | Loss: 0.5502 | Batch acc: 0.94\n",
      "  Step 180/1169 | Loss: 0.5407 | Batch acc: 0.94\n",
      "  Step 190/1169 | Loss: 0.8533 | Batch acc: 0.75\n",
      "  Step 200/1169 | Loss: 0.6057 | Batch acc: 0.91\n",
      "  Step 210/1169 | Loss: 0.4489 | Batch acc: 0.97\n",
      "  Step 220/1169 | Loss: 0.8366 | Batch acc: 0.78\n",
      "  Step 230/1169 | Loss: 0.4263 | Batch acc: 1.00\n",
      "  Step 240/1169 | Loss: 0.5613 | Batch acc: 0.94\n",
      "  Step 250/1169 | Loss: 0.4104 | Batch acc: 1.00\n",
      "  Step 260/1169 | Loss: 0.6429 | Batch acc: 0.88\n",
      "  Step 270/1169 | Loss: 0.6247 | Batch acc: 0.88\n",
      "  Step 280/1169 | Loss: 0.7493 | Batch acc: 0.84\n",
      "  Step 290/1169 | Loss: 0.4911 | Batch acc: 0.97\n",
      "  Step 300/1169 | Loss: 0.5740 | Batch acc: 0.94\n",
      "  Step 310/1169 | Loss: 0.5902 | Batch acc: 0.91\n",
      "  Step 320/1169 | Loss: 0.6423 | Batch acc: 0.88\n",
      "  Step 330/1169 | Loss: 0.5474 | Batch acc: 0.91\n",
      "  Step 340/1169 | Loss: 0.4817 | Batch acc: 0.97\n",
      "  Step 350/1169 | Loss: 0.7197 | Batch acc: 0.81\n",
      "  Step 360/1169 | Loss: 0.4764 | Batch acc: 0.97\n",
      "  Step 370/1169 | Loss: 0.5957 | Batch acc: 0.94\n",
      "  Step 380/1169 | Loss: 0.5896 | Batch acc: 0.88\n",
      "  Step 390/1169 | Loss: 0.6374 | Batch acc: 0.94\n",
      "  Step 400/1169 | Loss: 0.5162 | Batch acc: 0.94\n",
      "  Step 410/1169 | Loss: 0.4485 | Batch acc: 0.97\n",
      "  Step 420/1169 | Loss: 0.6269 | Batch acc: 0.94\n",
      "  Step 430/1169 | Loss: 0.6128 | Batch acc: 0.84\n",
      "  Step 440/1169 | Loss: 0.4823 | Batch acc: 0.94\n",
      "  Step 450/1169 | Loss: 0.5861 | Batch acc: 0.84\n",
      "  Step 460/1169 | Loss: 0.6243 | Batch acc: 0.94\n",
      "  Step 470/1169 | Loss: 0.4537 | Batch acc: 1.00\n",
      "  Step 480/1169 | Loss: 0.6066 | Batch acc: 0.94\n",
      "  Step 490/1169 | Loss: 0.7908 | Batch acc: 0.81\n",
      "  Step 500/1169 | Loss: 0.6387 | Batch acc: 0.91\n",
      "  Step 510/1169 | Loss: 0.6184 | Batch acc: 0.88\n",
      "  Step 520/1169 | Loss: 0.5520 | Batch acc: 0.88\n",
      "  Step 530/1169 | Loss: 0.5844 | Batch acc: 0.94\n",
      "  Step 540/1169 | Loss: 0.6126 | Batch acc: 0.91\n",
      "  Step 550/1169 | Loss: 0.5103 | Batch acc: 0.94\n",
      "  Step 560/1169 | Loss: 0.5306 | Batch acc: 0.91\n",
      "  Step 570/1169 | Loss: 0.3796 | Batch acc: 1.00\n",
      "  Step 580/1169 | Loss: 0.6947 | Batch acc: 0.91\n",
      "  Step 590/1169 | Loss: 0.8222 | Batch acc: 0.78\n",
      "  Step 600/1169 | Loss: 0.4649 | Batch acc: 0.97\n",
      "  Step 610/1169 | Loss: 0.5971 | Batch acc: 0.91\n",
      "  Step 620/1169 | Loss: 0.5188 | Batch acc: 0.88\n",
      "  Step 630/1169 | Loss: 0.6279 | Batch acc: 0.94\n",
      "  Step 640/1169 | Loss: 0.5727 | Batch acc: 0.94\n",
      "  Step 650/1169 | Loss: 0.6689 | Batch acc: 0.88\n",
      "  Step 660/1169 | Loss: 0.4321 | Batch acc: 0.97\n",
      "  Step 670/1169 | Loss: 0.4769 | Batch acc: 0.94\n",
      "  Step 680/1169 | Loss: 0.7218 | Batch acc: 0.84\n",
      "  Step 690/1169 | Loss: 0.5393 | Batch acc: 0.97\n",
      "  Step 700/1169 | Loss: 0.7575 | Batch acc: 0.84\n",
      "  Step 710/1169 | Loss: 0.6458 | Batch acc: 0.88\n",
      "  Step 720/1169 | Loss: 0.6610 | Batch acc: 0.91\n",
      "  Step 730/1169 | Loss: 0.4490 | Batch acc: 0.94\n",
      "  Step 740/1169 | Loss: 0.6691 | Batch acc: 0.91\n",
      "  Step 750/1169 | Loss: 0.5592 | Batch acc: 0.88\n",
      "  Step 760/1169 | Loss: 0.5584 | Batch acc: 0.88\n",
      "  Step 770/1169 | Loss: 0.4654 | Batch acc: 0.97\n",
      "  Step 780/1169 | Loss: 0.5216 | Batch acc: 0.91\n",
      "  Step 790/1169 | Loss: 0.5831 | Batch acc: 0.91\n",
      "  Step 800/1169 | Loss: 0.4759 | Batch acc: 0.94\n",
      "  Step 810/1169 | Loss: 0.5688 | Batch acc: 0.84\n",
      "  Step 820/1169 | Loss: 0.6439 | Batch acc: 0.88\n",
      "  Step 830/1169 | Loss: 0.5034 | Batch acc: 0.94\n",
      "  Step 840/1169 | Loss: 0.5002 | Batch acc: 0.97\n",
      "  Step 850/1169 | Loss: 0.6226 | Batch acc: 0.91\n",
      "  Step 860/1169 | Loss: 0.5203 | Batch acc: 0.97\n",
      "  Step 870/1169 | Loss: 0.8092 | Batch acc: 0.84\n",
      "  Step 880/1169 | Loss: 0.6685 | Batch acc: 0.81\n",
      "  Step 890/1169 | Loss: 0.5385 | Batch acc: 0.97\n",
      "  Step 900/1169 | Loss: 0.6021 | Batch acc: 0.88\n",
      "  Step 910/1169 | Loss: 0.4931 | Batch acc: 1.00\n",
      "  Step 920/1169 | Loss: 0.4792 | Batch acc: 0.94\n",
      "  Step 930/1169 | Loss: 0.5382 | Batch acc: 0.94\n",
      "  Step 940/1169 | Loss: 0.5244 | Batch acc: 0.97\n",
      "  Step 950/1169 | Loss: 0.7272 | Batch acc: 0.84\n",
      "  Step 960/1169 | Loss: 0.5158 | Batch acc: 0.91\n",
      "  Step 970/1169 | Loss: 0.5482 | Batch acc: 0.94\n",
      "  Step 980/1169 | Loss: 0.5401 | Batch acc: 0.91\n",
      "  Step 990/1169 | Loss: 0.5883 | Batch acc: 0.88\n",
      "  Step 1000/1169 | Loss: 0.5443 | Batch acc: 0.88\n",
      "  Step 1010/1169 | Loss: 0.5068 | Batch acc: 0.94\n",
      "  Step 1020/1169 | Loss: 0.5379 | Batch acc: 0.94\n",
      "  Step 1030/1169 | Loss: 0.6081 | Batch acc: 0.88\n",
      "  Step 1040/1169 | Loss: 0.7161 | Batch acc: 0.84\n",
      "  Step 1050/1169 | Loss: 0.5745 | Batch acc: 0.91\n",
      "  Step 1060/1169 | Loss: 0.6414 | Batch acc: 0.91\n",
      "  Step 1070/1169 | Loss: 0.5715 | Batch acc: 0.94\n",
      "  Step 1080/1169 | Loss: 0.6346 | Batch acc: 0.88\n",
      "  Step 1090/1169 | Loss: 0.5694 | Batch acc: 0.88\n",
      "  Step 1100/1169 | Loss: 0.7057 | Batch acc: 0.78\n",
      "  Step 1110/1169 | Loss: 0.5964 | Batch acc: 0.81\n",
      "  Step 1120/1169 | Loss: 0.4858 | Batch acc: 0.97\n",
      "  Step 1130/1169 | Loss: 0.5143 | Batch acc: 0.91\n",
      "  Step 1140/1169 | Loss: 0.5165 | Batch acc: 0.94\n",
      "  Step 1150/1169 | Loss: 0.4360 | Batch acc: 0.97\n",
      "  Step 1160/1169 | Loss: 0.4221 | Batch acc: 0.97\n",
      "Train: loss=0.5802, acc=0.907\n",
      "  Step 1/306 | Loss: 1.6239 | Batch acc: 0.38\n",
      "  Step 10/306 | Loss: 0.6200 | Batch acc: 0.84\n",
      "  Step 20/306 | Loss: 0.3363 | Batch acc: 1.00\n",
      "  Step 30/306 | Loss: 0.3360 | Batch acc: 1.00\n",
      "  Step 40/306 | Loss: 0.3276 | Batch acc: 1.00\n",
      "  Step 50/306 | Loss: 1.3168 | Batch acc: 0.25\n",
      "  Step 60/306 | Loss: 1.0293 | Batch acc: 0.62\n",
      "  Step 70/306 | Loss: 0.3533 | Batch acc: 1.00\n",
      "  Step 80/306 | Loss: 0.3386 | Batch acc: 1.00\n",
      "  Step 90/306 | Loss: 1.7870 | Batch acc: 0.25\n",
      "  Step 100/306 | Loss: 1.1185 | Batch acc: 0.69\n",
      "  Step 110/306 | Loss: 1.9040 | Batch acc: 0.16\n",
      "  Step 120/306 | Loss: 1.3882 | Batch acc: 0.59\n",
      "  Step 130/306 | Loss: 0.8352 | Batch acc: 0.88\n",
      "  Step 140/306 | Loss: 0.4987 | Batch acc: 0.97\n",
      "  Step 150/306 | Loss: 0.4680 | Batch acc: 1.00\n",
      "  Step 160/306 | Loss: 0.3402 | Batch acc: 1.00\n",
      "  Step 170/306 | Loss: 0.8514 | Batch acc: 0.72\n",
      "  Step 180/306 | Loss: 0.5261 | Batch acc: 0.94\n",
      "  Step 190/306 | Loss: 0.9376 | Batch acc: 0.81\n",
      "  Step 200/306 | Loss: 0.3989 | Batch acc: 1.00\n",
      "  Step 210/306 | Loss: 0.3404 | Batch acc: 1.00\n",
      "  Step 220/306 | Loss: 0.4513 | Batch acc: 0.97\n",
      "  Step 230/306 | Loss: 0.3665 | Batch acc: 1.00\n",
      "  Step 240/306 | Loss: 2.8398 | Batch acc: 0.00\n",
      "  Step 250/306 | Loss: 2.5936 | Batch acc: 0.03\n",
      "  Step 260/306 | Loss: 0.4109 | Batch acc: 1.00\n",
      "  Step 270/306 | Loss: 0.3619 | Batch acc: 1.00\n",
      "  Step 280/306 | Loss: 0.3437 | Batch acc: 1.00\n",
      "  Step 290/306 | Loss: 0.3273 | Batch acc: 1.00\n",
      "  Step 300/306 | Loss: 0.3523 | Batch acc: 1.00\n",
      "Val:   loss=0.8511, acc=0.773\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best.pt (acc=0.773)\n",
      "\n",
      "Validation Confusion Matrix (rows=true, cols=pred):\n",
      "[[   0    0    0    0    0    0    0   11    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    4    0   21   11    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    2    0  213  634    1  692    2   87   15]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   4    0    0    0   13  146    1 6806  528   54   15]\n",
      " [   0    0    0    0    8   17    0  124   98   15    1]\n",
      " [   0    0    0    0    1  219    0   12    0    7    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         Angiectasia      0.000     0.000     0.000        11\n",
      "       Blood - fresh      0.000     0.000     0.000         0\n",
      "             Erosion      0.000     0.000     0.000        36\n",
      "            Erythema      0.000     0.000     0.000         0\n",
      "        Foreign Body      0.000     0.000     0.000         0\n",
      "     Ileocecal valve      0.622     0.385     0.475      1647\n",
      "    Lymphangiectasia      0.000     0.000     0.000         0\n",
      " Normal clean mucosa      0.888     0.899     0.894      7567\n",
      "             Pylorus      0.153     0.373     0.217       263\n",
      "Reduced Mucosal View      0.043     0.029     0.035       239\n",
      "               Ulcer      0.000     0.000     0.000         0\n",
      "\n",
      "            accuracy                          0.773      9763\n",
      "           macro avg      0.155     0.153     0.147      9763\n",
      "        weighted avg      0.798     0.773     0.780      9763\n",
      "\n",
      "\n",
      "Training finished!\n",
      "Best validation accuracy: 0.773\n",
      "Elapsed time: 146.1 sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Tiny ResNet50 sanity trainer for Kvasir-Capsule (debug-friendly)\n",
    "# \n",
    "# * Beginner-friendly, **now extremely commented**\n",
    "# * Safe, small training run (2 epochs) to check end-to-end wiring\n",
    "# * Works well on Tesla V100 (uses mixed precision)\n",
    "# * Video-independent split (by `video_id`) to avoid leakage\n",
    "# * Extra debug prints (device, memory, batch shapes, step logs)\n",
    "# * Optional: freeze backbone for very fast convergence of the classifier head\n",
    "# * Validation summary includes confusion matrix + per-class metrics\n",
    "# \n",
    "# ➕ Changes vs earlier cell:\n",
    "# - Uses **new AMP API**: `from torch import amp; amp.autocast('cuda')` to avoid deprecation warnings\n",
    "# - Adds **label smoothing** + optional **weight decay** for stability\n",
    "# - Adds **GPU-2 pinning** (can be disabled by setting GPU_INDEX=None)\n",
    "# - Adds **confusion matrix** + **classification report** after validation\n",
    "# \n",
    "# NOTE: The logic below is *unchanged*; only comments were added for clarity.\n",
    "\n",
    "# %%\n",
    "# -------------------------\n",
    "# Standard library imports\n",
    "# -------------------------\n",
    "# os       : filesystem paths, environment variables (e.g., CUDA_VISIBLE_DEVICES)\n",
    "# time     : simple wall-clock timing of the whole train run\n",
    "# math     : not strictly needed here, but often handy for schedulers, etc.\n",
    "# warnings : to silence benign warnings for a cleaner notebook output\n",
    "import os, time, math, warnings\n",
    "from collections import Counter  # (not used below, but often useful for label histograms)\n",
    "\n",
    "# -------------------------\n",
    "# Third-party imports\n",
    "# -------------------------\n",
    "# pandas      : reading the metadata CSV with image paths / labels / groups\n",
    "# numpy       : CPU-side numeric ops, array concatenation for metrics\n",
    "# PIL.Image   : robust image loading; handles various formats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# -------------------------\n",
    "# PyTorch / TorchVision\n",
    "# -------------------------\n",
    "# torch             : tensors, autograd, CUDA utils\n",
    "# torch.nn          : neural network layers + loss functions\n",
    "# DataLoader        : mini-batching, shuffling, prefetching with workers\n",
    "# torchvision       : common transforms and pretrained CNN backbones\n",
    "# amp               : Automatic Mixed Precision for speed + memory savings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch import amp\n",
    "\n",
    "# -------------------------\n",
    "# Scikit-learn utilities\n",
    "# -------------------------\n",
    "# GroupShuffleSplit : ensures train/val split is **video-independent** (group = video_id)\n",
    "# Metrics           : confusion matrix + per-class precision/recall/F1 report\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Silence overly chatty user warnings (e.g., PIL/torchvision), keeps output readable.\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# ========================\n",
    "# CONFIGURATION CONSTANTS\n",
    "# ========================\n",
    "# Paths to data and outputs. Adjust these to your environment.\n",
    "# Paths to data and outputs. Adjust these to your environment.\n",
    "CSV_PATH      = \"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_filtered.csv\"\n",
    "IMG_ROOT      = \"/home/stud/fwag/bhome/ele670_project/data/raw/labelled_images\"\n",
    "RESULTS_DIR   = \"/home/stud/fwag/bhome/ele670_project/results\"\n",
    "SAVE_PATH     = os.path.join(RESULTS_DIR, \"tiny_resnet50_best.pt\")\n",
    "\n",
    "# Optional: path to class-name mapping saved by LabelEncoder during preprocessing\n",
    "LABELS_NPY    = \"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\"\n",
    "\n",
    "# Core training hyperparameters\n",
    "IMG_SIZE      = 224           # input resolution expected by ResNet50\n",
    "BATCH_SIZE    = 32            # try 64/96 if VRAM allows; affects throughput + stability\n",
    "NUM_WORKERS   = 6             # dataloader subprocesses; tune for server CPU\n",
    "EPOCHS        = 2             # keep short for sanity runs; increase when confident\n",
    "LR            = 1e-3          # Adam learning rate\n",
    "WEIGHT_DECAY  = 1e-4          # small L2 regularization for generalization\n",
    "LABEL_SMOOTH  = 0.05          # reduces overconfidence; helps class-imbalance a bit\n",
    "FREEZE_BACKBONE = True        # train only final FC layer for a *very* fast sanity pass\n",
    "USE_PRETRAINED = True         # start from ImageNet weights for quick convergence\n",
    "SEED          = 42            # reproducibility (affects split/shuffle/initialization)\n",
    "\n",
    "# Optional: pin training to a specific GPU index (e.g., GPU 2 on a multi-GPU server).\n",
    "# If None, uses default CUDA device selection.\n",
    "GPU_INDEX     = 2\n",
    "\n",
    "# How often to print batch-level logs during training/validation loops\n",
    "LOG_EVERY     = 10\n",
    "\n",
    "# ----------------------------\n",
    "# (1) Reproducibility seeding\n",
    "# ----------------------------\n",
    "torch.manual_seed(SEED)  # torch RNG seed (CPU + CUDA if available)\n",
    "np.random.seed(SEED)     # numpy RNG seed\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# (2) Pin to a specific GPU *before* constructing CUDA objects\n",
    "# -----------------------------------------------------------\n",
    "# Best practice in notebooks: mask other GPUs so the chosen one looks like cuda:0\n",
    "if torch.cuda.is_available() and GPU_INDEX is not None:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "# Now, after potentially masking devices, re-detect CUDA availability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    # Report which GPU and current memory state; helps verify the right GPU is in use.\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"Allocated:\", round(torch.cuda.memory_allocated()/1024**3, 2), \"GB\")\n",
    "    print(\"Reserved: \", round(torch.cuda.memory_reserved()/1024**3, 2), \"GB\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Enable cudNN autotuner: faster convs when input shapes are static (typical in CV)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    # Slightly faster matmul kernels on Ampere+; safe to ignore if unsupported\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ========================\n",
    "# DATASET IMPLEMENTATION\n",
    "# ========================\n",
    "class KvasirDataset(Dataset):\n",
    "    \"\"\"Thin PyTorch Dataset wrapper around a DataFrame of image rows.\n",
    "    \n",
    "    Each row must contain:\n",
    "    - image_path     : relative path to the image file on disk (under IMG_ROOT)\n",
    "    - encoded_label  : integer class id (0..num_classes-1)\n",
    "    \n",
    "    Returns (image_tensor, label_int) for each index. If an image fails to load,\n",
    "    we emit a warning and return a black placeholder to keep the batch shapes valid.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str, transform):\n",
    "        # Keep a defensive copy with consecutive indices\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Required for PyTorch to know how many items are in the dataset\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Index into the DataFrame to fetch the sample\n",
    "        row = self.df.iloc[idx]\n",
    "        rel = row[\"image_path\"]  # relative path under IMG_ROOT\n",
    "        path = os.path.join(self.img_root, rel)\n",
    "        try:\n",
    "            # Open image robustly and convert to 3-channel RGB\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, UnidentifiedImageError) as e:\n",
    "            # If the file is missing or corrupted, warn and provide a dummy image\n",
    "            print(f\"[WARNING] Failed to open {path}: {e}\")\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        # Apply torchvision transforms (resize, flip, tensorize, normalize)\n",
    "        x = self.transform(img)\n",
    "        # Labels are expected to already be numeric in the CSV\n",
    "        y = int(row[\"encoded_label\"])  # integer class id\n",
    "        return x, y\n",
    "\n",
    "# ==================\n",
    "# LOAD & VALIDATE CSV\n",
    "# ==================\n",
    "# The CSV is expected to contain at least: image_path, encoded_label, video_id\n",
    "# (finding_class is optional, used only for pretty printing class names later.)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"First rows of metadata_normalized.csv:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic schema checks to fail fast if the CSV is malformed\n",
    "required_cols = {\"image_path\", \"encoded_label\", \"video_id\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "assert not missing, f\"CSV is missing required columns: {missing}\"\n",
    "\n",
    "# Determine number of unique classes from the encoded label column\n",
    "num_classes = df[\"encoded_label\"].nunique()\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Prepare (optional) mapping from integer labels to human-readable names.\n",
    "# We'll finalize it *after* the split, using the most common name per label in TRAIN.\n",
    "if \"finding_class\" in df.columns:\n",
    "    label_to_names = None  # filled later from the training subset\n",
    "else:\n",
    "    label_to_names = None  # will default to generic names\n",
    "\n",
    "# ==============================================\n",
    "# TRAIN/VAL SPLIT — **VIDEO-INDEPENDENT** SPLIT\n",
    "# ==============================================\n",
    "# GroupShuffleSplit ensures all frames from the same video_id are kept together\n",
    "# (i.e., no leakage where the model sees frames of the same video in both splits.)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"video_id\"]))\n",
    "df_train, df_val = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()\n",
    "\n",
    "print(f\"Train samples: {len(df_train)} | Val samples: {len(df_val)}\")\n",
    "print(f\"Train videos: {df_train['video_id'].nunique()} | Val videos: {df_val['video_id'].nunique()}\")\n",
    "\n",
    "# --------------- LABEL NAMES (preferred: from LabelEncoder) ---------------\n",
    "# Try to load class names saved during preprocessing with scikit-learn's LabelEncoder.\n",
    "# This guarantees the names align EXACTLY with how `encoded_label` was produced.\n",
    "try:\n",
    "    classes = np.load(LABELS_NPY, allow_pickle=True)\n",
    "    label_to_names = {i: str(name) for i, name in enumerate(classes)}\n",
    "    print(f\"Loaded {len(label_to_names)} class names from {LABELS_NPY}\")\n",
    "except Exception as e:\n",
    "    # Graceful fallback: infer from TRAIN frequencies (previous behavior)\n",
    "    print(f\"[WARN] Could not load {LABELS_NPY} ({e}). Falling back to inferring from TRAIN.\")\n",
    "    if \"finding_class\" in df.columns:\n",
    "        names = (\n",
    "            df_train.groupby([\"encoded_label\", \"finding_class\"]).size()\n",
    "            .reset_index(name=\"count\")\n",
    "            .sort_values([\"encoded_label\", \"count\"], ascending=[True, False])\n",
    "            .drop_duplicates(subset=[\"encoded_label\"])  # keep top name per label\n",
    "        )\n",
    "        label_to_names = dict(zip(names[\"encoded_label\"].astype(int), names[\"finding_class\"].astype(str)))\n",
    "    else:\n",
    "        label_to_names = {i: f\"class_{i}\" for i in range(num_classes)}\n",
    "\n",
    "# =====================\n",
    "# IMAGE TRANSFORMATIONS\n",
    "# =====================\n",
    "# Standard ImageNet normalization statistics for ResNet-family backbones\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# TRAIN pipeline: deterministic resize → light augmentation → tensorize → normalize\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),  # helps against left/right biases and small dataset size\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# VAL pipeline: resize + normalization only (no randomness)\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# ==================\n",
    "# DATA LOADERS (PyTorch)\n",
    "# ==================\n",
    "# pin_memory=True: speeds up host→GPU transfers\n",
    "# persistent_workers=True: avoids worker restart overhead across epochs\n",
    "# prefetch_factor: how many batches each worker preloads; tune with NUM_WORKERS\n",
    "train_ds = KvasirDataset(df_train, IMG_ROOT, train_tf)\n",
    "val_ds   = KvasirDataset(df_val,   IMG_ROOT, val_tf)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=True  # drop_last=True for even batch shapes on AMP\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=False\n",
    ")\n",
    "\n",
    "# Quick sanity print to confirm tensor shapes and label dtype\n",
    "print(\"One training batch (images, labels):\")\n",
    "sample_imgs, sample_labels = next(iter(train_loader))\n",
    "print(\"Image batch shape:\", sample_imgs.shape)   # [B, 3, H, W]\n",
    "print(\"Label batch shape:\", sample_labels.shape) # [B]\n",
    "\n",
    "# ==============\n",
    "# MODEL DEFINITION\n",
    "# ==============\n",
    "# Load a ResNet50 backbone; optionally with ImageNet-1K weights for faster convergence.\n",
    "if USE_PRETRAINED:\n",
    "    try:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "    except AttributeError:\n",
    "        # TorchVision < 0.13 compatibility fallback\n",
    "        weights = \"IMAGENET1K_V2\"\n",
    "    model = models.resnet50(weights=weights)\n",
    "else:\n",
    "    model = models.resnet50(weights=None)\n",
    "\n",
    "# Replace the final classification head to match our dataset's class count\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Optionally freeze the convolutional backbone so only the final FC trains.\n",
    "# This is great for quick sanity checks; later you can unfreeze for full finetuning.\n",
    "if FREEZE_BACKBONE:\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "# Move the model to the chosen device (GPU or CPU)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ======================\n",
    "# LOSS FUNCTION & OPTIMIZER\n",
    "# ======================\n",
    "# CrossEntropyLoss with label-smoothing mitigates over-confident predictions and can\n",
    "# slightly improve generalization on small / imbalanced datasets.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
    "\n",
    "# Only optimize parameters that are marked as trainable (respects FREEZE_BACKBONE)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# AMP gradient scaler for stable mixed-precision training on CUDA\n",
    "scaler = amp.GradScaler('cuda') if DEVICE == 'cuda' else None\n",
    "\n",
    "# ======================\n",
    "# TRAIN / EVAL UTILITIES\n",
    "# ======================\n",
    "@torch.no_grad()\n",
    "def _accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    \"\"\"Compute top-1 accuracy for a batch (utility; not used in final printouts).\"\"\"\n",
    "    return (logits.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "def run_epoch(loader, train: bool = True, desc: str = \"train\"):\n",
    "    \"\"\"Runs one pass over a DataLoader.\n",
    "    \n",
    "    Args:\n",
    "      loader: DataLoader yielding (images, labels)\n",
    "      train : if True, updates model weights; if False, evaluation-only\n",
    "      desc  : string for logging (\"train\"/\"val\")\n",
    "    Returns:\n",
    "      (avg_loss, avg_accuracy)\n",
    "    \"\"\"\n",
    "    model.train(train)  # toggles dropout/batchnorm behavior as appropriate\n",
    "\n",
    "    total_loss, total_correct, total_seen = 0.0, 0, 0\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader, 1):\n",
    "        # Non-blocking copies overlap data transfer with compute on CUDA\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        # Create an autocast context for mixed precision on CUDA; CPU uses full precision\n",
    "        if DEVICE == 'cuda':\n",
    "            autocast_ctx = amp.autocast('cuda', enabled=True)\n",
    "        else:\n",
    "            from contextlib import nullcontext\n",
    "            autocast_ctx = nullcontext()\n",
    "\n",
    "        # Forward pass (mixed precision when enabled)\n",
    "        with autocast_ctx:\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        if train:\n",
    "            # Standard fused optimizer step; with AMP we scale/unscale grads to avoid underflow\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler is not None:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # --- Metrics bookkeeping in FP32 ---\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct = (preds == labels).sum().item()\n",
    "            batch_sz = labels.size(0)\n",
    "            total_correct += correct\n",
    "            total_seen += batch_sz\n",
    "            total_loss += float(loss.item()) * batch_sz  # sum of per-sample losses\n",
    "\n",
    "        # Periodic progress print for visibility\n",
    "        if step % LOG_EVERY == 0 or step == 1:\n",
    "            batch_acc = correct / batch_sz\n",
    "            print(f\"  Step {step}/{len(loader)} | Loss: {loss.item():.4f} | Batch acc: {batch_acc:.2f}\")\n",
    "\n",
    "    # Compute dataset-wide averages\n",
    "    avg_loss = total_loss / max(1, total_seen)\n",
    "    avg_acc  = total_correct / max(1, total_seen)\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def collect_predictions(loader):\n",
    "    \"\"\"Run the model in eval mode and collect all predictions + labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_true : np.ndarray of shape (N,)\n",
    "        Ground-truth integer labels for the entire split.\n",
    "    y_pred : np.ndarray of shape (N,)\n",
    "        Predicted class indices (argmax over logits) for the entire split.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            if DEVICE == 'cuda':\n",
    "                with amp.autocast('cuda', enabled=True):\n",
    "                    logits = model(images)\n",
    "            else:\n",
    "                logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Concatenate list of arrays into one long vector per side\n",
    "    y_true = np.concatenate(all_labels)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    return y_true, y_pred\n",
    "\n",
    "# ============================\n",
    "# MAIN TRAINING CONTROL-LOOP\n",
    "# ============================\n",
    "print(\"\\n==== START TRAINING ====\\n\")\n",
    "best_val_acc = 0.0  # track best validation accuracy to decide checkpointing\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    # One training epoch\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True, desc=\"train\")\n",
    "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.3f}\")\n",
    "\n",
    "    # One validation epoch (no weight updates)\n",
    "    vl_loss, vl_acc = run_epoch(val_loader, train=False, desc=\"val\")\n",
    "    print(f\"Val:   loss={vl_loss:.4f}, acc={vl_acc:.3f}\")\n",
    "\n",
    "    # Save a checkpoint if validation accuracy improved\n",
    "    if vl_acc > best_val_acc:\n",
    "        best_val_acc = vl_acc\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  ✅ New best model saved → {SAVE_PATH} (acc={best_val_acc:.3f})\")\n",
    "\n",
    "    # --- Post-epoch diagnostics on the validation split ---\n",
    "    y_true, y_pred = collect_predictions(val_loader)\n",
    "\n",
    "    # 1) Confusion matrix: rows = actual class, columns = predicted class\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    print(\"\\nValidation Confusion Matrix (rows=true, cols=pred):\")\n",
    "    # Pretty-print small matrices to console; for large K consider saving to file\n",
    "    with np.printoptions(threshold=200, linewidth=200):\n",
    "        print(cm)\n",
    "\n",
    "    # 2) Per-class precision/recall/F1 (macro/weighted) with human-friendly names\n",
    "    target_names = [label_to_names.get(i, f\"class_{i}\") for i in range(num_classes)]\n",
    "    print(\"\\nPer-class metrics (validation):\")\n",
    "    print(classification_report(y_true, y_pred,\n",
    "                                labels=list(range(num_classes)),\n",
    "                                target_names=target_names,\n",
    "                                digits=3))\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(\"Best validation accuracy:\", round(best_val_acc, 3))\n",
    "print(\"Elapsed time: %.1f sec\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45fef151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla V100-PCIE-32GB\n",
      "Loaded metadata:\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              7  \n",
      "1  0728084c8da942d9              7  \n",
      "2  0728084c8da942d9              7  \n",
      "3  0728084c8da942d9              7  \n",
      "4  0728084c8da942d9              7  \n",
      "Number of classes: 11\n",
      "Train samples: 37408 | Val samples: 9763\n",
      "\n",
      "[STRAT] per-class distribution and deviations:\n",
      " label_id           class_name  global_count  global_pct  train_count  train_pct  train_abs_dev_pp  train_rel_dev_%  val_count  val_pct  val_abs_dev_pp  val_rel_dev_%\n",
      "        0          Angiectasia           866       1.836          855      2.286             0.450             24.5         11    0.113           1.723           93.9\n",
      "        1        Blood - fresh           446       0.945          446      1.192             0.247             26.1          0    0.000           0.945          100.0\n",
      "        2              Erosion           507       1.075          471      1.259             0.184             17.1         36    0.369           0.706           65.7\n",
      "        3             Erythema           159       0.337          159      0.425             0.088             26.1          0    0.000           0.337          100.0\n",
      "        4         Foreign Body           776       1.645          776      2.074             0.429             26.1          0    0.000           1.645          100.0\n",
      "        5      Ileocecal valve          4189       8.880         2542      6.795             2.085             23.5       1647   16.870           7.989           90.0\n",
      "        6     Lymphangiectasia           592       1.255          592      1.583             0.328             26.1          0    0.000           1.255          100.0\n",
      "        7  Normal clean mucosa         34338      72.795        26771     71.565             1.230              1.7       7567   77.507           4.712            6.5\n",
      "        8              Pylorus          1538       3.260         1275      3.408             0.148              4.5        263    2.694           0.567           17.4\n",
      "        9 Reduced Mucosal View          2906       6.161         2667      7.129             0.969             15.7        239    2.448           3.713           60.3\n",
      "       10                Ulcer           854       1.810          854      2.283             0.472             26.1          0    0.000           1.810          100.0\n",
      "\n",
      "[STRAT][SUMMARY]\n",
      "  Zero-support classes: TRAIN=0 | VAL=5\n",
      "  Train: mean abs dev = 0.60 pp | max abs dev = 2.09 pp | JSD = 0.0015\n",
      "  Val  : mean abs dev = 2.31 pp | max abs dev = 7.99 pp | JSD = 0.0372\n",
      "  ⚠️  Val split has classes with support=0 — metrics for those classes are undefined. Consider a class-aware grouped split.\n",
      "[STRAT] saved → /home/stud/fwag/bhome/ele670_project/results/stratification_report_weighted_cb_beta0.99_gss.csv\n",
      "[WEIGHTS] mode=class_balanced  ->  min=1.000, max=1.254\n",
      "\n",
      "[CHECK] Train counts and weights used by loss:\n",
      " label_id           class_name  count_train   weight\n",
      "        3             Erythema          159 1.253604\n",
      "        1        Blood - fresh          446 1.011435\n",
      "        2              Erosion          471 1.008872\n",
      "        6     Lymphangiectasia          592 1.002613\n",
      "        4         Foreign Body          776 1.000410\n",
      "       10                Ulcer          854 1.000187\n",
      "        0          Angiectasia          855 1.000185\n",
      "        8              Pylorus         1275 1.000003\n",
      "        5      Ileocecal valve         2542 1.000000\n",
      "        7  Normal clean mucosa        26771 1.000000\n",
      "        9 Reduced Mucosal View         2667 1.000000\n",
      "\n",
      "==== START TRAINING (Weighted Loss) ====\n",
      "\n",
      "\n",
      "Epoch 1/2\n",
      "  [train] step 1/1169 | loss=2.4959\n",
      "  [train] step 10/1169 | loss=1.5466\n",
      "  [train] step 20/1169 | loss=1.2040\n",
      "  [train] step 30/1169 | loss=0.8978\n",
      "  [train] step 40/1169 | loss=1.3094\n",
      "  [train] step 50/1169 | loss=1.1116\n",
      "  [train] step 60/1169 | loss=0.9727\n",
      "  [train] step 70/1169 | loss=1.0770\n",
      "  [train] step 80/1169 | loss=1.0448\n",
      "  [train] step 90/1169 | loss=1.2515\n",
      "  [train] step 100/1169 | loss=0.8009\n",
      "  [train] step 110/1169 | loss=1.0881\n",
      "  [train] step 120/1169 | loss=0.9838\n",
      "  [train] step 130/1169 | loss=0.7835\n",
      "  [train] step 140/1169 | loss=1.0385\n",
      "  [train] step 150/1169 | loss=0.8065\n",
      "  [train] step 160/1169 | loss=1.1675\n",
      "  [train] step 170/1169 | loss=0.9723\n",
      "  [train] step 180/1169 | loss=0.8435\n",
      "  [train] step 190/1169 | loss=1.2020\n",
      "  [train] step 200/1169 | loss=0.9176\n",
      "  [train] step 210/1169 | loss=0.8222\n",
      "  [train] step 220/1169 | loss=1.0690\n",
      "  [train] step 230/1169 | loss=1.1342\n",
      "  [train] step 240/1169 | loss=1.0632\n",
      "  [train] step 250/1169 | loss=1.0347\n",
      "  [train] step 260/1169 | loss=0.7427\n",
      "  [train] step 270/1169 | loss=0.7999\n",
      "  [train] step 280/1169 | loss=0.5751\n",
      "  [train] step 290/1169 | loss=0.7717\n",
      "  [train] step 300/1169 | loss=0.8842\n",
      "  [train] step 310/1169 | loss=0.6716\n",
      "  [train] step 320/1169 | loss=0.8010\n",
      "  [train] step 330/1169 | loss=0.7761\n",
      "  [train] step 340/1169 | loss=0.7460\n",
      "  [train] step 350/1169 | loss=1.0668\n",
      "  [train] step 360/1169 | loss=0.7734\n",
      "  [train] step 370/1169 | loss=0.7080\n",
      "  [train] step 380/1169 | loss=0.4774\n",
      "  [train] step 390/1169 | loss=1.0244\n",
      "  [train] step 400/1169 | loss=0.7222\n",
      "  [train] step 410/1169 | loss=0.6516\n",
      "  [train] step 420/1169 | loss=0.7883\n",
      "  [train] step 430/1169 | loss=0.7098\n",
      "  [train] step 440/1169 | loss=1.0185\n",
      "  [train] step 450/1169 | loss=0.9939\n",
      "  [train] step 460/1169 | loss=0.8286\n",
      "  [train] step 470/1169 | loss=0.6186\n",
      "  [train] step 480/1169 | loss=0.5256\n",
      "  [train] step 490/1169 | loss=0.5981\n",
      "  [train] step 500/1169 | loss=0.7246\n",
      "  [train] step 510/1169 | loss=0.9050\n",
      "  [train] step 520/1169 | loss=0.8208\n",
      "  [train] step 530/1169 | loss=0.7008\n",
      "  [train] step 540/1169 | loss=0.5748\n",
      "  [train] step 550/1169 | loss=0.6650\n",
      "  [train] step 560/1169 | loss=0.6029\n",
      "  [train] step 570/1169 | loss=0.6902\n",
      "  [train] step 580/1169 | loss=0.8305\n",
      "  [train] step 590/1169 | loss=0.4452\n",
      "  [train] step 600/1169 | loss=0.5592\n",
      "  [train] step 610/1169 | loss=0.6073\n",
      "  [train] step 620/1169 | loss=0.8155\n",
      "  [train] step 630/1169 | loss=0.6373\n",
      "  [train] step 640/1169 | loss=0.6777\n",
      "  [train] step 650/1169 | loss=0.5658\n",
      "  [train] step 660/1169 | loss=0.9512\n",
      "  [train] step 670/1169 | loss=0.6974\n",
      "  [train] step 680/1169 | loss=0.8535\n",
      "  [train] step 690/1169 | loss=0.8465\n",
      "  [train] step 700/1169 | loss=0.6957\n",
      "  [train] step 710/1169 | loss=0.7063\n",
      "  [train] step 720/1169 | loss=0.8144\n",
      "  [train] step 730/1169 | loss=0.7973\n",
      "  [train] step 740/1169 | loss=0.7234\n",
      "  [train] step 750/1169 | loss=0.6120\n",
      "  [train] step 760/1169 | loss=0.6557\n",
      "  [train] step 770/1169 | loss=0.6245\n",
      "  [train] step 780/1169 | loss=0.5784\n",
      "  [train] step 790/1169 | loss=0.7732\n",
      "  [train] step 800/1169 | loss=0.8338\n",
      "  [train] step 810/1169 | loss=0.8116\n",
      "  [train] step 820/1169 | loss=0.5549\n",
      "  [train] step 830/1169 | loss=0.9135\n",
      "  [train] step 840/1169 | loss=0.7350\n",
      "  [train] step 850/1169 | loss=1.0593\n",
      "  [train] step 860/1169 | loss=0.5967\n",
      "  [train] step 870/1169 | loss=0.6111\n",
      "  [train] step 880/1169 | loss=0.7474\n",
      "  [train] step 890/1169 | loss=0.5975\n",
      "  [train] step 900/1169 | loss=0.7211\n",
      "  [train] step 910/1169 | loss=0.8148\n",
      "  [train] step 920/1169 | loss=0.8446\n",
      "  [train] step 930/1169 | loss=0.6009\n",
      "  [train] step 940/1169 | loss=0.7364\n",
      "  [train] step 950/1169 | loss=0.8963\n",
      "  [train] step 960/1169 | loss=0.4674\n",
      "  [train] step 970/1169 | loss=0.5169\n",
      "  [train] step 980/1169 | loss=0.6525\n",
      "  [train] step 990/1169 | loss=0.6046\n",
      "  [train] step 1000/1169 | loss=0.5615\n",
      "  [train] step 1010/1169 | loss=0.7723\n",
      "  [train] step 1020/1169 | loss=0.5584\n",
      "  [train] step 1030/1169 | loss=0.5131\n",
      "  [train] step 1040/1169 | loss=0.7692\n",
      "  [train] step 1050/1169 | loss=0.6129\n",
      "  [train] step 1060/1169 | loss=0.6226\n",
      "  [train] step 1070/1169 | loss=0.6737\n",
      "  [train] step 1080/1169 | loss=0.6805\n",
      "  [train] step 1090/1169 | loss=0.4637\n",
      "  [train] step 1100/1169 | loss=0.5102\n",
      "  [train] step 1110/1169 | loss=0.8039\n",
      "  [train] step 1120/1169 | loss=0.6836\n",
      "  [train] step 1130/1169 | loss=0.5470\n",
      "  [train] step 1140/1169 | loss=0.5915\n",
      "  [train] step 1150/1169 | loss=0.5688\n",
      "  [train] step 1160/1169 | loss=0.5319\n",
      "Train: loss=0.7746, acc=0.840\n",
      "  [val] step 1/306 | loss=1.7660\n",
      "  [val] step 10/306 | loss=0.6200\n",
      "  [val] step 20/306 | loss=0.3459\n",
      "  [val] step 30/306 | loss=0.3435\n",
      "  [val] step 40/306 | loss=0.3452\n",
      "  [val] step 50/306 | loss=0.9369\n",
      "  [val] step 60/306 | loss=0.6954\n",
      "  [val] step 70/306 | loss=0.3681\n",
      "  [val] step 80/306 | loss=0.3342\n",
      "  [val] step 90/306 | loss=2.0664\n",
      "  [val] step 100/306 | loss=1.4360\n",
      "  [val] step 110/306 | loss=2.1884\n",
      "  [val] step 120/306 | loss=1.6636\n",
      "  [val] step 130/306 | loss=1.1496\n",
      "  [val] step 140/306 | loss=0.4154\n",
      "  [val] step 150/306 | loss=0.4120\n",
      "  [val] step 160/306 | loss=0.3561\n",
      "  [val] step 170/306 | loss=0.8485\n",
      "  [val] step 180/306 | loss=0.4731\n",
      "  [val] step 190/306 | loss=0.7684\n",
      "  [val] step 200/306 | loss=0.4284\n",
      "  [val] step 210/306 | loss=0.3434\n",
      "  [val] step 220/306 | loss=0.5319\n",
      "  [val] step 230/306 | loss=0.4553\n",
      "  [val] step 240/306 | loss=2.3737\n",
      "  [val] step 250/306 | loss=3.3355\n",
      "  [val] step 260/306 | loss=0.3923\n",
      "  [val] step 270/306 | loss=0.3618\n",
      "  [val] step 280/306 | loss=0.3358\n",
      "  [val] step 290/306 | loss=0.3312\n",
      "  [val] step 300/306 | loss=0.3287\n",
      "Val:   loss=0.8536, acc=0.772\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best_weighted.pt (acc=0.772)\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   0    0    0    0    0    0    0   11    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    3    0   24    9    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    6    0    0  149  461    3  886    2   79   61]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    1    8  105    9 6999  371   44   24]\n",
      " [   0    1    0    0   12   11    0  162   54   20    3]\n",
      " [   0    0    0    0    0  183    0   24    0   21   11]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        11\n",
      "           1      0.000     0.000     0.000         0\n",
      "           2      0.000     0.000     0.000        36\n",
      "           3      0.000     0.000     0.000         0\n",
      "           4      0.000     0.000     0.000         0\n",
      "           5      0.604     0.280     0.383      1647\n",
      "           6      0.000     0.000     0.000         0\n",
      "           7      0.863     0.925     0.893      7567\n",
      "           8      0.124     0.205     0.155       263\n",
      "           9      0.128     0.088     0.104       239\n",
      "          10      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.772      9763\n",
      "   macro avg      0.156     0.136     0.139      9763\n",
      "weighted avg      0.778     0.772     0.763      9763\n",
      "\n",
      "Macro-F1: 0.139 | Balanced Acc: 0.250\n",
      "\n",
      "Epoch 2/2\n",
      "  [train] step 1/1169 | loss=0.6474\n",
      "  [train] step 10/1169 | loss=0.5882\n",
      "  [train] step 20/1169 | loss=0.5087\n",
      "  [train] step 30/1169 | loss=0.5699\n",
      "  [train] step 40/1169 | loss=0.6033\n",
      "  [train] step 50/1169 | loss=0.5984\n",
      "  [train] step 60/1169 | loss=0.8381\n",
      "  [train] step 70/1169 | loss=0.4684\n",
      "  [train] step 80/1169 | loss=0.5063\n",
      "  [train] step 90/1169 | loss=0.6464\n",
      "  [train] step 100/1169 | loss=0.5364\n",
      "  [train] step 110/1169 | loss=0.6015\n",
      "  [train] step 120/1169 | loss=0.5981\n",
      "  [train] step 130/1169 | loss=0.5802\n",
      "  [train] step 140/1169 | loss=0.4551\n",
      "  [train] step 150/1169 | loss=0.5207\n",
      "  [train] step 160/1169 | loss=0.6291\n",
      "  [train] step 170/1169 | loss=0.6482\n",
      "  [train] step 180/1169 | loss=0.4914\n",
      "  [train] step 190/1169 | loss=0.6594\n",
      "  [train] step 200/1169 | loss=0.5491\n",
      "  [train] step 210/1169 | loss=0.5806\n",
      "  [train] step 220/1169 | loss=0.5223\n",
      "  [train] step 230/1169 | loss=0.7041\n",
      "  [train] step 240/1169 | loss=0.5132\n",
      "  [train] step 250/1169 | loss=0.8916\n",
      "  [train] step 260/1169 | loss=0.7442\n",
      "  [train] step 270/1169 | loss=0.4264\n",
      "  [train] step 280/1169 | loss=0.6833\n",
      "  [train] step 290/1169 | loss=0.5051\n",
      "  [train] step 300/1169 | loss=0.5410\n",
      "  [train] step 310/1169 | loss=0.5730\n",
      "  [train] step 320/1169 | loss=0.5911\n",
      "  [train] step 330/1169 | loss=0.5372\n",
      "  [train] step 340/1169 | loss=0.6477\n",
      "  [train] step 350/1169 | loss=0.6411\n",
      "  [train] step 360/1169 | loss=0.6431\n",
      "  [train] step 370/1169 | loss=0.4683\n",
      "  [train] step 380/1169 | loss=0.5496\n",
      "  [train] step 390/1169 | loss=0.6322\n",
      "  [train] step 400/1169 | loss=0.7256\n",
      "  [train] step 410/1169 | loss=0.4732\n",
      "  [train] step 420/1169 | loss=0.5736\n",
      "  [train] step 430/1169 | loss=0.6632\n",
      "  [train] step 440/1169 | loss=0.4737\n",
      "  [train] step 450/1169 | loss=0.6983\n",
      "  [train] step 460/1169 | loss=0.6712\n",
      "  [train] step 470/1169 | loss=0.6995\n",
      "  [train] step 480/1169 | loss=0.5154\n",
      "  [train] step 490/1169 | loss=0.6864\n",
      "  [train] step 500/1169 | loss=0.6053\n",
      "  [train] step 510/1169 | loss=0.4565\n",
      "  [train] step 520/1169 | loss=0.5588\n",
      "  [train] step 530/1169 | loss=0.6140\n",
      "  [train] step 540/1169 | loss=0.7408\n",
      "  [train] step 550/1169 | loss=0.5901\n",
      "  [train] step 560/1169 | loss=0.5705\n",
      "  [train] step 570/1169 | loss=0.5018\n",
      "  [train] step 580/1169 | loss=0.5116\n",
      "  [train] step 590/1169 | loss=0.5156\n",
      "  [train] step 600/1169 | loss=0.8226\n",
      "  [train] step 610/1169 | loss=0.5261\n",
      "  [train] step 620/1169 | loss=0.5087\n",
      "  [train] step 630/1169 | loss=0.5311\n",
      "  [train] step 640/1169 | loss=0.5156\n",
      "  [train] step 650/1169 | loss=0.8432\n",
      "  [train] step 660/1169 | loss=0.4862\n",
      "  [train] step 670/1169 | loss=0.4517\n",
      "  [train] step 680/1169 | loss=0.5635\n",
      "  [train] step 690/1169 | loss=0.5395\n",
      "  [train] step 700/1169 | loss=0.5608\n",
      "  [train] step 710/1169 | loss=0.6300\n",
      "  [train] step 720/1169 | loss=0.6943\n",
      "  [train] step 730/1169 | loss=0.5720\n",
      "  [train] step 740/1169 | loss=0.5719\n",
      "  [train] step 750/1169 | loss=0.5567\n",
      "  [train] step 760/1169 | loss=0.5285\n",
      "  [train] step 770/1169 | loss=0.5461\n",
      "  [train] step 780/1169 | loss=0.7061\n",
      "  [train] step 790/1169 | loss=0.4674\n",
      "  [train] step 800/1169 | loss=0.5421\n",
      "  [train] step 810/1169 | loss=0.5609\n",
      "  [train] step 820/1169 | loss=0.5444\n",
      "  [train] step 830/1169 | loss=0.4597\n",
      "  [train] step 840/1169 | loss=0.4621\n",
      "  [train] step 850/1169 | loss=0.4603\n",
      "  [train] step 860/1169 | loss=0.7709\n",
      "  [train] step 870/1169 | loss=0.5433\n",
      "  [train] step 880/1169 | loss=0.5982\n",
      "  [train] step 890/1169 | loss=0.5819\n",
      "  [train] step 900/1169 | loss=0.4859\n",
      "  [train] step 910/1169 | loss=0.7933\n",
      "  [train] step 920/1169 | loss=0.6921\n",
      "  [train] step 930/1169 | loss=0.5689\n",
      "  [train] step 940/1169 | loss=0.6934\n",
      "  [train] step 950/1169 | loss=0.6922\n",
      "  [train] step 960/1169 | loss=0.6131\n",
      "  [train] step 970/1169 | loss=0.5845\n",
      "  [train] step 980/1169 | loss=0.6079\n",
      "  [train] step 990/1169 | loss=0.4462\n",
      "  [train] step 1000/1169 | loss=0.5401\n",
      "  [train] step 1010/1169 | loss=0.5567\n",
      "  [train] step 1020/1169 | loss=0.4927\n",
      "  [train] step 1030/1169 | loss=0.7444\n",
      "  [train] step 1040/1169 | loss=0.5179\n",
      "  [train] step 1050/1169 | loss=0.4948\n",
      "  [train] step 1060/1169 | loss=0.6467\n",
      "  [train] step 1070/1169 | loss=0.5490\n",
      "  [train] step 1080/1169 | loss=0.5308\n",
      "  [train] step 1090/1169 | loss=0.6043\n",
      "  [train] step 1100/1169 | loss=0.6003\n",
      "  [train] step 1110/1169 | loss=0.6138\n",
      "  [train] step 1120/1169 | loss=0.5276\n",
      "  [train] step 1130/1169 | loss=0.5657\n",
      "  [train] step 1140/1169 | loss=0.5714\n",
      "  [train] step 1150/1169 | loss=0.4560\n",
      "  [train] step 1160/1169 | loss=0.5214\n",
      "Train: loss=0.5892, acc=0.908\n",
      "  [val] step 1/306 | loss=1.7146\n",
      "  [val] step 10/306 | loss=0.6836\n",
      "  [val] step 20/306 | loss=0.3482\n",
      "  [val] step 30/306 | loss=0.3434\n",
      "  [val] step 40/306 | loss=0.3516\n",
      "  [val] step 50/306 | loss=1.3036\n",
      "  [val] step 60/306 | loss=1.2961\n",
      "  [val] step 70/306 | loss=0.3883\n",
      "  [val] step 80/306 | loss=0.3407\n",
      "  [val] step 90/306 | loss=2.1235\n",
      "  [val] step 100/306 | loss=1.2668\n",
      "  [val] step 110/306 | loss=2.2626\n",
      "  [val] step 120/306 | loss=1.5829\n",
      "  [val] step 130/306 | loss=0.9468\n",
      "  [val] step 140/306 | loss=0.4926\n",
      "  [val] step 150/306 | loss=0.4500\n",
      "  [val] step 160/306 | loss=0.3619\n",
      "  [val] step 170/306 | loss=0.8446\n",
      "  [val] step 180/306 | loss=0.5493\n",
      "  [val] step 190/306 | loss=0.9549\n",
      "  [val] step 200/306 | loss=0.4668\n",
      "  [val] step 210/306 | loss=0.3545\n",
      "  [val] step 220/306 | loss=0.6852\n",
      "  [val] step 230/306 | loss=0.5041\n",
      "  [val] step 240/306 | loss=2.5990\n",
      "  [val] step 250/306 | loss=2.7780\n",
      "  [val] step 260/306 | loss=0.4343\n",
      "  [val] step 270/306 | loss=0.4157\n",
      "  [val] step 280/306 | loss=0.3493\n",
      "  [val] step 290/306 | loss=0.3409\n",
      "  [val] step 300/306 | loss=0.3746\n",
      "Val:   loss=0.9071, acc=0.753\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   0    0    0    0    0    0    0   11    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    4    0   14   18    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    8    7    0  224  532    1  756   15   91   13]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  20    0    2    1   12  148   19 6687  598   66   14]\n",
      " [   0    0    0    0    3   16    0  108  118   17    1]\n",
      " [   0    0    0    0    2  206    0   18    0   11    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        11\n",
      "           1      0.000     0.000     0.000         0\n",
      "           2      0.000     0.000     0.000        36\n",
      "           3      0.000     0.000     0.000         0\n",
      "           4      0.000     0.000     0.000         0\n",
      "           5      0.587     0.323     0.417      1647\n",
      "           6      0.000     0.000     0.000         0\n",
      "           7      0.881     0.884     0.882      7567\n",
      "           8      0.158     0.449     0.233       263\n",
      "           9      0.059     0.046     0.052       239\n",
      "          10      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.753      9763\n",
      "   macro avg      0.153     0.155     0.144      9763\n",
      "weighted avg      0.787     0.753     0.762      9763\n",
      "\n",
      "Macro-F1: 0.144 | Balanced Acc: 0.284\n",
      "\n",
      "Training finished!\n",
      "Best validation accuracy: 0.772\n",
      "Elapsed time: 490.2 sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Tiny ResNet50 sanity trainer (weighted-loss + stratification diagnostics)\n",
    "# \n",
    "# Adds **class-weighted CrossEntropyLoss** to handle class imbalance and a\n",
    "# **stratification report** to quantify how well Train/Val match the global\n",
    "# label distribution (zero-support warnings, per-class deviations, JSD).\n",
    "# Everything else remains identical to the baseline trainer.\n",
    "#\n",
    "# - Uses class-balanced (effective number) or inverse-frequency weights on TRAIN.\n",
    "# - Keeps dataset and DataLoader unchanged (no oversampling).\n",
    "# - Preserves label smoothing.\n",
    "# - Prints confusion matrix + per-class metrics for analysis.\n",
    "# - Saves a CSV summary of stratification to RESULTS_DIR for easy comparisons.\n",
    "\n",
    "# %%\n",
    "# -------------------------\n",
    "# Standard library imports\n",
    "# -------------------------\n",
    "import os, time, math, warnings\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------\n",
    "# Third-party imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# -------------------------\n",
    "# PyTorch / TorchVision\n",
    "# -------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch import amp\n",
    "\n",
    "# -------------------------\n",
    "# Scikit-learn utilities\n",
    "# -------------------------\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, f1_score\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# ========================\n",
    "# CONFIGURATION CONSTANTS\n",
    "# ========================\n",
    "CSV_PATH      = \"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_filtered.csv\"\n",
    "IMG_ROOT      = \"/home/stud/fwag/bhome/ele670_project/data/raw/labelled_images\"\n",
    "RESULTS_DIR   = \"/home/stud/fwag/bhome/ele670_project/results\"\n",
    "SAVE_PATH     = os.path.join(RESULTS_DIR, \"tiny_resnet50_best_weighted.pt\")\n",
    "LABELS_NPY    = \"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\"\n",
    "\n",
    "# Optional: tag to differentiate experiment variants (appears in saved reports)\n",
    "EXPERIMENT_TAG = \"weighted_cb_beta0.99_gss\"\n",
    "\n",
    "IMG_SIZE      = 224\n",
    "BATCH_SIZE    = 32\n",
    "NUM_WORKERS   = 6\n",
    "EPOCHS        = 2   # for wiring/debug; consider 5–10 for clearer comparisons\n",
    "LR            = 1e-3\n",
    "WEIGHT_DECAY  = 1e-4\n",
    "LABEL_SMOOTH  = 0.05\n",
    "FREEZE_BACKBONE = True\n",
    "USE_PRETRAINED = True\n",
    "SEED          = 42\n",
    "GPU_INDEX     = 2\n",
    "LOG_EVERY     = 10\n",
    "\n",
    "# ----------------------------\n",
    "# (1) Reproducibility + GPU pinning\n",
    "# ----------------------------\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available() and GPU_INDEX is not None:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ========================\n",
    "# DATASET IMPLEMENTATION\n",
    "# ========================\n",
    "class KvasirDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(self.img_root, row[\"image_path\"])\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, UnidentifiedImageError):\n",
    "            print(f\"[WARN] Missing/corrupt: {path}\")\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        x = self.transform(img)\n",
    "        y = int(row[\"encoded_label\"])\n",
    "        return x, y\n",
    "\n",
    "# ==================\n",
    "# LOAD METADATA\n",
    "# ==================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Loaded metadata:\")\n",
    "print(df.head())\n",
    "\n",
    "num_classes = df[\"encoded_label\"].nunique()\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# ===========================\n",
    "# VIDEO-INDEPENDENT SPLIT\n",
    "# ===========================\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "train_idx, val_idx = next(gss.split(df, groups=df[\"video_id\"]))\n",
    "df_train, df_val = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()\n",
    "print(f\"Train samples: {len(df_train)} | Val samples: {len(df_val)}\")\n",
    "\n",
    "# ===============================\n",
    "# STRATIFICATION DIAGNOSTICS CELL\n",
    "# ===============================\n",
    "\n",
    "def _js_divergence(p, q, eps=1e-12):\n",
    "    p = np.asarray(p, dtype=np.float64); q = np.asarray(q, dtype=np.float64)\n",
    "    p = np.clip(p, eps, 1.0); q = np.clip(q, eps, 1.0)\n",
    "    p /= p.sum(); q /= q.sum(); m = 0.5 * (p + q)\n",
    "    kl_pm = np.sum(p * np.log(p / m)); kl_qm = np.sum(q * np.log(q / m))\n",
    "    return 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "\n",
    "def stratification_report(df_all, df_tr, df_va, label_col=\"encoded_label\", labels_npy_path=None, save_csv=None, tag=None):\n",
    "    # Global distribution\n",
    "    g_counts = df_all[label_col].value_counts().sort_index()\n",
    "    classes = g_counts.index.tolist()\n",
    "    g_probs  = (g_counts / g_counts.sum()).values\n",
    "\n",
    "    # Train distribution\n",
    "    t_counts = df_tr[label_col].value_counts().reindex(classes, fill_value=0)\n",
    "    t_probs  = (t_counts / max(1, t_counts.sum())).values\n",
    "\n",
    "    # Val distribution\n",
    "    v_counts = df_va[label_col].value_counts().reindex(classes, fill_value=0)\n",
    "    v_probs  = (v_counts / max(1, v_counts.sum())).values\n",
    "\n",
    "    # Deviations\n",
    "    t_abs_pp = np.abs(t_probs - g_probs) * 100.0\n",
    "    v_abs_pp = np.abs(v_probs - g_probs) * 100.0\n",
    "    denom = np.where(g_probs > 0, g_probs, np.nan)\n",
    "    t_rel = np.abs(t_probs - g_probs) / denom * 100.0\n",
    "    v_rel = np.abs(v_probs - g_probs) / denom * 100.0\n",
    "\n",
    "    # Optional class names\n",
    "    id2name = {i: f\"class_{i}\" for i in classes}\n",
    "    try:\n",
    "        if labels_npy_path is not None:\n",
    "            names = np.load(labels_npy_path, allow_pickle=True)\n",
    "            id2name = {i: str(names[i]) for i in classes}\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    tbl = pd.DataFrame({\n",
    "        \"label_id\": classes,\n",
    "        \"class_name\": [id2name[i] for i in classes],\n",
    "        \"global_count\": g_counts.values,\n",
    "        \"global_pct\": (g_probs * 100).round(3),\n",
    "        \"train_count\": t_counts.values,\n",
    "        \"train_pct\": (t_probs * 100).round(3),\n",
    "        \"train_abs_dev_pp\": t_abs_pp.round(3),\n",
    "        \"train_rel_dev_%\": np.where(np.isfinite(t_rel), t_rel, np.nan).round(1),\n",
    "        \"val_count\": v_counts.values,\n",
    "        \"val_pct\": (v_probs * 100).round(3),\n",
    "        \"val_abs_dev_pp\": v_abs_pp.round(3),\n",
    "        \"val_rel_dev_%\": np.where(np.isfinite(v_rel), v_rel, np.nan).round(1),\n",
    "    })\n",
    "\n",
    "    # Summary metrics\n",
    "    t_jsd = _js_divergence(g_probs, t_probs)\n",
    "    v_jsd = _js_divergence(g_probs, v_probs)\n",
    "    zero_train = int((t_counts.values == 0).sum())\n",
    "    zero_val   = int((v_counts.values == 0).sum())\n",
    "\n",
    "    print(\"\\n[STRAT] per-class distribution and deviations:\")\n",
    "    print(tbl.to_string(index=False, max_rows=200))\n",
    "\n",
    "    print(\"\\n[STRAT][SUMMARY]\")\n",
    "    print(f\"  Zero-support classes: TRAIN={zero_train} | VAL={zero_val}\")\n",
    "    print(f\"  Train: mean abs dev = {t_abs_pp.mean():.2f} pp | max abs dev = {t_abs_pp.max():.2f} pp | JSD = {t_jsd:.4f}\")\n",
    "    print(f\"  Val  : mean abs dev = {v_abs_pp.mean():.2f} pp | max abs dev = {v_abs_pp.max():.2f} pp | JSD = {v_jsd:.4f}\")\n",
    "    if zero_val > 0:\n",
    "        print(\"  ⚠️  Val split has classes with support=0 — metrics for those classes are undefined. Consider a class-aware grouped split.\")\n",
    "\n",
    "    if save_csv:\n",
    "        out = tbl.copy()\n",
    "        out.insert(0, \"experiment_tag\", tag if tag else \"\")\n",
    "        out.to_csv(save_csv, index=False)\n",
    "        print(f\"[STRAT] saved → {save_csv}\")\n",
    "\n",
    "    return {\n",
    "        \"table\": tbl,\n",
    "        \"train_jsd\": float(t_jsd),\n",
    "        \"val_jsd\": float(v_jsd),\n",
    "        \"train_mean_abs_pp\": float(t_abs_pp.mean()),\n",
    "        \"val_mean_abs_pp\": float(v_abs_pp.mean()),\n",
    "        \"zero_train\": zero_train,\n",
    "        \"zero_val\": zero_val,\n",
    "    }\n",
    "\n",
    "# Run diagnostics and persist CSV for experiment tracking\n",
    "_ = stratification_report(\n",
    "    df_all=df, df_tr=df_train, df_va=df_val,\n",
    "    label_col=\"encoded_label\",\n",
    "    labels_npy_path=LABELS_NPY,\n",
    "    save_csv=os.path.join(RESULTS_DIR, f\"stratification_report_{EXPERIMENT_TAG}.csv\"),\n",
    "    tag=EXPERIMENT_TAG,\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# TRANSFORMS & LOADERS\n",
    "# =====================\n",
    "mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_ds = KvasirDataset(df_train, IMG_ROOT, train_tf)\n",
    "val_ds   = KvasirDataset(df_val,   IMG_ROOT, val_tf)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4\n",
    ")\n",
    "\n",
    "# ==================\n",
    "# MODEL\n",
    "# ==================\n",
    "if USE_PRETRAINED:\n",
    "    try:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "    except AttributeError:\n",
    "        weights = \"IMAGENET1K_V2\"\n",
    "    model = models.resnet50(weights=weights)\n",
    "else:\n",
    "    model = models.resnet50(weights=None)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "if FREEZE_BACKBONE:\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ======================================\n",
    "# COMPUTE CLASS WEIGHTS (TRAIN SPLIT ONLY) — CLEAN & CONSISTENT\n",
    "# ======================================\n",
    "counts = df_train[\"encoded_label\"].value_counts().sort_index()\n",
    "counts_idx_sorted = counts\n",
    "N, K = counts_idx_sorted.sum(), len(counts_idx_sorted)\n",
    "\n",
    "# ----- Class-Balanced (effective number) weights -----\n",
    "beta = 0.99  # try 0.995 or 0.999 if imbalance is extreme\n",
    "eff = 1.0 - np.power(beta, counts_idx_sorted.values)\n",
    "cb_w = ((1.0 - beta) / np.maximum(eff, 1e-12)).astype(np.float32)\n",
    "cb_w = cb_w / cb_w.min()\n",
    "\n",
    "# (Optional) inverse-frequency for reference/ablation\n",
    "inv_w = (N / (K * counts_idx_sorted.values)).astype(np.float32)\n",
    "inv_w = inv_w / inv_w.min()\n",
    "\n",
    "# Pick which to use for training:\n",
    "WEIGHT_MODE = \"class_balanced\"  # or \"invfreq\"\n",
    "w = cb_w if WEIGHT_MODE == \"class_balanced\" else inv_w\n",
    "class_weights = torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "print(f\"[WEIGHTS] mode={WEIGHT_MODE}  ->  min={w.min():.3f}, max={w.max():.3f}\")\n",
    "\n",
    "# ----- Build readable table (aligned with what you actually use) -----\n",
    "try:\n",
    "    classes = np.load(LABELS_NPY, allow_pickle=True)\n",
    "    id2name = {i: str(n) for i, n in enumerate(classes)}\n",
    "except Exception:\n",
    "    id2name = {i: f\"class_{i}\" for i in range(len(w))}\n",
    "\n",
    "weights_table = pd.DataFrame({\n",
    "    \"label_id\": counts_idx_sorted.index,\n",
    "    \"class_name\": [id2name[i] for i in counts_idx_sorted.index],\n",
    "    \"count_train\": counts_idx_sorted.values,\n",
    "    \"weight\": w,\n",
    "    \"invfreq_ref\": inv_w,\n",
    "    \"cb_ref\": cb_w,\n",
    "}).sort_values(\"weight\", ascending=False)\n",
    "\n",
    "print(\"\\n[CHECK] Train counts and weights used by loss:\")\n",
    "print(weights_table[[\"label_id\",\"class_name\",\"count_train\",\"weight\"]].to_string(index=False))\n",
    "\n",
    "# (Optional) persist for reproducibility\n",
    "# weights_csv = os.path.join(RESULTS_DIR, f\"train_class_weights_{WEIGHT_MODE}_{EXPERIMENT_TAG}.csv\")\n",
    "# weights_table.to_csv(weights_csv, index=False)\n",
    "# print(f\"[SAVED] {weights_csv}\")\n",
    "\n",
    "# ======================================\n",
    "# LOSS FUNCTION + OPTIMIZER\n",
    "# ======================================\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = amp.GradScaler('cuda') if DEVICE == 'cuda' else None\n",
    "\n",
    "# ======================\n",
    "# TRAIN / EVAL FUNCTIONS\n",
    "# ======================\n",
    "@torch.no_grad()\n",
    "def _accuracy(logits, labels):\n",
    "    return (logits.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "def run_epoch(loader, train=True, desc=\"train\"):\n",
    "    model.train(train)\n",
    "    total_loss, total_correct, total_seen = 0.0, 0, 0\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader, 1):\n",
    "        images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "        ctx = amp.autocast('cuda', enabled=(DEVICE=='cuda'))\n",
    "        with ctx:\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_seen += labels.size(0)\n",
    "            total_loss += float(loss.item()) * labels.size(0)\n",
    "        if step % LOG_EVERY == 0 or step == 1:\n",
    "            print(f\"  [{desc}] step {step}/{len(loader)} | loss={loss.item():.4f}\")\n",
    "    return total_loss / total_seen, total_correct / total_seen\n",
    "\n",
    "\n",
    "def collect_predictions(loader):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
    "                logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "    return np.concatenate(all_labels), np.concatenate(all_preds)\n",
    "\n",
    "# ============================\n",
    "# MAIN TRAIN LOOP\n",
    "# ============================\n",
    "print(\"\\n==== START TRAINING (Weighted Loss) ====\\n\")\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True, desc=\"train\")\n",
    "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.3f}\")\n",
    "    vl_loss, vl_acc = run_epoch(val_loader, train=False, desc=\"val\")\n",
    "    print(f\"Val:   loss={vl_loss:.4f}, acc={vl_acc:.3f}\")\n",
    "\n",
    "    if vl_acc > best_val_acc:\n",
    "        best_val_acc = vl_acc\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  ✅ New best model saved → {SAVE_PATH} (acc={best_val_acc:.3f})\")\n",
    "\n",
    "    y_true, y_pred = collect_predictions(val_loader)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "    with np.printoptions(threshold=200, linewidth=200):\n",
    "        print(cm)\n",
    "\n",
    "    print(\"\\nPer-class metrics (validation):\")\n",
    "    print(classification_report(\n",
    "        y_true, y_pred, labels=list(range(num_classes)), digits=3\n",
    "    ))\n",
    "\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    bal_acc  = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f\"Macro-F1: {macro_f1:.3f} | Balanced Acc: {bal_acc:.3f}\")\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(\"Best validation accuracy:\", round(best_val_acc, 3))\n",
    "print(\"Elapsed time: %.1f sec\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398cba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla V100-PCIE-32GB\n",
      "Loaded metadata:\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              7  \n",
      "1  0728084c8da942d9              7  \n",
      "2  0728084c8da942d9              7  \n",
      "3  0728084c8da942d9              7  \n",
      "4  0728084c8da942d9              7  \n",
      "Number of classes: 11\n",
      "Train samples: 23721 | Val samples: 23450\n",
      "\n",
      "[STRAT] per-class distribution and deviations:\n",
      " label_id           class_name  global_count  global_pct  train_count  train_pct  train_abs_dev_pp  train_rel_dev_%  val_count  val_pct  val_abs_dev_pp  val_rel_dev_%\n",
      "        0          Angiectasia           866       1.836          182      0.767             1.069             58.2        684    2.917           1.081           58.9\n",
      "        1        Blood - fresh           446       0.945           22      0.093             0.853             90.2        424    1.808           0.863           91.2\n",
      "        2              Erosion           507       1.075          295      1.244             0.169             15.7        212    0.904           0.171           15.9\n",
      "        3             Erythema           159       0.337          123      0.519             0.181             53.8         36    0.154           0.184           54.5\n",
      "        4         Foreign Body           776       1.645          186      0.784             0.861             52.3        590    2.516           0.871           52.9\n",
      "        5      Ileocecal valve          4189       8.880         1777      7.491             1.389             15.6       2412   10.286           1.405           15.8\n",
      "        6     Lymphangiectasia           592       1.255           74      0.312             0.943             75.1        518    2.209           0.954           76.0\n",
      "        7  Normal clean mucosa         34338      72.795        18187     76.670             3.876              5.3      16151   68.874           3.921            5.4\n",
      "        8              Pylorus          1538       3.260          994      4.190             0.930             28.5        544    2.320           0.941           28.9\n",
      "        9 Reduced Mucosal View          2906       6.161         1154      4.865             1.296             21.0       1752    7.471           1.311           21.3\n",
      "       10                Ulcer           854       1.810          727      3.065             1.254             69.3        127    0.542           1.269           70.1\n",
      "\n",
      "[STRAT][SUMMARY]\n",
      "  Zero-support classes: TRAIN=0 | VAL=0\n",
      "  Train: mean abs dev = 1.17 pp | max abs dev = 3.88 pp | JSD = 0.0076\n",
      "  Val  : mean abs dev = 1.18 pp | max abs dev = 3.92 pp | JSD = 0.0057\n",
      "[STRAT] saved → /home/stud/fwag/bhome/ele670_project/results/stratification_report_weighted_cb_beta0.99_grouped_class_balanced.csv\n",
      "[WEIGHTS] mode=class_balanced  ->  min=1.000, max=5.041\n",
      "\n",
      "[CHECK] Train counts and weights used by loss:\n",
      " label_id           class_name  count_train   weight\n",
      "        1        Blood - fresh           22 5.041100\n",
      "        6     Lymphangiectasia           74 1.905996\n",
      "        3             Erythema          123 1.409420\n",
      "        0          Angiectasia          182 1.191254\n",
      "        4         Foreign Body          186 1.182343\n",
      "        2              Erosion          295 1.054372\n",
      "       10                Ulcer          727 1.000672\n",
      "        8              Pylorus          994 1.000046\n",
      "        9 Reduced Mucosal View         1154 1.000009\n",
      "        5      Ileocecal valve         1777 1.000000\n",
      "        7  Normal clean mucosa        18187 1.000000\n",
      "\n",
      "==== START TRAINING (Weighted Loss) ====\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "  [train] step 1/741 | loss=2.5550\n",
      "  [train] step 10/741 | loss=1.4098\n",
      "  [train] step 20/741 | loss=1.4696\n",
      "  [train] step 30/741 | loss=1.0209\n",
      "  [train] step 40/741 | loss=1.1419\n",
      "  [train] step 50/741 | loss=0.9963\n",
      "  [train] step 60/741 | loss=1.4286\n",
      "  [train] step 70/741 | loss=1.1184\n",
      "  [train] step 80/741 | loss=1.2955\n",
      "  [train] step 90/741 | loss=0.9026\n",
      "  [train] step 100/741 | loss=1.1541\n",
      "  [train] step 110/741 | loss=1.0899\n",
      "  [train] step 120/741 | loss=1.4903\n",
      "  [train] step 130/741 | loss=0.9244\n",
      "  [train] step 140/741 | loss=0.9295\n",
      "  [train] step 150/741 | loss=1.0039\n",
      "  [train] step 160/741 | loss=0.8400\n",
      "  [train] step 170/741 | loss=0.6590\n",
      "  [train] step 180/741 | loss=0.7107\n",
      "  [train] step 190/741 | loss=0.9712\n",
      "  [train] step 200/741 | loss=0.9807\n",
      "  [train] step 210/741 | loss=0.7672\n",
      "  [train] step 220/741 | loss=0.8109\n",
      "  [train] step 230/741 | loss=0.8841\n",
      "  [train] step 240/741 | loss=0.9066\n",
      "  [train] step 250/741 | loss=0.6568\n",
      "  [train] step 260/741 | loss=0.8315\n",
      "  [train] step 270/741 | loss=0.8366\n",
      "  [train] step 280/741 | loss=0.7844\n",
      "  [train] step 290/741 | loss=0.7874\n",
      "  [train] step 300/741 | loss=0.7639\n",
      "  [train] step 310/741 | loss=1.0454\n",
      "  [train] step 320/741 | loss=0.8793\n",
      "  [train] step 330/741 | loss=0.7691\n",
      "  [train] step 340/741 | loss=0.8252\n",
      "  [train] step 350/741 | loss=0.7805\n",
      "  [train] step 360/741 | loss=0.7525\n",
      "  [train] step 370/741 | loss=0.9167\n",
      "  [train] step 380/741 | loss=0.7618\n",
      "  [train] step 390/741 | loss=0.8961\n",
      "  [train] step 400/741 | loss=0.8076\n",
      "  [train] step 410/741 | loss=0.8138\n",
      "  [train] step 420/741 | loss=0.7954\n",
      "  [train] step 430/741 | loss=0.6102\n",
      "  [train] step 440/741 | loss=0.8837\n",
      "  [train] step 450/741 | loss=0.7954\n",
      "  [train] step 460/741 | loss=0.9132\n",
      "  [train] step 470/741 | loss=0.8439\n",
      "  [train] step 480/741 | loss=0.6236\n",
      "  [train] step 490/741 | loss=0.8717\n",
      "  [train] step 500/741 | loss=0.9471\n",
      "  [train] step 510/741 | loss=0.6103\n",
      "  [train] step 520/741 | loss=0.8714\n",
      "  [train] step 530/741 | loss=0.6851\n",
      "  [train] step 540/741 | loss=0.7573\n",
      "  [train] step 550/741 | loss=0.6183\n",
      "  [train] step 560/741 | loss=0.8629\n",
      "  [train] step 570/741 | loss=0.6435\n",
      "  [train] step 580/741 | loss=0.6878\n",
      "  [train] step 590/741 | loss=0.5837\n",
      "  [train] step 600/741 | loss=0.6675\n",
      "  [train] step 610/741 | loss=0.8357\n",
      "  [train] step 620/741 | loss=0.6590\n",
      "  [train] step 630/741 | loss=0.7144\n",
      "  [train] step 640/741 | loss=0.8370\n",
      "  [train] step 650/741 | loss=0.7451\n",
      "  [train] step 660/741 | loss=0.7270\n",
      "  [train] step 670/741 | loss=0.5948\n",
      "  [train] step 680/741 | loss=0.8645\n",
      "  [train] step 690/741 | loss=0.7024\n",
      "  [train] step 700/741 | loss=0.6592\n",
      "  [train] step 710/741 | loss=0.7418\n",
      "  [train] step 720/741 | loss=0.8159\n",
      "  [train] step 730/741 | loss=0.5421\n",
      "  [train] step 740/741 | loss=0.5351\n",
      "Train: loss=0.8396, acc=0.864\n",
      "  [val] step 1/733 | loss=1.2697\n",
      "  [val] step 10/733 | loss=0.5686\n",
      "  [val] step 20/733 | loss=0.5227\n",
      "  [val] step 30/733 | loss=1.5183\n",
      "  [val] step 40/733 | loss=2.8039\n",
      "  [val] step 50/733 | loss=4.5459\n",
      "  [val] step 60/733 | loss=0.4591\n",
      "  [val] step 70/733 | loss=0.5621\n",
      "  [val] step 80/733 | loss=0.8215\n",
      "  [val] step 90/733 | loss=0.4692\n",
      "  [val] step 100/733 | loss=0.4531\n",
      "  [val] step 110/733 | loss=0.5261\n",
      "  [val] step 120/733 | loss=0.9089\n",
      "  [val] step 130/733 | loss=1.0013\n",
      "  [val] step 140/733 | loss=3.5821\n",
      "  [val] step 150/733 | loss=1.0277\n",
      "  [val] step 160/733 | loss=0.4869\n",
      "  [val] step 170/733 | loss=3.2155\n",
      "  [val] step 180/733 | loss=3.4250\n",
      "  [val] step 190/733 | loss=0.6175\n",
      "  [val] step 200/733 | loss=0.6897\n",
      "  [val] step 210/733 | loss=1.7889\n",
      "  [val] step 220/733 | loss=0.8730\n",
      "  [val] step 230/733 | loss=0.5372\n",
      "  [val] step 240/733 | loss=0.4890\n",
      "  [val] step 250/733 | loss=0.5421\n",
      "  [val] step 260/733 | loss=0.8915\n",
      "  [val] step 270/733 | loss=0.4914\n",
      "  [val] step 280/733 | loss=0.5880\n",
      "  [val] step 290/733 | loss=0.5646\n",
      "  [val] step 300/733 | loss=1.8307\n",
      "  [val] step 310/733 | loss=1.5060\n",
      "  [val] step 320/733 | loss=1.9385\n",
      "  [val] step 330/733 | loss=1.6737\n",
      "  [val] step 340/733 | loss=0.6269\n",
      "  [val] step 350/733 | loss=4.1257\n",
      "  [val] step 360/733 | loss=0.6357\n",
      "  [val] step 370/733 | loss=0.6159\n",
      "  [val] step 380/733 | loss=0.6352\n",
      "  [val] step 390/733 | loss=0.6600\n",
      "  [val] step 400/733 | loss=0.7160\n",
      "  [val] step 410/733 | loss=0.5564\n",
      "  [val] step 420/733 | loss=0.7210\n",
      "  [val] step 430/733 | loss=0.6410\n",
      "  [val] step 440/733 | loss=1.0575\n",
      "  [val] step 450/733 | loss=0.5484\n",
      "  [val] step 460/733 | loss=0.4912\n",
      "  [val] step 470/733 | loss=0.9655\n",
      "  [val] step 480/733 | loss=1.3320\n",
      "  [val] step 490/733 | loss=2.0559\n",
      "  [val] step 500/733 | loss=0.4907\n",
      "  [val] step 510/733 | loss=0.5951\n",
      "  [val] step 520/733 | loss=0.4559\n",
      "  [val] step 530/733 | loss=0.4835\n",
      "  [val] step 540/733 | loss=0.4993\n",
      "  [val] step 550/733 | loss=0.4594\n",
      "  [val] step 560/733 | loss=4.9801\n",
      "  [val] step 570/733 | loss=5.3724\n",
      "  [val] step 580/733 | loss=6.3574\n",
      "  [val] step 590/733 | loss=0.6178\n",
      "  [val] step 600/733 | loss=0.4521\n",
      "  [val] step 610/733 | loss=0.6445\n",
      "  [val] step 620/733 | loss=0.6546\n",
      "  [val] step 630/733 | loss=0.4779\n",
      "  [val] step 640/733 | loss=0.4491\n",
      "  [val] step 650/733 | loss=0.4493\n",
      "  [val] step 660/733 | loss=3.1691\n",
      "  [val] step 670/733 | loss=0.6823\n",
      "  [val] step 680/733 | loss=0.6525\n",
      "  [val] step 690/733 | loss=0.8033\n",
      "  [val] step 700/733 | loss=0.6359\n",
      "  [val] step 710/733 | loss=0.4519\n",
      "  [val] step 720/733 | loss=4.5212\n",
      "  [val] step 730/733 | loss=1.7270\n",
      "Val:   loss=1.3697, acc=0.706\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best_weighted.pt (acc=0.706)\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0     0     0     0     0     0   684     0     0     0]\n",
      " [    0     0     0     0     0   145     0   256    10     0    13]\n",
      " [    3     0     0     0     0    15     0   137    57     0     0]\n",
      " [    0     0     0     0     0     0     0    22     0     0    14]\n",
      " [    0     0     0     0    12    11     1   471    93     2     0]\n",
      " [    0     0     0     0     0   722     0  1358    63    90   179]\n",
      " [    0     0     0     0    14     3     0   497     0     3     1]\n",
      " [    1     0     0     6     1   106     2 15281   608    78    68]\n",
      " [    0     0     0     0     0     1     3   322   217     0     1]\n",
      " [    0     0     0     0     1   299     0  1107     1   292    52]\n",
      " [    0     0     0     0     0     1     0    33    71     0    22]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.000     0.000     0.000       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.429     0.020     0.039       590\n",
      "           5      0.554     0.299     0.389      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.758     0.946     0.841     16151\n",
      "           8      0.194     0.399     0.261       544\n",
      "           9      0.628     0.167     0.263      1752\n",
      "          10      0.063     0.173     0.092       127\n",
      "\n",
      "    accuracy                          0.706     23450\n",
      "   macro avg      0.239     0.182     0.171     23450\n",
      "weighted avg      0.641     0.706     0.647     23450\n",
      "\n",
      "Macro-F1: 0.171 | Balanced Acc: 0.182\n",
      "\n",
      "Epoch 2/10\n",
      "  [train] step 1/741 | loss=0.5933\n",
      "  [train] step 10/741 | loss=0.8799\n",
      "  [train] step 20/741 | loss=0.6532\n",
      "  [train] step 30/741 | loss=0.6268\n",
      "  [train] step 40/741 | loss=0.6523\n",
      "  [train] step 50/741 | loss=0.7232\n",
      "  [train] step 60/741 | loss=0.5958\n",
      "  [train] step 70/741 | loss=0.6569\n",
      "  [train] step 80/741 | loss=0.6176\n",
      "  [train] step 90/741 | loss=0.8488\n",
      "  [train] step 100/741 | loss=0.9364\n",
      "  [train] step 110/741 | loss=0.8778\n",
      "  [train] step 120/741 | loss=0.6367\n",
      "  [train] step 130/741 | loss=0.5482\n",
      "  [train] step 140/741 | loss=0.7053\n",
      "  [train] step 150/741 | loss=0.6900\n",
      "  [train] step 160/741 | loss=0.8330\n",
      "  [train] step 170/741 | loss=0.6220\n",
      "  [train] step 180/741 | loss=0.6109\n",
      "  [train] step 190/741 | loss=0.7254\n",
      "  [train] step 200/741 | loss=0.8869\n",
      "  [train] step 210/741 | loss=0.7062\n",
      "  [train] step 220/741 | loss=0.5822\n",
      "  [train] step 230/741 | loss=0.6834\n",
      "  [train] step 240/741 | loss=0.9215\n",
      "  [train] step 250/741 | loss=0.7696\n",
      "  [train] step 260/741 | loss=0.6701\n",
      "  [train] step 270/741 | loss=0.6025\n",
      "  [train] step 280/741 | loss=0.6560\n",
      "  [train] step 290/741 | loss=0.5332\n",
      "  [train] step 300/741 | loss=0.6097\n",
      "  [train] step 310/741 | loss=0.6463\n",
      "  [train] step 320/741 | loss=0.6094\n",
      "  [train] step 330/741 | loss=0.8090\n",
      "  [train] step 340/741 | loss=0.5497\n",
      "  [train] step 350/741 | loss=0.6274\n",
      "  [train] step 360/741 | loss=0.7281\n",
      "  [train] step 370/741 | loss=0.6890\n",
      "  [train] step 380/741 | loss=0.5975\n",
      "  [train] step 390/741 | loss=0.5969\n",
      "  [train] step 400/741 | loss=0.6378\n",
      "  [train] step 410/741 | loss=0.5752\n",
      "  [train] step 420/741 | loss=0.9139\n",
      "  [train] step 430/741 | loss=0.5823\n",
      "  [train] step 440/741 | loss=0.8084\n",
      "  [train] step 450/741 | loss=0.5953\n",
      "  [train] step 460/741 | loss=0.5996\n",
      "  [train] step 470/741 | loss=0.6260\n",
      "  [train] step 480/741 | loss=0.5961\n",
      "  [train] step 490/741 | loss=0.6562\n",
      "  [train] step 500/741 | loss=0.5431\n",
      "  [train] step 510/741 | loss=0.5719\n",
      "  [train] step 520/741 | loss=0.7995\n",
      "  [train] step 530/741 | loss=0.6002\n",
      "  [train] step 540/741 | loss=0.5984\n",
      "  [train] step 550/741 | loss=0.6205\n",
      "  [train] step 560/741 | loss=0.7116\n",
      "  [train] step 570/741 | loss=0.6736\n",
      "  [train] step 580/741 | loss=0.7904\n",
      "  [train] step 590/741 | loss=0.5858\n",
      "  [train] step 600/741 | loss=0.8743\n",
      "  [train] step 610/741 | loss=0.5422\n",
      "  [train] step 620/741 | loss=0.8493\n",
      "  [train] step 630/741 | loss=0.5533\n",
      "  [train] step 640/741 | loss=0.7363\n",
      "  [train] step 650/741 | loss=0.5254\n",
      "  [train] step 660/741 | loss=0.6500\n",
      "  [train] step 670/741 | loss=0.6851\n",
      "  [train] step 680/741 | loss=0.6156\n",
      "  [train] step 690/741 | loss=0.8026\n",
      "  [train] step 700/741 | loss=0.7915\n",
      "  [train] step 710/741 | loss=0.6076\n",
      "  [train] step 720/741 | loss=0.6445\n",
      "  [train] step 730/741 | loss=0.7104\n",
      "  [train] step 740/741 | loss=0.7362\n",
      "Train: loss=0.6583, acc=0.924\n",
      "  [val] step 1/733 | loss=1.1074\n",
      "  [val] step 10/733 | loss=0.5970\n",
      "  [val] step 20/733 | loss=0.5437\n",
      "  [val] step 30/733 | loss=1.7071\n",
      "  [val] step 40/733 | loss=2.7759\n",
      "  [val] step 50/733 | loss=4.7181\n",
      "  [val] step 60/733 | loss=0.4529\n",
      "  [val] step 70/733 | loss=0.5652\n",
      "  [val] step 80/733 | loss=0.8346\n",
      "  [val] step 90/733 | loss=0.4826\n",
      "  [val] step 100/733 | loss=0.4577\n",
      "  [val] step 110/733 | loss=0.5258\n",
      "  [val] step 120/733 | loss=1.1930\n",
      "  [val] step 130/733 | loss=1.2888\n",
      "  [val] step 140/733 | loss=3.2944\n",
      "  [val] step 150/733 | loss=1.1153\n",
      "  [val] step 160/733 | loss=0.4899\n",
      "  [val] step 170/733 | loss=3.1311\n",
      "  [val] step 180/733 | loss=3.6915\n",
      "  [val] step 190/733 | loss=0.7472\n",
      "  [val] step 200/733 | loss=0.6803\n",
      "  [val] step 210/733 | loss=1.5862\n",
      "  [val] step 220/733 | loss=0.7866\n",
      "  [val] step 230/733 | loss=0.5755\n",
      "  [val] step 240/733 | loss=0.5152\n",
      "  [val] step 250/733 | loss=0.5986\n",
      "  [val] step 260/733 | loss=1.0680\n",
      "  [val] step 270/733 | loss=0.5152\n",
      "  [val] step 280/733 | loss=0.6304\n",
      "  [val] step 290/733 | loss=0.6318\n",
      "  [val] step 300/733 | loss=1.9271\n",
      "  [val] step 310/733 | loss=1.8137\n",
      "  [val] step 320/733 | loss=2.0587\n",
      "  [val] step 330/733 | loss=1.9975\n",
      "  [val] step 340/733 | loss=0.6126\n",
      "  [val] step 350/733 | loss=4.2547\n",
      "  [val] step 360/733 | loss=0.6219\n",
      "  [val] step 370/733 | loss=0.6028\n",
      "  [val] step 380/733 | loss=0.6154\n",
      "  [val] step 390/733 | loss=0.6426\n",
      "  [val] step 400/733 | loss=0.6966\n",
      "  [val] step 410/733 | loss=0.6229\n",
      "  [val] step 420/733 | loss=0.6982\n",
      "  [val] step 430/733 | loss=0.6911\n",
      "  [val] step 440/733 | loss=1.1775\n",
      "  [val] step 450/733 | loss=0.6055\n",
      "  [val] step 460/733 | loss=0.5161\n",
      "  [val] step 470/733 | loss=1.0896\n",
      "  [val] step 480/733 | loss=1.6578\n",
      "  [val] step 490/733 | loss=2.6036\n",
      "  [val] step 500/733 | loss=0.4983\n",
      "  [val] step 510/733 | loss=0.6129\n",
      "  [val] step 520/733 | loss=0.4656\n",
      "  [val] step 530/733 | loss=0.5026\n",
      "  [val] step 540/733 | loss=0.5303\n",
      "  [val] step 550/733 | loss=0.4578\n",
      "  [val] step 560/733 | loss=5.1955\n",
      "  [val] step 570/733 | loss=5.1593\n",
      "  [val] step 580/733 | loss=5.7832\n",
      "  [val] step 590/733 | loss=0.6294\n",
      "  [val] step 600/733 | loss=0.4744\n",
      "  [val] step 610/733 | loss=0.6646\n",
      "  [val] step 620/733 | loss=0.6484\n",
      "  [val] step 630/733 | loss=0.4727\n",
      "  [val] step 640/733 | loss=0.4547\n",
      "  [val] step 650/733 | loss=0.4571\n",
      "  [val] step 660/733 | loss=2.3603\n",
      "  [val] step 670/733 | loss=0.7388\n",
      "  [val] step 680/733 | loss=0.6804\n",
      "  [val] step 690/733 | loss=0.8026\n",
      "  [val] step 700/733 | loss=0.7883\n",
      "  [val] step 710/733 | loss=0.4751\n",
      "  [val] step 720/733 | loss=4.6948\n",
      "  [val] step 730/733 | loss=1.3999\n",
      "Val:   loss=1.4083, acc=0.695\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    1     0     0     2     0     0     0   679     2     0     0]\n",
      " [    0     0     0     0     0   155     0   228    27     0    14]\n",
      " [   15     0     1     0     0    24     0   109    57     0     6]\n",
      " [    0     1     0     0     0     0     0    15     0     1    19]\n",
      " [    1     0     2     0    18    23     0   394   144     6     2]\n",
      " [    0     0    27     0     2   619     0  1146   228   115   275]\n",
      " [    0     0     1     0    32     4     0   476     1     3     1]\n",
      " [    7     0    18    11     3   104     1 14912   854   131   110]\n",
      " [    2     0     2     0     0     2     1   223   310     0     4]\n",
      " [    0     0    16     0     2   320     1   910     3   388   112]\n",
      " [    0     0     3     0     0     1     0    16    64     0    43]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.038     0.001     0.003       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.014     0.005     0.007       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.316     0.031     0.056       590\n",
      "           5      0.494     0.257     0.338      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.780     0.923     0.846     16151\n",
      "           8      0.183     0.570     0.278       544\n",
      "           9      0.602     0.221     0.324      1752\n",
      "          10      0.073     0.339     0.121       127\n",
      "\n",
      "    accuracy                          0.695     23450\n",
      "   macro avg      0.228     0.213     0.179     23450\n",
      "weighted avg      0.647     0.695     0.650     23450\n",
      "\n",
      "Macro-F1: 0.179 | Balanced Acc: 0.213\n",
      "\n",
      "Epoch 3/10\n",
      "  [train] step 1/741 | loss=0.5809\n",
      "  [train] step 10/741 | loss=0.6542\n",
      "  [train] step 20/741 | loss=0.5888\n",
      "  [train] step 30/741 | loss=0.5993\n",
      "  [train] step 40/741 | loss=0.6000\n",
      "  [train] step 50/741 | loss=0.6540\n",
      "  [train] step 60/741 | loss=0.6590\n",
      "  [train] step 70/741 | loss=0.5089\n",
      "  [train] step 80/741 | loss=0.5336\n",
      "  [train] step 90/741 | loss=0.5288\n",
      "  [train] step 100/741 | loss=0.5936\n",
      "  [train] step 110/741 | loss=0.6231\n",
      "  [train] step 120/741 | loss=0.6632\n",
      "  [train] step 130/741 | loss=0.6613\n",
      "  [train] step 140/741 | loss=0.7773\n",
      "  [train] step 150/741 | loss=0.5464\n",
      "  [train] step 160/741 | loss=0.6763\n",
      "  [train] step 170/741 | loss=0.5998\n",
      "  [train] step 180/741 | loss=0.5962\n",
      "  [train] step 190/741 | loss=0.5733\n",
      "  [train] step 200/741 | loss=0.6486\n",
      "  [train] step 210/741 | loss=0.6305\n",
      "  [train] step 220/741 | loss=0.9815\n",
      "  [train] step 230/741 | loss=0.5872\n",
      "  [train] step 240/741 | loss=0.5806\n",
      "  [train] step 250/741 | loss=0.7142\n",
      "  [train] step 260/741 | loss=0.7342\n",
      "  [train] step 270/741 | loss=0.6858\n",
      "  [train] step 280/741 | loss=0.5386\n",
      "  [train] step 290/741 | loss=0.5543\n",
      "  [train] step 300/741 | loss=0.6123\n",
      "  [train] step 310/741 | loss=0.5415\n",
      "  [train] step 320/741 | loss=0.6701\n",
      "  [train] step 330/741 | loss=0.6985\n",
      "  [train] step 340/741 | loss=0.5916\n",
      "  [train] step 350/741 | loss=0.6073\n",
      "  [train] step 360/741 | loss=0.8948\n",
      "  [train] step 370/741 | loss=0.5993\n",
      "  [train] step 380/741 | loss=0.6228\n",
      "  [train] step 390/741 | loss=0.6446\n",
      "  [train] step 400/741 | loss=0.7420\n",
      "  [train] step 410/741 | loss=0.6541\n",
      "  [train] step 420/741 | loss=0.6903\n",
      "  [train] step 430/741 | loss=0.5707\n",
      "  [train] step 440/741 | loss=0.6487\n",
      "  [train] step 450/741 | loss=0.5453\n",
      "  [train] step 460/741 | loss=0.5603\n",
      "  [train] step 470/741 | loss=0.7171\n",
      "  [train] step 480/741 | loss=0.5919\n",
      "  [train] step 490/741 | loss=0.6343\n",
      "  [train] step 500/741 | loss=0.5949\n",
      "  [train] step 510/741 | loss=0.5571\n",
      "  [train] step 520/741 | loss=0.6060\n",
      "  [train] step 530/741 | loss=0.7041\n",
      "  [train] step 540/741 | loss=0.4888\n",
      "  [train] step 550/741 | loss=0.5701\n",
      "  [train] step 560/741 | loss=0.4932\n",
      "  [train] step 570/741 | loss=0.6382\n",
      "  [train] step 580/741 | loss=0.6637\n",
      "  [train] step 590/741 | loss=0.5810\n",
      "  [train] step 600/741 | loss=0.5248\n",
      "  [train] step 610/741 | loss=0.6226\n",
      "  [train] step 620/741 | loss=0.6644\n",
      "  [train] step 630/741 | loss=0.5614\n",
      "  [train] step 640/741 | loss=0.5501\n",
      "  [train] step 650/741 | loss=0.6011\n",
      "  [train] step 660/741 | loss=0.5797\n",
      "  [train] step 670/741 | loss=0.5880\n",
      "  [train] step 680/741 | loss=0.6300\n",
      "  [train] step 690/741 | loss=0.5411\n",
      "  [train] step 700/741 | loss=0.5080\n",
      "  [train] step 710/741 | loss=0.5213\n",
      "  [train] step 720/741 | loss=0.6409\n",
      "  [train] step 730/741 | loss=0.6138\n",
      "  [train] step 740/741 | loss=0.5486\n",
      "Train: loss=0.6146, acc=0.942\n",
      "  [val] step 1/733 | loss=0.9050\n",
      "  [val] step 10/733 | loss=0.6133\n",
      "  [val] step 20/733 | loss=0.5111\n",
      "  [val] step 30/733 | loss=1.5092\n",
      "  [val] step 40/733 | loss=2.5125\n",
      "  [val] step 50/733 | loss=4.4856\n",
      "  [val] step 60/733 | loss=0.4445\n",
      "  [val] step 70/733 | loss=0.5979\n",
      "  [val] step 80/733 | loss=0.7708\n",
      "  [val] step 90/733 | loss=0.4936\n",
      "  [val] step 100/733 | loss=0.4571\n",
      "  [val] step 110/733 | loss=0.4867\n",
      "  [val] step 120/733 | loss=0.9163\n",
      "  [val] step 130/733 | loss=1.2752\n",
      "  [val] step 140/733 | loss=3.8531\n",
      "  [val] step 150/733 | loss=1.2163\n",
      "  [val] step 160/733 | loss=0.4937\n",
      "  [val] step 170/733 | loss=2.9071\n",
      "  [val] step 180/733 | loss=3.4562\n",
      "  [val] step 190/733 | loss=0.5863\n",
      "  [val] step 200/733 | loss=0.6033\n",
      "  [val] step 210/733 | loss=1.7838\n",
      "  [val] step 220/733 | loss=0.9934\n",
      "  [val] step 230/733 | loss=0.6379\n",
      "  [val] step 240/733 | loss=0.5556\n",
      "  [val] step 250/733 | loss=0.6082\n",
      "  [val] step 260/733 | loss=0.9315\n",
      "  [val] step 270/733 | loss=0.4873\n",
      "  [val] step 280/733 | loss=0.6097\n",
      "  [val] step 290/733 | loss=0.6170\n",
      "  [val] step 300/733 | loss=1.4853\n",
      "  [val] step 310/733 | loss=1.7818\n",
      "  [val] step 320/733 | loss=1.9799\n",
      "  [val] step 330/733 | loss=1.8494\n",
      "  [val] step 340/733 | loss=0.5678\n",
      "  [val] step 350/733 | loss=4.0460\n",
      "  [val] step 360/733 | loss=0.6089\n",
      "  [val] step 370/733 | loss=0.6097\n",
      "  [val] step 380/733 | loss=0.5960\n",
      "  [val] step 390/733 | loss=0.5940\n",
      "  [val] step 400/733 | loss=0.6842\n",
      "  [val] step 410/733 | loss=0.5464\n",
      "  [val] step 420/733 | loss=0.6779\n",
      "  [val] step 430/733 | loss=0.6775\n",
      "  [val] step 440/733 | loss=1.2032\n",
      "  [val] step 450/733 | loss=0.6666\n",
      "  [val] step 460/733 | loss=0.5205\n",
      "  [val] step 470/733 | loss=1.0372\n",
      "  [val] step 480/733 | loss=1.4314\n",
      "  [val] step 490/733 | loss=2.4058\n",
      "  [val] step 500/733 | loss=0.5246\n",
      "  [val] step 510/733 | loss=0.6404\n",
      "  [val] step 520/733 | loss=0.4558\n",
      "  [val] step 530/733 | loss=0.5234\n",
      "  [val] step 540/733 | loss=0.5044\n",
      "  [val] step 550/733 | loss=0.4485\n",
      "  [val] step 560/733 | loss=4.8573\n",
      "  [val] step 570/733 | loss=5.5502\n",
      "  [val] step 580/733 | loss=6.1531\n",
      "  [val] step 590/733 | loss=0.6218\n",
      "  [val] step 600/733 | loss=0.4769\n",
      "  [val] step 610/733 | loss=0.7121\n",
      "  [val] step 620/733 | loss=0.6544\n",
      "  [val] step 630/733 | loss=0.4852\n",
      "  [val] step 640/733 | loss=0.4632\n",
      "  [val] step 650/733 | loss=0.4541\n",
      "  [val] step 660/733 | loss=1.9952\n",
      "  [val] step 670/733 | loss=0.6471\n",
      "  [val] step 680/733 | loss=0.5836\n",
      "  [val] step 690/733 | loss=0.7197\n",
      "  [val] step 700/733 | loss=0.7800\n",
      "  [val] step 710/733 | loss=0.4700\n",
      "  [val] step 720/733 | loss=4.5972\n",
      "  [val] step 730/733 | loss=1.5629\n",
      "Val:   loss=1.3689, acc=0.705\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    2     0     0     4     0     0     0   678     0     0     0]\n",
      " [    0     0     3     1     0   209     0   196    10     0     5]\n",
      " [   21     0     1     0     0    48     4   101    33     0     4]\n",
      " [    0     1     0     1     0     0     0    15     0     2    17]\n",
      " [    1     0     1     0    15    32     0   441    92     8     0]\n",
      " [    0     0    16     0     2   742     0  1249    67   239    97]\n",
      " [    0     0     1     3    28     3     0   475     0     7     1]\n",
      " [    5     0    16    67     1   165     5 15016   617   214    45]\n",
      " [    2     0     3     1     0     6     1   306   222     0     3]\n",
      " [    0     0     6     0     2   286     1   928     0   500    29]\n",
      " [    3     0     3     0     0    11     0    24    48     0    38]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.059     0.003     0.006       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.020     0.005     0.008       212\n",
      "           3      0.013     0.028     0.018        36\n",
      "           4      0.312     0.025     0.047       590\n",
      "           5      0.494     0.308     0.379      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.773     0.930     0.844     16151\n",
      "           8      0.204     0.408     0.272       544\n",
      "           9      0.515     0.285     0.367      1752\n",
      "          10      0.159     0.299     0.208       127\n",
      "\n",
      "    accuracy                          0.705     23450\n",
      "   macro avg      0.232     0.208     0.195     23450\n",
      "weighted avg      0.637     0.705     0.657     23450\n",
      "\n",
      "Macro-F1: 0.195 | Balanced Acc: 0.208\n",
      "\n",
      "Epoch 4/10\n",
      "  [train] step 1/741 | loss=0.5834\n",
      "  [train] step 10/741 | loss=0.6610\n",
      "  [train] step 20/741 | loss=0.6701\n",
      "  [train] step 30/741 | loss=0.5225\n",
      "  [train] step 40/741 | loss=0.6200\n",
      "  [train] step 50/741 | loss=0.9629\n",
      "  [train] step 60/741 | loss=0.6815\n",
      "  [train] step 70/741 | loss=0.6768\n",
      "  [train] step 80/741 | loss=0.7089\n",
      "  [train] step 90/741 | loss=0.5026\n",
      "  [train] step 100/741 | loss=0.5208\n",
      "  [train] step 110/741 | loss=0.6620\n",
      "  [train] step 120/741 | loss=0.5635\n",
      "  [train] step 130/741 | loss=0.7564\n",
      "  [train] step 140/741 | loss=0.5691\n",
      "  [train] step 150/741 | loss=0.5711\n",
      "  [train] step 160/741 | loss=0.5433\n",
      "  [train] step 170/741 | loss=0.5311\n",
      "  [train] step 180/741 | loss=0.6022\n",
      "  [train] step 190/741 | loss=0.5998\n",
      "  [train] step 200/741 | loss=0.6331\n",
      "  [train] step 210/741 | loss=0.6150\n",
      "  [train] step 220/741 | loss=0.5703\n",
      "  [train] step 230/741 | loss=0.5274\n",
      "  [train] step 240/741 | loss=0.6720\n",
      "  [train] step 250/741 | loss=0.5161\n",
      "  [train] step 260/741 | loss=0.5696\n",
      "  [train] step 270/741 | loss=0.6329\n",
      "  [train] step 280/741 | loss=0.5545\n",
      "  [train] step 290/741 | loss=0.6115\n",
      "  [train] step 300/741 | loss=0.8747\n",
      "  [train] step 310/741 | loss=0.5931\n",
      "  [train] step 320/741 | loss=0.5194\n",
      "  [train] step 330/741 | loss=0.6971\n",
      "  [train] step 340/741 | loss=0.6385\n",
      "  [train] step 350/741 | loss=0.5091\n",
      "  [train] step 360/741 | loss=0.5125\n",
      "  [train] step 370/741 | loss=0.7865\n",
      "  [train] step 380/741 | loss=0.6492\n",
      "  [train] step 390/741 | loss=0.5766\n",
      "  [train] step 400/741 | loss=0.7259\n",
      "  [train] step 410/741 | loss=0.5861\n",
      "  [train] step 420/741 | loss=0.5523\n",
      "  [train] step 430/741 | loss=0.5771\n",
      "  [train] step 440/741 | loss=0.6082\n",
      "  [train] step 450/741 | loss=0.6134\n",
      "  [train] step 460/741 | loss=0.5157\n",
      "  [train] step 470/741 | loss=0.6020\n",
      "  [train] step 480/741 | loss=0.5977\n",
      "  [train] step 490/741 | loss=0.6702\n",
      "  [train] step 500/741 | loss=0.5683\n",
      "  [train] step 510/741 | loss=0.5346\n",
      "  [train] step 520/741 | loss=0.5316\n",
      "  [train] step 530/741 | loss=0.6960\n",
      "  [train] step 540/741 | loss=0.9321\n",
      "  [train] step 550/741 | loss=0.6321\n",
      "  [train] step 560/741 | loss=0.5430\n",
      "  [train] step 570/741 | loss=0.5487\n",
      "  [train] step 580/741 | loss=0.5693\n",
      "  [train] step 590/741 | loss=0.5606\n",
      "  [train] step 600/741 | loss=0.5159\n",
      "  [train] step 610/741 | loss=0.6942\n",
      "  [train] step 620/741 | loss=0.6011\n",
      "  [train] step 630/741 | loss=0.6748\n",
      "  [train] step 640/741 | loss=0.5704\n",
      "  [train] step 650/741 | loss=0.5982\n",
      "  [train] step 660/741 | loss=0.5514\n",
      "  [train] step 670/741 | loss=0.6292\n",
      "  [train] step 680/741 | loss=0.5277\n",
      "  [train] step 690/741 | loss=0.5618\n",
      "  [train] step 700/741 | loss=0.6069\n",
      "  [train] step 710/741 | loss=0.8039\n",
      "  [train] step 720/741 | loss=0.6048\n",
      "  [train] step 730/741 | loss=0.6068\n",
      "  [train] step 740/741 | loss=0.5980\n",
      "Train: loss=0.5958, acc=0.948\n",
      "  [val] step 1/733 | loss=1.0057\n",
      "  [val] step 10/733 | loss=0.5979\n",
      "  [val] step 20/733 | loss=0.5044\n",
      "  [val] step 30/733 | loss=1.8561\n",
      "  [val] step 40/733 | loss=3.0467\n",
      "  [val] step 50/733 | loss=4.6676\n",
      "  [val] step 60/733 | loss=0.4451\n",
      "  [val] step 70/733 | loss=0.5664\n",
      "  [val] step 80/733 | loss=0.7737\n",
      "  [val] step 90/733 | loss=0.4940\n",
      "  [val] step 100/733 | loss=0.4560\n",
      "  [val] step 110/733 | loss=0.5065\n",
      "  [val] step 120/733 | loss=1.2048\n",
      "  [val] step 130/733 | loss=0.9897\n",
      "  [val] step 140/733 | loss=3.5915\n",
      "  [val] step 150/733 | loss=0.9473\n",
      "  [val] step 160/733 | loss=0.4878\n",
      "  [val] step 170/733 | loss=2.6711\n",
      "  [val] step 180/733 | loss=3.4394\n",
      "  [val] step 190/733 | loss=0.6446\n",
      "  [val] step 200/733 | loss=0.6168\n",
      "  [val] step 210/733 | loss=1.6098\n",
      "  [val] step 220/733 | loss=0.8172\n",
      "  [val] step 230/733 | loss=0.6912\n",
      "  [val] step 240/733 | loss=0.5709\n",
      "  [val] step 250/733 | loss=0.5746\n",
      "  [val] step 260/733 | loss=0.9370\n",
      "  [val] step 270/733 | loss=0.4969\n",
      "  [val] step 280/733 | loss=0.5836\n",
      "  [val] step 290/733 | loss=0.6467\n",
      "  [val] step 300/733 | loss=1.8632\n",
      "  [val] step 310/733 | loss=2.1626\n",
      "  [val] step 320/733 | loss=2.2261\n",
      "  [val] step 330/733 | loss=2.2062\n",
      "  [val] step 340/733 | loss=0.5811\n",
      "  [val] step 350/733 | loss=3.9140\n",
      "  [val] step 360/733 | loss=0.6916\n",
      "  [val] step 370/733 | loss=0.6317\n",
      "  [val] step 380/733 | loss=0.6389\n",
      "  [val] step 390/733 | loss=0.6945\n",
      "  [val] step 400/733 | loss=0.7767\n",
      "  [val] step 410/733 | loss=0.5775\n",
      "  [val] step 420/733 | loss=0.6588\n",
      "  [val] step 430/733 | loss=0.6662\n",
      "  [val] step 440/733 | loss=1.2447\n",
      "  [val] step 450/733 | loss=0.6278\n",
      "  [val] step 460/733 | loss=0.5462\n",
      "  [val] step 470/733 | loss=0.7983\n",
      "  [val] step 480/733 | loss=1.4132\n",
      "  [val] step 490/733 | loss=2.4770\n",
      "  [val] step 500/733 | loss=0.5226\n",
      "  [val] step 510/733 | loss=0.6341\n",
      "  [val] step 520/733 | loss=0.4638\n",
      "  [val] step 530/733 | loss=0.4966\n",
      "  [val] step 540/733 | loss=0.5333\n",
      "  [val] step 550/733 | loss=0.4566\n",
      "  [val] step 560/733 | loss=4.7644\n",
      "  [val] step 570/733 | loss=5.2084\n",
      "  [val] step 580/733 | loss=5.6661\n",
      "  [val] step 590/733 | loss=0.7171\n",
      "  [val] step 600/733 | loss=0.5141\n",
      "  [val] step 610/733 | loss=0.7609\n",
      "  [val] step 620/733 | loss=0.7650\n",
      "  [val] step 630/733 | loss=0.5000\n",
      "  [val] step 640/733 | loss=0.4775\n",
      "  [val] step 650/733 | loss=0.4632\n",
      "  [val] step 660/733 | loss=2.3325\n",
      "  [val] step 670/733 | loss=0.7176\n",
      "  [val] step 680/733 | loss=0.6175\n",
      "  [val] step 690/733 | loss=0.7576\n",
      "  [val] step 700/733 | loss=0.8324\n",
      "  [val] step 710/733 | loss=0.4733\n",
      "  [val] step 720/733 | loss=4.4950\n",
      "  [val] step 730/733 | loss=1.5432\n",
      "Val:   loss=1.3900, acc=0.703\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    1     0     1     4     0     0     0   678     0     0     0]\n",
      " [    0     0     8     2     0   203     0   186    18     0     7]\n",
      " [   21     0     3     0     0    51     2    89    42     0     4]\n",
      " [    0     3     0     0     0     0     0    13     0     1    19]\n",
      " [    0     0     4     0    18    51     0   410   103     4     0]\n",
      " [    0     0    67     0     5   635     0  1251   185   148   121]\n",
      " [    0     0     4     0    50     4     0   454     1     5     0]\n",
      " [    6     1    51    42     3   190     4 15072   583   148    51]\n",
      " [    3     0     4     1     0     5     2   278   248     0     3]\n",
      " [    1     1    36     0     4   270     0   944     1   463    32]\n",
      " [    2     0     9     0     0     3     0    19    58     0    36]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.029     0.001     0.003       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.016     0.014     0.015       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.225     0.031     0.054       590\n",
      "           5      0.450     0.263     0.332      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.777     0.933     0.848     16151\n",
      "           8      0.200     0.456     0.278       544\n",
      "           9      0.602     0.264     0.367      1752\n",
      "          10      0.132     0.283     0.180       127\n",
      "\n",
      "    accuracy                          0.703     23450\n",
      "   macro avg      0.221     0.204     0.189     23450\n",
      "weighted avg      0.639     0.703     0.655     23450\n",
      "\n",
      "Macro-F1: 0.189 | Balanced Acc: 0.204\n",
      "\n",
      "Epoch 5/10\n",
      "  [train] step 1/741 | loss=0.6513\n",
      "  [train] step 10/741 | loss=0.5046\n",
      "  [train] step 20/741 | loss=0.5040\n",
      "  [train] step 30/741 | loss=0.5867\n",
      "  [train] step 40/741 | loss=0.4712\n",
      "  [train] step 50/741 | loss=0.5798\n",
      "  [train] step 60/741 | loss=0.5697\n",
      "  [train] step 70/741 | loss=0.5947\n",
      "  [train] step 80/741 | loss=0.6349\n",
      "  [train] step 90/741 | loss=0.5165\n",
      "  [train] step 100/741 | loss=0.6526\n",
      "  [train] step 110/741 | loss=0.6927\n",
      "  [train] step 120/741 | loss=0.6186\n",
      "  [train] step 130/741 | loss=0.5868\n",
      "  [train] step 140/741 | loss=0.6113\n",
      "  [train] step 150/741 | loss=0.4939\n",
      "  [train] step 160/741 | loss=0.4553\n",
      "  [train] step 170/741 | loss=0.5406\n",
      "  [train] step 180/741 | loss=0.6180\n",
      "  [train] step 190/741 | loss=0.5418\n",
      "  [train] step 200/741 | loss=0.5024\n",
      "  [train] step 210/741 | loss=0.5804\n",
      "  [train] step 220/741 | loss=0.5782\n",
      "  [train] step 230/741 | loss=0.5056\n",
      "  [train] step 240/741 | loss=0.5079\n",
      "  [train] step 250/741 | loss=0.6054\n",
      "  [train] step 260/741 | loss=0.6478\n",
      "  [train] step 270/741 | loss=0.5785\n",
      "  [train] step 280/741 | loss=0.5622\n",
      "  [train] step 290/741 | loss=0.5402\n",
      "  [train] step 300/741 | loss=0.7353\n",
      "  [train] step 310/741 | loss=0.6116\n",
      "  [train] step 320/741 | loss=0.7148\n",
      "  [train] step 330/741 | loss=0.6429\n",
      "  [train] step 340/741 | loss=0.5645\n",
      "  [train] step 350/741 | loss=0.5862\n",
      "  [train] step 360/741 | loss=0.6779\n",
      "  [train] step 370/741 | loss=0.5584\n",
      "  [train] step 380/741 | loss=0.5801\n",
      "  [train] step 390/741 | loss=0.4886\n",
      "  [train] step 400/741 | loss=0.5123\n",
      "  [train] step 410/741 | loss=0.5619\n",
      "  [train] step 420/741 | loss=0.5484\n",
      "  [train] step 430/741 | loss=0.5145\n",
      "  [train] step 440/741 | loss=0.5583\n",
      "  [train] step 450/741 | loss=0.5357\n",
      "  [train] step 460/741 | loss=0.5342\n",
      "  [train] step 470/741 | loss=0.5940\n",
      "  [train] step 480/741 | loss=0.5234\n",
      "  [train] step 490/741 | loss=0.7364\n",
      "  [train] step 500/741 | loss=0.5291\n",
      "  [train] step 510/741 | loss=0.5150\n",
      "  [train] step 520/741 | loss=0.5199\n",
      "  [train] step 530/741 | loss=0.6042\n",
      "  [train] step 540/741 | loss=0.6626\n",
      "  [train] step 550/741 | loss=0.5116\n",
      "  [train] step 560/741 | loss=0.5320\n",
      "  [train] step 570/741 | loss=0.5631\n",
      "  [train] step 580/741 | loss=0.5222\n",
      "  [train] step 590/741 | loss=0.5545\n",
      "  [train] step 600/741 | loss=0.5887\n",
      "  [train] step 610/741 | loss=0.5279\n",
      "  [train] step 620/741 | loss=0.5093\n",
      "  [train] step 630/741 | loss=0.5152\n",
      "  [train] step 640/741 | loss=0.5391\n",
      "  [train] step 650/741 | loss=0.6062\n",
      "  [train] step 660/741 | loss=0.6334\n",
      "  [train] step 670/741 | loss=0.5095\n",
      "  [train] step 680/741 | loss=0.5410\n",
      "  [train] step 690/741 | loss=0.5379\n",
      "  [train] step 700/741 | loss=0.5967\n",
      "  [train] step 710/741 | loss=0.6206\n",
      "  [train] step 720/741 | loss=0.5396\n",
      "  [train] step 730/741 | loss=0.6362\n",
      "  [train] step 740/741 | loss=0.5128\n",
      "Train: loss=0.5794, acc=0.955\n",
      "  [val] step 1/733 | loss=1.0074\n",
      "  [val] step 10/733 | loss=0.6131\n",
      "  [val] step 20/733 | loss=0.5102\n",
      "  [val] step 30/733 | loss=1.7078\n",
      "  [val] step 40/733 | loss=3.0216\n",
      "  [val] step 50/733 | loss=4.6804\n",
      "  [val] step 60/733 | loss=0.4458\n",
      "  [val] step 70/733 | loss=0.5513\n",
      "  [val] step 80/733 | loss=0.7532\n",
      "  [val] step 90/733 | loss=0.4837\n",
      "  [val] step 100/733 | loss=0.4568\n",
      "  [val] step 110/733 | loss=0.4944\n",
      "  [val] step 120/733 | loss=1.4145\n",
      "  [val] step 130/733 | loss=1.3057\n",
      "  [val] step 140/733 | loss=3.4291\n",
      "  [val] step 150/733 | loss=1.2003\n",
      "  [val] step 160/733 | loss=0.4827\n",
      "  [val] step 170/733 | loss=2.8107\n",
      "  [val] step 180/733 | loss=3.5263\n",
      "  [val] step 190/733 | loss=0.6009\n",
      "  [val] step 200/733 | loss=0.5958\n",
      "  [val] step 210/733 | loss=1.6028\n",
      "  [val] step 220/733 | loss=0.8711\n",
      "  [val] step 230/733 | loss=0.6403\n",
      "  [val] step 240/733 | loss=0.5391\n",
      "  [val] step 250/733 | loss=0.5397\n",
      "  [val] step 260/733 | loss=0.9723\n",
      "  [val] step 270/733 | loss=0.4897\n",
      "  [val] step 280/733 | loss=0.5863\n",
      "  [val] step 290/733 | loss=0.6180\n",
      "  [val] step 300/733 | loss=1.6405\n",
      "  [val] step 310/733 | loss=2.1549\n",
      "  [val] step 320/733 | loss=2.2005\n",
      "  [val] step 330/733 | loss=2.2094\n",
      "  [val] step 340/733 | loss=0.5580\n",
      "  [val] step 350/733 | loss=4.3020\n",
      "  [val] step 360/733 | loss=0.5742\n",
      "  [val] step 370/733 | loss=0.5608\n",
      "  [val] step 380/733 | loss=0.5479\n",
      "  [val] step 390/733 | loss=0.5630\n",
      "  [val] step 400/733 | loss=0.6364\n",
      "  [val] step 410/733 | loss=0.5769\n",
      "  [val] step 420/733 | loss=0.6288\n",
      "  [val] step 430/733 | loss=0.6531\n",
      "  [val] step 440/733 | loss=1.1951\n",
      "  [val] step 450/733 | loss=0.6422\n",
      "  [val] step 460/733 | loss=0.5251\n",
      "  [val] step 470/733 | loss=0.9641\n",
      "  [val] step 480/733 | loss=1.6015\n",
      "  [val] step 490/733 | loss=2.8758\n",
      "  [val] step 500/733 | loss=0.5002\n",
      "  [val] step 510/733 | loss=0.5966\n",
      "  [val] step 520/733 | loss=0.4574\n",
      "  [val] step 530/733 | loss=0.5043\n",
      "  [val] step 540/733 | loss=0.5302\n",
      "  [val] step 550/733 | loss=0.4459\n",
      "  [val] step 560/733 | loss=4.9789\n",
      "  [val] step 570/733 | loss=4.9288\n",
      "  [val] step 580/733 | loss=5.6527\n",
      "  [val] step 590/733 | loss=0.6305\n",
      "  [val] step 600/733 | loss=0.5073\n",
      "  [val] step 610/733 | loss=0.7498\n",
      "  [val] step 620/733 | loss=0.6406\n",
      "  [val] step 630/733 | loss=0.4812\n",
      "  [val] step 640/733 | loss=0.4748\n",
      "  [val] step 650/733 | loss=0.4532\n",
      "  [val] step 660/733 | loss=2.3190\n",
      "  [val] step 670/733 | loss=0.6622\n",
      "  [val] step 680/733 | loss=0.6126\n",
      "  [val] step 690/733 | loss=0.6974\n",
      "  [val] step 700/733 | loss=0.8430\n",
      "  [val] step 710/733 | loss=0.4731\n",
      "  [val] step 720/733 | loss=5.0347\n",
      "  [val] step 730/733 | loss=1.3131\n",
      "Val:   loss=1.4080, acc=0.696\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0     1     4     0     0     0   676     2     0     1]\n",
      " [    0     0     1     3     0   223     0   169    19     0     9]\n",
      " [   22     0     4     0     0    38     1    95    42     0    10]\n",
      " [    0     2     0     0     0     1     0    11     0     1    21]\n",
      " [    0     0     4     1    13    42     0   401   123     5     1]\n",
      " [    2     0    49     0     6   667     0  1139   235   179   135]\n",
      " [    0     0     3     2    47     3     0   457     1     4     1]\n",
      " [    8     0    47    36     4   144     1 14883   786   170    72]\n",
      " [    2     0     2     1     0     6     1   237   293     0     2]\n",
      " [    1     0    38     0     5   271     0   971     1   423    42]\n",
      " [    2     0    10     0     0     3     0     9    59     0    44]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.025     0.019     0.022       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.173     0.022     0.039       590\n",
      "           5      0.477     0.277     0.350      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.781     0.921     0.846     16151\n",
      "           8      0.188     0.539     0.278       544\n",
      "           9      0.541     0.241     0.334      1752\n",
      "          10      0.130     0.346     0.189       127\n",
      "\n",
      "    accuracy                          0.696     23450\n",
      "   macro avg      0.211     0.215     0.187     23450\n",
      "weighted avg      0.637     0.696     0.652     23450\n",
      "\n",
      "Macro-F1: 0.187 | Balanced Acc: 0.215\n",
      "\n",
      "Epoch 6/10\n",
      "  [train] step 1/741 | loss=0.5319\n",
      "  [train] step 10/741 | loss=0.5304\n",
      "  [train] step 20/741 | loss=0.5694\n",
      "  [train] step 30/741 | loss=0.6404\n",
      "  [train] step 40/741 | loss=0.5086\n",
      "  [train] step 50/741 | loss=0.5336\n",
      "  [train] step 60/741 | loss=0.6391\n",
      "  [train] step 70/741 | loss=0.5905\n",
      "  [train] step 80/741 | loss=0.5197\n",
      "  [train] step 90/741 | loss=0.5843\n",
      "  [train] step 100/741 | loss=0.5601\n",
      "  [train] step 110/741 | loss=0.4893\n",
      "  [train] step 120/741 | loss=0.5096\n",
      "  [train] step 130/741 | loss=0.5336\n",
      "  [train] step 140/741 | loss=0.5390\n",
      "  [train] step 150/741 | loss=0.5066\n",
      "  [train] step 160/741 | loss=0.5989\n",
      "  [train] step 170/741 | loss=0.5368\n",
      "  [train] step 180/741 | loss=0.6017\n",
      "  [train] step 190/741 | loss=0.5196\n",
      "  [train] step 200/741 | loss=0.6402\n",
      "  [train] step 210/741 | loss=0.5383\n",
      "  [train] step 220/741 | loss=0.5676\n",
      "  [train] step 230/741 | loss=0.5871\n",
      "  [train] step 240/741 | loss=0.5495\n",
      "  [train] step 250/741 | loss=0.5408\n",
      "  [train] step 260/741 | loss=0.5231\n",
      "  [train] step 270/741 | loss=0.6765\n",
      "  [train] step 280/741 | loss=0.4894\n",
      "  [train] step 290/741 | loss=0.7173\n",
      "  [train] step 300/741 | loss=0.5724\n",
      "  [train] step 310/741 | loss=0.5202\n",
      "  [train] step 320/741 | loss=0.6737\n",
      "  [train] step 330/741 | loss=0.5560\n",
      "  [train] step 340/741 | loss=0.4898\n",
      "  [train] step 350/741 | loss=0.6754\n",
      "  [train] step 360/741 | loss=0.5453\n",
      "  [train] step 370/741 | loss=0.8116\n",
      "  [train] step 380/741 | loss=0.6216\n",
      "  [train] step 390/741 | loss=0.5685\n",
      "  [train] step 400/741 | loss=0.5397\n",
      "  [train] step 410/741 | loss=0.5398\n",
      "  [train] step 420/741 | loss=0.5329\n",
      "  [train] step 430/741 | loss=0.6117\n",
      "  [train] step 440/741 | loss=0.6064\n",
      "  [train] step 450/741 | loss=0.5643\n",
      "  [train] step 460/741 | loss=0.5232\n",
      "  [train] step 470/741 | loss=0.5155\n",
      "  [train] step 480/741 | loss=0.5624\n",
      "  [train] step 490/741 | loss=0.5767\n",
      "  [train] step 500/741 | loss=0.6885\n",
      "  [train] step 510/741 | loss=0.6364\n",
      "  [train] step 520/741 | loss=0.5937\n",
      "  [train] step 530/741 | loss=0.6400\n",
      "  [train] step 540/741 | loss=0.6854\n",
      "  [train] step 550/741 | loss=0.6492\n",
      "  [train] step 560/741 | loss=0.4807\n",
      "  [train] step 570/741 | loss=0.6649\n",
      "  [train] step 580/741 | loss=0.4972\n",
      "  [train] step 590/741 | loss=0.4979\n",
      "  [train] step 600/741 | loss=0.5069\n",
      "  [train] step 610/741 | loss=0.5001\n",
      "  [train] step 620/741 | loss=0.5293\n",
      "  [train] step 630/741 | loss=0.4989\n",
      "  [train] step 640/741 | loss=0.5183\n",
      "  [train] step 650/741 | loss=0.4950\n",
      "  [train] step 660/741 | loss=0.4865\n",
      "  [train] step 670/741 | loss=0.5883\n",
      "  [train] step 680/741 | loss=0.6788\n",
      "  [train] step 690/741 | loss=0.5322\n",
      "  [train] step 700/741 | loss=0.4801\n",
      "  [train] step 710/741 | loss=0.6336\n",
      "  [train] step 720/741 | loss=0.5249\n",
      "  [train] step 730/741 | loss=0.5981\n",
      "  [train] step 740/741 | loss=0.5370\n",
      "Train: loss=0.5729, acc=0.956\n",
      "  [val] step 1/733 | loss=1.1873\n",
      "  [val] step 10/733 | loss=0.5650\n",
      "  [val] step 20/733 | loss=0.4784\n",
      "  [val] step 30/733 | loss=2.2981\n",
      "  [val] step 40/733 | loss=3.3641\n",
      "  [val] step 50/733 | loss=4.8612\n",
      "  [val] step 60/733 | loss=0.4530\n",
      "  [val] step 70/733 | loss=0.5146\n",
      "  [val] step 80/733 | loss=0.6696\n",
      "  [val] step 90/733 | loss=0.4691\n",
      "  [val] step 100/733 | loss=0.4688\n",
      "  [val] step 110/733 | loss=0.4649\n",
      "  [val] step 120/733 | loss=1.4306\n",
      "  [val] step 130/733 | loss=1.0395\n",
      "  [val] step 140/733 | loss=4.0206\n",
      "  [val] step 150/733 | loss=0.9079\n",
      "  [val] step 160/733 | loss=0.4605\n",
      "  [val] step 170/733 | loss=2.8474\n",
      "  [val] step 180/733 | loss=3.2642\n",
      "  [val] step 190/733 | loss=0.5734\n",
      "  [val] step 200/733 | loss=0.5389\n",
      "  [val] step 210/733 | loss=1.5636\n",
      "  [val] step 220/733 | loss=0.9600\n",
      "  [val] step 230/733 | loss=0.6332\n",
      "  [val] step 240/733 | loss=0.5244\n",
      "  [val] step 250/733 | loss=0.4923\n",
      "  [val] step 260/733 | loss=0.9203\n",
      "  [val] step 270/733 | loss=0.4617\n",
      "  [val] step 280/733 | loss=0.5291\n",
      "  [val] step 290/733 | loss=0.5236\n",
      "  [val] step 300/733 | loss=1.5961\n",
      "  [val] step 310/733 | loss=2.1648\n",
      "  [val] step 320/733 | loss=2.2091\n",
      "  [val] step 330/733 | loss=2.2166\n",
      "  [val] step 340/733 | loss=0.5496\n",
      "  [val] step 350/733 | loss=4.1198\n",
      "  [val] step 360/733 | loss=0.5437\n",
      "  [val] step 370/733 | loss=0.5385\n",
      "  [val] step 380/733 | loss=0.5163\n",
      "  [val] step 390/733 | loss=0.5510\n",
      "  [val] step 400/733 | loss=0.6064\n",
      "  [val] step 410/733 | loss=0.5365\n",
      "  [val] step 420/733 | loss=0.5593\n",
      "  [val] step 430/733 | loss=0.5896\n",
      "  [val] step 440/733 | loss=1.0345\n",
      "  [val] step 450/733 | loss=0.5389\n",
      "  [val] step 460/733 | loss=0.4910\n",
      "  [val] step 470/733 | loss=0.7030\n",
      "  [val] step 480/733 | loss=1.3906\n",
      "  [val] step 490/733 | loss=2.9364\n",
      "  [val] step 500/733 | loss=0.4832\n",
      "  [val] step 510/733 | loss=0.5488\n",
      "  [val] step 520/733 | loss=0.4543\n",
      "  [val] step 530/733 | loss=0.4697\n",
      "  [val] step 540/733 | loss=0.4863\n",
      "  [val] step 550/733 | loss=0.4422\n",
      "  [val] step 560/733 | loss=4.9983\n",
      "  [val] step 570/733 | loss=5.4224\n",
      "  [val] step 580/733 | loss=6.2933\n",
      "  [val] step 590/733 | loss=0.6242\n",
      "  [val] step 600/733 | loss=0.4938\n",
      "  [val] step 610/733 | loss=0.7006\n",
      "  [val] step 620/733 | loss=0.6264\n",
      "  [val] step 630/733 | loss=0.4767\n",
      "  [val] step 640/733 | loss=0.4638\n",
      "  [val] step 650/733 | loss=0.4526\n",
      "  [val] step 660/733 | loss=2.6440\n",
      "  [val] step 670/733 | loss=0.6488\n",
      "  [val] step 680/733 | loss=0.5887\n",
      "  [val] step 690/733 | loss=0.5960\n",
      "  [val] step 700/733 | loss=0.6488\n",
      "  [val] step 710/733 | loss=0.4522\n",
      "  [val] step 720/733 | loss=5.0412\n",
      "  [val] step 730/733 | loss=1.0936\n",
      "Val:   loss=1.4215, acc=0.701\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0     0     3     0     0     0   678     2     0     1]\n",
      " [    0     0     0     1     0   194     0   199    20     0    10]\n",
      " [   12     1     3     0     0    43     0    98    43     0    12]\n",
      " [    0     3     0     0     0     1     0    13     0     1    18]\n",
      " [    0     0     1     1    10    28     0   443   103     2     2]\n",
      " [    0     2    17     0     1   629     0  1322   161   144   136]\n",
      " [    0     0     0     1    29     3     0   478     1     6     0]\n",
      " [    2     0    13    23     3   119     1 15167   634   120    69]\n",
      " [    0     0     0     0     0     7     1   269   265     0     2]\n",
      " [    0     2     5     0     2   302     0  1072     0   325    44]\n",
      " [    1     0     1     0     0     2     0    14    60     0    49]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.075     0.014     0.024       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.222     0.017     0.031       590\n",
      "           5      0.474     0.261     0.336      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.768     0.939     0.845     16151\n",
      "           8      0.206     0.487     0.289       544\n",
      "           9      0.543     0.186     0.277      1752\n",
      "          10      0.143     0.386     0.209       127\n",
      "\n",
      "    accuracy                          0.701     23450\n",
      "   macro avg      0.221     0.208     0.183     23450\n",
      "weighted avg      0.630     0.701     0.646     23450\n",
      "\n",
      "Macro-F1: 0.183 | Balanced Acc: 0.208\n",
      "\n",
      "Epoch 7/10\n",
      "  [train] step 1/741 | loss=0.5602\n",
      "  [train] step 10/741 | loss=0.5577\n",
      "  [train] step 20/741 | loss=0.5424\n",
      "  [train] step 30/741 | loss=0.5801\n",
      "  [train] step 40/741 | loss=0.5152\n",
      "  [train] step 50/741 | loss=0.5699\n",
      "  [train] step 60/741 | loss=0.5170\n",
      "  [train] step 70/741 | loss=0.5681\n",
      "  [train] step 80/741 | loss=0.4802\n",
      "  [train] step 90/741 | loss=0.7159\n",
      "  [train] step 100/741 | loss=0.6329\n",
      "  [train] step 110/741 | loss=0.5746\n",
      "  [train] step 120/741 | loss=0.6108\n",
      "  [train] step 130/741 | loss=0.4708\n",
      "  [train] step 140/741 | loss=0.6461\n",
      "  [train] step 150/741 | loss=0.5269\n",
      "  [train] step 160/741 | loss=0.5173\n",
      "  [train] step 170/741 | loss=0.5242\n",
      "  [train] step 180/741 | loss=0.5199\n",
      "  [train] step 190/741 | loss=0.5017\n",
      "  [train] step 200/741 | loss=0.4856\n",
      "  [train] step 210/741 | loss=0.5760\n",
      "  [train] step 220/741 | loss=0.5487\n",
      "  [train] step 230/741 | loss=0.4963\n",
      "  [train] step 240/741 | loss=0.5209\n",
      "  [train] step 250/741 | loss=0.5562\n",
      "  [train] step 260/741 | loss=0.5305\n",
      "  [train] step 270/741 | loss=0.5072\n",
      "  [train] step 280/741 | loss=0.5617\n",
      "  [train] step 290/741 | loss=0.5107\n",
      "  [train] step 300/741 | loss=0.5452\n",
      "  [train] step 310/741 | loss=0.5711\n",
      "  [train] step 320/741 | loss=0.5837\n",
      "  [train] step 330/741 | loss=0.6116\n",
      "  [train] step 340/741 | loss=0.5951\n",
      "  [train] step 350/741 | loss=0.4826\n",
      "  [train] step 360/741 | loss=0.5083\n",
      "  [train] step 370/741 | loss=0.5758\n",
      "  [train] step 380/741 | loss=0.5007\n",
      "  [train] step 390/741 | loss=0.5858\n",
      "  [train] step 400/741 | loss=0.6267\n",
      "  [train] step 410/741 | loss=0.5349\n",
      "  [train] step 420/741 | loss=0.5479\n",
      "  [train] step 430/741 | loss=0.5192\n",
      "  [train] step 440/741 | loss=0.4979\n",
      "  [train] step 450/741 | loss=0.5062\n",
      "  [train] step 460/741 | loss=0.6029\n",
      "  [train] step 470/741 | loss=0.4958\n",
      "  [train] step 480/741 | loss=0.6658\n",
      "  [train] step 490/741 | loss=0.6688\n",
      "  [train] step 500/741 | loss=0.4962\n",
      "  [train] step 510/741 | loss=0.6529\n",
      "  [train] step 520/741 | loss=0.4933\n",
      "  [train] step 530/741 | loss=0.4982\n",
      "  [train] step 540/741 | loss=0.5101\n",
      "  [train] step 550/741 | loss=0.5770\n",
      "  [train] step 560/741 | loss=0.5301\n",
      "  [train] step 570/741 | loss=0.5687\n",
      "  [train] step 580/741 | loss=0.5953\n",
      "  [train] step 590/741 | loss=0.5066\n",
      "  [train] step 600/741 | loss=0.4999\n",
      "  [train] step 610/741 | loss=0.5363\n",
      "  [train] step 620/741 | loss=0.5137\n",
      "  [train] step 630/741 | loss=0.6641\n",
      "  [train] step 640/741 | loss=0.5370\n",
      "  [train] step 650/741 | loss=0.5281\n",
      "  [train] step 660/741 | loss=0.5204\n",
      "  [train] step 670/741 | loss=0.5003\n",
      "  [train] step 680/741 | loss=0.5651\n",
      "  [train] step 690/741 | loss=0.6084\n",
      "  [train] step 700/741 | loss=0.6548\n",
      "  [train] step 710/741 | loss=0.5031\n",
      "  [train] step 720/741 | loss=0.6435\n",
      "  [train] step 730/741 | loss=0.5736\n",
      "  [train] step 740/741 | loss=0.6195\n",
      "Train: loss=0.5640, acc=0.960\n",
      "  [val] step 1/733 | loss=0.9285\n",
      "  [val] step 10/733 | loss=0.5690\n",
      "  [val] step 20/733 | loss=0.5040\n",
      "  [val] step 30/733 | loss=2.4098\n",
      "  [val] step 40/733 | loss=3.4675\n",
      "  [val] step 50/733 | loss=5.2733\n",
      "  [val] step 60/733 | loss=0.4522\n",
      "  [val] step 70/733 | loss=0.5329\n",
      "  [val] step 80/733 | loss=0.6872\n",
      "  [val] step 90/733 | loss=0.4863\n",
      "  [val] step 100/733 | loss=0.4681\n",
      "  [val] step 110/733 | loss=0.4747\n",
      "  [val] step 120/733 | loss=1.6191\n",
      "  [val] step 130/733 | loss=1.0812\n",
      "  [val] step 140/733 | loss=3.4988\n",
      "  [val] step 150/733 | loss=0.9994\n",
      "  [val] step 160/733 | loss=0.4867\n",
      "  [val] step 170/733 | loss=2.5966\n",
      "  [val] step 180/733 | loss=3.5359\n",
      "  [val] step 190/733 | loss=0.5653\n",
      "  [val] step 200/733 | loss=0.5724\n",
      "  [val] step 210/733 | loss=1.7222\n",
      "  [val] step 220/733 | loss=1.0582\n",
      "  [val] step 230/733 | loss=0.6045\n",
      "  [val] step 240/733 | loss=0.5264\n",
      "  [val] step 250/733 | loss=0.5102\n",
      "  [val] step 260/733 | loss=0.9469\n",
      "  [val] step 270/733 | loss=0.4733\n",
      "  [val] step 280/733 | loss=0.5477\n",
      "  [val] step 290/733 | loss=0.6240\n",
      "  [val] step 300/733 | loss=1.6801\n",
      "  [val] step 310/733 | loss=2.4409\n",
      "  [val] step 320/733 | loss=2.3135\n",
      "  [val] step 330/733 | loss=2.3822\n",
      "  [val] step 340/733 | loss=0.5490\n",
      "  [val] step 350/733 | loss=4.2176\n",
      "  [val] step 360/733 | loss=0.5589\n",
      "  [val] step 370/733 | loss=0.5368\n",
      "  [val] step 380/733 | loss=0.5389\n",
      "  [val] step 390/733 | loss=0.5672\n",
      "  [val] step 400/733 | loss=0.6217\n",
      "  [val] step 410/733 | loss=0.5573\n",
      "  [val] step 420/733 | loss=0.5642\n",
      "  [val] step 430/733 | loss=0.6041\n",
      "  [val] step 440/733 | loss=1.1071\n",
      "  [val] step 450/733 | loss=0.5819\n",
      "  [val] step 460/733 | loss=0.5254\n",
      "  [val] step 470/733 | loss=0.7180\n",
      "  [val] step 480/733 | loss=1.4268\n",
      "  [val] step 490/733 | loss=3.0238\n",
      "  [val] step 500/733 | loss=0.4918\n",
      "  [val] step 510/733 | loss=0.5756\n",
      "  [val] step 520/733 | loss=0.4603\n",
      "  [val] step 530/733 | loss=0.4834\n",
      "  [val] step 540/733 | loss=0.5187\n",
      "  [val] step 550/733 | loss=0.4476\n",
      "  [val] step 560/733 | loss=4.9588\n",
      "  [val] step 570/733 | loss=4.7532\n",
      "  [val] step 580/733 | loss=5.4065\n",
      "  [val] step 590/733 | loss=0.6318\n",
      "  [val] step 600/733 | loss=0.5069\n",
      "  [val] step 610/733 | loss=0.7686\n",
      "  [val] step 620/733 | loss=0.6104\n",
      "  [val] step 630/733 | loss=0.4859\n",
      "  [val] step 640/733 | loss=0.4624\n",
      "  [val] step 650/733 | loss=0.4535\n",
      "  [val] step 660/733 | loss=2.5558\n",
      "  [val] step 670/733 | loss=0.6521\n",
      "  [val] step 680/733 | loss=0.6191\n",
      "  [val] step 690/733 | loss=0.7278\n",
      "  [val] step 700/733 | loss=0.8172\n",
      "  [val] step 710/733 | loss=0.4738\n",
      "  [val] step 720/733 | loss=5.1313\n",
      "  [val] step 730/733 | loss=1.2640\n",
      "Val:   loss=1.4157, acc=0.700\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    2     0     3     2     0     1     0   676     0     0     0]\n",
      " [    0     0    14     0     0   225     0   161    16     0     8]\n",
      " [   23     0     3     0     0    44     1    95    34     0    12]\n",
      " [    0     3     0     0     0     0     0    13     0     1    19]\n",
      " [    1     0     6     1     9    30     0   439    99     4     1]\n",
      " [    1     0    77     0     1   617     0  1298   142   186    90]\n",
      " [    0     0     5     0    33     5     0   468     1     5     1]\n",
      " [   13     1    95    18     2    96     1 15060   666   144    55]\n",
      " [    6     1     5     0     0     4     2   268   256     0     2]\n",
      " [    7     1    63     0     4   244     0   991     0   416    26]\n",
      " [    3     0    16     0     0     4     0     7    54     0    43]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.036     0.003     0.005       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.010     0.014     0.012       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.184     0.015     0.028       590\n",
      "           5      0.486     0.256     0.335      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.773     0.932     0.845     16151\n",
      "           8      0.202     0.471     0.283       544\n",
      "           9      0.550     0.237     0.332      1752\n",
      "          10      0.167     0.339     0.224       127\n",
      "\n",
      "    accuracy                          0.700     23450\n",
      "   macro avg      0.219     0.206     0.188     23450\n",
      "weighted avg      0.635     0.700     0.650     23450\n",
      "\n",
      "Macro-F1: 0.188 | Balanced Acc: 0.206\n",
      "\n",
      "Epoch 8/10\n",
      "  [train] step 1/741 | loss=0.4949\n",
      "  [train] step 10/741 | loss=0.5997\n",
      "  [train] step 20/741 | loss=0.4964\n",
      "  [train] step 30/741 | loss=0.5954\n",
      "  [train] step 40/741 | loss=0.4921\n",
      "  [train] step 50/741 | loss=0.5377\n",
      "  [train] step 60/741 | loss=0.5420\n",
      "  [train] step 70/741 | loss=0.5931\n",
      "  [train] step 80/741 | loss=0.4793\n",
      "  [train] step 90/741 | loss=0.4728\n",
      "  [train] step 100/741 | loss=0.4991\n",
      "  [train] step 110/741 | loss=0.5286\n",
      "  [train] step 120/741 | loss=0.5347\n",
      "  [train] step 130/741 | loss=0.5067\n",
      "  [train] step 140/741 | loss=0.4438\n",
      "  [train] step 150/741 | loss=0.5757\n",
      "  [train] step 160/741 | loss=0.6629\n",
      "  [train] step 170/741 | loss=0.5804\n",
      "  [train] step 180/741 | loss=0.5395\n",
      "  [train] step 190/741 | loss=0.5562\n",
      "  [train] step 200/741 | loss=0.5983\n",
      "  [train] step 210/741 | loss=0.5550\n",
      "  [train] step 220/741 | loss=0.5624\n",
      "  [train] step 230/741 | loss=0.5516\n",
      "  [train] step 240/741 | loss=0.5099\n",
      "  [train] step 250/741 | loss=0.6946\n",
      "  [train] step 260/741 | loss=0.5829\n",
      "  [train] step 270/741 | loss=0.5681\n",
      "  [train] step 280/741 | loss=0.5101\n",
      "  [train] step 290/741 | loss=0.5123\n",
      "  [train] step 300/741 | loss=0.5281\n",
      "  [train] step 310/741 | loss=0.6173\n",
      "  [train] step 320/741 | loss=0.6309\n",
      "  [train] step 330/741 | loss=0.5107\n",
      "  [train] step 340/741 | loss=0.4969\n",
      "  [train] step 350/741 | loss=0.5366\n",
      "  [train] step 360/741 | loss=0.5587\n",
      "  [train] step 370/741 | loss=0.5464\n",
      "  [train] step 380/741 | loss=0.5224\n",
      "  [train] step 390/741 | loss=0.4991\n",
      "  [train] step 400/741 | loss=0.5534\n",
      "  [train] step 410/741 | loss=0.5292\n",
      "  [train] step 420/741 | loss=0.5023\n",
      "  [train] step 430/741 | loss=0.5279\n",
      "  [train] step 440/741 | loss=0.5003\n",
      "  [train] step 450/741 | loss=0.5980\n",
      "  [train] step 460/741 | loss=0.6364\n",
      "  [train] step 470/741 | loss=0.4722\n",
      "  [train] step 480/741 | loss=0.5182\n",
      "  [train] step 490/741 | loss=0.9532\n",
      "  [train] step 500/741 | loss=0.5780\n",
      "  [train] step 510/741 | loss=0.5504\n",
      "  [train] step 520/741 | loss=0.5844\n",
      "  [train] step 530/741 | loss=0.5879\n",
      "  [train] step 540/741 | loss=0.4764\n",
      "  [train] step 550/741 | loss=0.5726\n",
      "  [train] step 560/741 | loss=0.5239\n",
      "  [train] step 570/741 | loss=0.4824\n",
      "  [train] step 580/741 | loss=0.6143\n",
      "  [train] step 590/741 | loss=0.6065\n",
      "  [train] step 600/741 | loss=0.4888\n",
      "  [train] step 610/741 | loss=0.5346\n",
      "  [train] step 620/741 | loss=0.4857\n",
      "  [train] step 630/741 | loss=0.6269\n",
      "  [train] step 640/741 | loss=0.5382\n",
      "  [train] step 650/741 | loss=0.7610\n",
      "  [train] step 660/741 | loss=0.5520\n",
      "  [train] step 670/741 | loss=0.6254\n",
      "  [train] step 680/741 | loss=0.5335\n",
      "  [train] step 690/741 | loss=0.5071\n",
      "  [train] step 700/741 | loss=0.5066\n",
      "  [train] step 710/741 | loss=0.5745\n",
      "  [train] step 720/741 | loss=0.5461\n",
      "  [train] step 730/741 | loss=0.5080\n",
      "  [train] step 740/741 | loss=0.5134\n",
      "Train: loss=0.5599, acc=0.963\n",
      "  [val] step 1/733 | loss=1.0477\n",
      "  [val] step 10/733 | loss=0.5248\n",
      "  [val] step 20/733 | loss=0.4804\n",
      "  [val] step 30/733 | loss=2.3561\n",
      "  [val] step 40/733 | loss=3.6203\n",
      "  [val] step 50/733 | loss=5.4698\n",
      "  [val] step 60/733 | loss=0.4607\n",
      "  [val] step 70/733 | loss=0.5140\n",
      "  [val] step 80/733 | loss=0.5868\n",
      "  [val] step 90/733 | loss=0.4724\n",
      "  [val] step 100/733 | loss=0.4682\n",
      "  [val] step 110/733 | loss=0.4617\n",
      "  [val] step 120/733 | loss=1.5815\n",
      "  [val] step 130/733 | loss=1.3444\n",
      "  [val] step 140/733 | loss=3.9432\n",
      "  [val] step 150/733 | loss=1.1922\n",
      "  [val] step 160/733 | loss=0.4675\n",
      "  [val] step 170/733 | loss=2.7877\n",
      "  [val] step 180/733 | loss=3.3559\n",
      "  [val] step 190/733 | loss=0.5553\n",
      "  [val] step 200/733 | loss=0.5172\n",
      "  [val] step 210/733 | loss=1.3766\n",
      "  [val] step 220/733 | loss=0.9381\n",
      "  [val] step 230/733 | loss=0.5889\n",
      "  [val] step 240/733 | loss=0.4877\n",
      "  [val] step 250/733 | loss=0.4947\n",
      "  [val] step 260/733 | loss=0.9113\n",
      "  [val] step 270/733 | loss=0.4726\n",
      "  [val] step 280/733 | loss=0.5550\n",
      "  [val] step 290/733 | loss=0.5130\n",
      "  [val] step 300/733 | loss=1.8694\n",
      "  [val] step 310/733 | loss=2.4732\n",
      "  [val] step 320/733 | loss=2.4504\n",
      "  [val] step 330/733 | loss=2.4241\n",
      "  [val] step 340/733 | loss=0.5703\n",
      "  [val] step 350/733 | loss=4.4979\n",
      "  [val] step 360/733 | loss=0.5459\n",
      "  [val] step 370/733 | loss=0.5416\n",
      "  [val] step 380/733 | loss=0.5304\n",
      "  [val] step 390/733 | loss=0.5621\n",
      "  [val] step 400/733 | loss=0.6259\n",
      "  [val] step 410/733 | loss=0.6683\n",
      "  [val] step 420/733 | loss=0.5107\n",
      "  [val] step 430/733 | loss=0.5541\n",
      "  [val] step 440/733 | loss=0.9324\n",
      "  [val] step 450/733 | loss=0.5128\n",
      "  [val] step 460/733 | loss=0.4756\n",
      "  [val] step 470/733 | loss=0.8364\n",
      "  [val] step 480/733 | loss=1.6920\n",
      "  [val] step 490/733 | loss=3.0272\n",
      "  [val] step 500/733 | loss=0.4670\n",
      "  [val] step 510/733 | loss=0.5260\n",
      "  [val] step 520/733 | loss=0.4594\n",
      "  [val] step 530/733 | loss=0.4705\n",
      "  [val] step 540/733 | loss=0.4904\n",
      "  [val] step 550/733 | loss=0.4485\n",
      "  [val] step 560/733 | loss=5.1703\n",
      "  [val] step 570/733 | loss=5.4131\n",
      "  [val] step 580/733 | loss=6.2379\n",
      "  [val] step 590/733 | loss=0.6244\n",
      "  [val] step 600/733 | loss=0.4842\n",
      "  [val] step 610/733 | loss=0.6938\n",
      "  [val] step 620/733 | loss=0.6242\n",
      "  [val] step 630/733 | loss=0.4766\n",
      "  [val] step 640/733 | loss=0.4569\n",
      "  [val] step 650/733 | loss=0.4525\n",
      "  [val] step 660/733 | loss=2.8287\n",
      "  [val] step 670/733 | loss=0.6433\n",
      "  [val] step 680/733 | loss=0.6440\n",
      "  [val] step 690/733 | loss=0.6358\n",
      "  [val] step 700/733 | loss=0.6341\n",
      "  [val] step 710/733 | loss=0.4581\n",
      "  [val] step 720/733 | loss=5.0252\n",
      "  [val] step 730/733 | loss=1.4492\n",
      "Val:   loss=1.4559, acc=0.691\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0     0     2     0     0     0   675     6     0     1]\n",
      " [    0     1     2     1     0   216     0   165    32     0     7]\n",
      " [   17     0     2     0     0    50     0    82    55     0     6]\n",
      " [    0     1     0     0     0     0     0    17     0     0    18]\n",
      " [    0     0     1     0     8    42     0   405   130     4     0]\n",
      " [    1     0     7     0     1   548     0  1337   301   142    75]\n",
      " [    0     0     1     0    41     4     0   468     1     3     0]\n",
      " [    7     1    12     5     3   113     0 14957   901   108    44]\n",
      " [    1     0     0     0     0     7     0   213   321     0     2]\n",
      " [    0     0     5     0     2   276     0  1116     4   334    15]\n",
      " [    2     0     1     0     0     3     0     6    78     0    37]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.333     0.002     0.005       424\n",
      "           2      0.065     0.009     0.016       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.145     0.014     0.025       590\n",
      "           5      0.435     0.227     0.299      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.769     0.926     0.840     16151\n",
      "           8      0.176     0.590     0.271       544\n",
      "           9      0.565     0.191     0.285      1752\n",
      "          10      0.180     0.291     0.223       127\n",
      "\n",
      "    accuracy                          0.691     23450\n",
      "   macro avg      0.243     0.205     0.179     23450\n",
      "weighted avg      0.632     0.691     0.639     23450\n",
      "\n",
      "Macro-F1: 0.179 | Balanced Acc: 0.205\n",
      "\n",
      "Epoch 9/10\n",
      "  [train] step 1/741 | loss=0.5025\n",
      "  [train] step 10/741 | loss=0.6010\n",
      "  [train] step 20/741 | loss=0.5185\n",
      "  [train] step 30/741 | loss=0.5603\n",
      "  [train] step 40/741 | loss=0.5402\n",
      "  [train] step 50/741 | loss=0.4374\n",
      "  [train] step 60/741 | loss=0.5609\n",
      "  [train] step 70/741 | loss=0.4712\n",
      "  [train] step 80/741 | loss=0.5642\n",
      "  [train] step 90/741 | loss=0.5043\n",
      "  [train] step 100/741 | loss=0.5520\n",
      "  [train] step 110/741 | loss=0.5483\n",
      "  [train] step 120/741 | loss=0.5379\n",
      "  [train] step 130/741 | loss=0.5364\n",
      "  [train] step 140/741 | loss=0.6201\n",
      "  [train] step 150/741 | loss=0.6861\n",
      "  [train] step 160/741 | loss=0.5128\n",
      "  [train] step 170/741 | loss=0.5798\n",
      "  [train] step 180/741 | loss=0.5863\n",
      "  [train] step 190/741 | loss=0.5097\n",
      "  [train] step 200/741 | loss=0.5773\n",
      "  [train] step 210/741 | loss=0.5187\n",
      "  [train] step 220/741 | loss=0.6532\n",
      "  [train] step 230/741 | loss=0.5027\n",
      "  [train] step 240/741 | loss=0.6955\n",
      "  [train] step 250/741 | loss=0.5732\n",
      "  [train] step 260/741 | loss=0.6108\n",
      "  [train] step 270/741 | loss=0.5047\n",
      "  [train] step 280/741 | loss=0.5921\n",
      "  [train] step 290/741 | loss=0.5339\n",
      "  [train] step 300/741 | loss=0.5722\n",
      "  [train] step 310/741 | loss=0.6870\n",
      "  [train] step 320/741 | loss=0.5709\n",
      "  [train] step 330/741 | loss=0.5406\n",
      "  [train] step 340/741 | loss=0.6020\n",
      "  [train] step 350/741 | loss=0.5512\n",
      "  [train] step 360/741 | loss=0.4884\n",
      "  [train] step 370/741 | loss=0.5343\n",
      "  [train] step 380/741 | loss=0.6683\n",
      "  [train] step 390/741 | loss=0.6508\n",
      "  [train] step 400/741 | loss=0.6264\n",
      "  [train] step 410/741 | loss=0.5915\n",
      "  [train] step 420/741 | loss=0.6186\n",
      "  [train] step 430/741 | loss=0.6407\n",
      "  [train] step 440/741 | loss=0.4726\n",
      "  [train] step 450/741 | loss=0.5909\n",
      "  [train] step 460/741 | loss=0.5415\n",
      "  [train] step 470/741 | loss=0.5800\n",
      "  [train] step 480/741 | loss=0.5559\n",
      "  [train] step 490/741 | loss=0.5196\n",
      "  [train] step 500/741 | loss=0.7787\n",
      "  [train] step 510/741 | loss=0.5868\n",
      "  [train] step 520/741 | loss=0.5316\n",
      "  [train] step 530/741 | loss=0.4899\n",
      "  [train] step 540/741 | loss=0.5643\n",
      "  [train] step 550/741 | loss=0.6477\n",
      "  [train] step 560/741 | loss=0.5195\n",
      "  [train] step 570/741 | loss=0.4875\n",
      "  [train] step 580/741 | loss=0.5191\n",
      "  [train] step 590/741 | loss=0.5349\n",
      "  [train] step 600/741 | loss=0.4926\n",
      "  [train] step 610/741 | loss=0.4857\n",
      "  [train] step 620/741 | loss=0.5914\n",
      "  [train] step 630/741 | loss=0.4856\n",
      "  [train] step 640/741 | loss=0.6062\n",
      "  [train] step 650/741 | loss=0.6849\n",
      "  [train] step 660/741 | loss=0.5493\n",
      "  [train] step 670/741 | loss=0.4880\n",
      "  [train] step 680/741 | loss=0.5355\n",
      "  [train] step 690/741 | loss=0.4823\n",
      "  [train] step 700/741 | loss=0.5221\n",
      "  [train] step 710/741 | loss=0.5236\n",
      "  [train] step 720/741 | loss=0.4847\n",
      "  [train] step 730/741 | loss=0.5007\n",
      "  [train] step 740/741 | loss=0.7177\n",
      "Train: loss=0.5550, acc=0.965\n",
      "  [val] step 1/733 | loss=1.0198\n",
      "  [val] step 10/733 | loss=0.5575\n",
      "  [val] step 20/733 | loss=0.4834\n",
      "  [val] step 30/733 | loss=2.2859\n",
      "  [val] step 40/733 | loss=3.3524\n",
      "  [val] step 50/733 | loss=5.0517\n",
      "  [val] step 60/733 | loss=0.4572\n",
      "  [val] step 70/733 | loss=0.5059\n",
      "  [val] step 80/733 | loss=0.6581\n",
      "  [val] step 90/733 | loss=0.4807\n",
      "  [val] step 100/733 | loss=0.4718\n",
      "  [val] step 110/733 | loss=0.4628\n",
      "  [val] step 120/733 | loss=1.6097\n",
      "  [val] step 130/733 | loss=1.2868\n",
      "  [val] step 140/733 | loss=3.6854\n",
      "  [val] step 150/733 | loss=1.0809\n",
      "  [val] step 160/733 | loss=0.4703\n",
      "  [val] step 170/733 | loss=2.9034\n",
      "  [val] step 180/733 | loss=3.4325\n",
      "  [val] step 190/733 | loss=0.5785\n",
      "  [val] step 200/733 | loss=0.5359\n",
      "  [val] step 210/733 | loss=1.6976\n",
      "  [val] step 220/733 | loss=0.9166\n",
      "  [val] step 230/733 | loss=0.6007\n",
      "  [val] step 240/733 | loss=0.5019\n",
      "  [val] step 250/733 | loss=0.4985\n",
      "  [val] step 260/733 | loss=0.9189\n",
      "  [val] step 270/733 | loss=0.4621\n",
      "  [val] step 280/733 | loss=0.5379\n",
      "  [val] step 290/733 | loss=0.5542\n",
      "  [val] step 300/733 | loss=1.6457\n",
      "  [val] step 310/733 | loss=2.3814\n",
      "  [val] step 320/733 | loss=2.3768\n",
      "  [val] step 330/733 | loss=2.2730\n",
      "  [val] step 340/733 | loss=0.5199\n",
      "  [val] step 350/733 | loss=4.5575\n",
      "  [val] step 360/733 | loss=0.4970\n",
      "  [val] step 370/733 | loss=0.5072\n",
      "  [val] step 380/733 | loss=0.4921\n",
      "  [val] step 390/733 | loss=0.5170\n",
      "  [val] step 400/733 | loss=0.5773\n",
      "  [val] step 410/733 | loss=0.5822\n",
      "  [val] step 420/733 | loss=0.5483\n",
      "  [val] step 430/733 | loss=0.6200\n",
      "  [val] step 440/733 | loss=1.1103\n",
      "  [val] step 450/733 | loss=0.5548\n",
      "  [val] step 460/733 | loss=0.4966\n",
      "  [val] step 470/733 | loss=0.8216\n",
      "  [val] step 480/733 | loss=1.6009\n",
      "  [val] step 490/733 | loss=3.0341\n",
      "  [val] step 500/733 | loss=0.4748\n",
      "  [val] step 510/733 | loss=0.5480\n",
      "  [val] step 520/733 | loss=0.4570\n",
      "  [val] step 530/733 | loss=0.4712\n",
      "  [val] step 540/733 | loss=0.5075\n",
      "  [val] step 550/733 | loss=0.4464\n",
      "  [val] step 560/733 | loss=5.1592\n",
      "  [val] step 570/733 | loss=5.3042\n",
      "  [val] step 580/733 | loss=6.1896\n",
      "  [val] step 590/733 | loss=0.5895\n",
      "  [val] step 600/733 | loss=0.4900\n",
      "  [val] step 610/733 | loss=0.7308\n",
      "  [val] step 620/733 | loss=0.5958\n",
      "  [val] step 630/733 | loss=0.4688\n",
      "  [val] step 640/733 | loss=0.4568\n",
      "  [val] step 650/733 | loss=0.4532\n",
      "  [val] step 660/733 | loss=2.8367\n",
      "  [val] step 670/733 | loss=0.6448\n",
      "  [val] step 680/733 | loss=0.6162\n",
      "  [val] step 690/733 | loss=0.6286\n",
      "  [val] step 700/733 | loss=0.7185\n",
      "  [val] step 710/733 | loss=0.4633\n",
      "  [val] step 720/733 | loss=4.6605\n",
      "  [val] step 730/733 | loss=1.3063\n",
      "Val:   loss=1.4311, acc=0.698\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0     2     2     0     0     0   677     2     0     1]\n",
      " [    0     0     6     1     0   206     0   176    27     0     8]\n",
      " [   16     1     4     0     0    45     1    93    42     0    10]\n",
      " [    0     1     0     0     0     1     0    14     0     1    19]\n",
      " [    0     0     2     0    13    47     0   410   115     3     0]\n",
      " [    1     1    43     0     1   641     0  1272   190   175    88]\n",
      " [    0     0     3     0    40     5     0   465     1     4     0]\n",
      " [    5     0    54    11     5   119     0 15005   764   140    48]\n",
      " [    0     0     1     0     0    10     2   253   276     0     2]\n",
      " [    0     0    43     0     7   277     0  1016     0   383    26]\n",
      " [    0     0     8     0     0     6     0    15    57     0    41]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.024     0.019     0.021       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.197     0.022     0.040       590\n",
      "           5      0.472     0.266     0.340      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.774     0.929     0.844     16151\n",
      "           8      0.187     0.507     0.274       544\n",
      "           9      0.542     0.219     0.312      1752\n",
      "          10      0.169     0.323     0.222       127\n",
      "\n",
      "    accuracy                          0.698     23450\n",
      "   macro avg      0.215     0.208     0.187     23450\n",
      "weighted avg      0.632     0.698     0.648     23450\n",
      "\n",
      "Macro-F1: 0.187 | Balanced Acc: 0.208\n",
      "\n",
      "Epoch 10/10\n",
      "  [train] step 1/741 | loss=0.4900\n",
      "  [train] step 10/741 | loss=0.5114\n",
      "  [train] step 20/741 | loss=0.6153\n",
      "  [train] step 30/741 | loss=0.6995\n",
      "  [train] step 40/741 | loss=0.5049\n",
      "  [train] step 50/741 | loss=0.5507\n",
      "  [train] step 60/741 | loss=0.5857\n",
      "  [train] step 70/741 | loss=0.5268\n",
      "  [train] step 80/741 | loss=0.6253\n",
      "  [train] step 90/741 | loss=0.5432\n",
      "  [train] step 100/741 | loss=0.5529\n",
      "  [train] step 110/741 | loss=0.4510\n",
      "  [train] step 120/741 | loss=0.5414\n",
      "  [train] step 130/741 | loss=0.6180\n",
      "  [train] step 140/741 | loss=0.5427\n",
      "  [train] step 150/741 | loss=0.5033\n",
      "  [train] step 160/741 | loss=0.6171\n",
      "  [train] step 170/741 | loss=0.5560\n",
      "  [train] step 180/741 | loss=0.5513\n",
      "  [train] step 190/741 | loss=0.6249\n",
      "  [train] step 200/741 | loss=0.4922\n",
      "  [train] step 210/741 | loss=0.5016\n",
      "  [train] step 220/741 | loss=0.4927\n",
      "  [train] step 230/741 | loss=0.6487\n",
      "  [train] step 240/741 | loss=0.5755\n",
      "  [train] step 250/741 | loss=0.5853\n",
      "  [train] step 260/741 | loss=0.5373\n",
      "  [train] step 270/741 | loss=0.4883\n",
      "  [train] step 280/741 | loss=0.5173\n",
      "  [train] step 290/741 | loss=0.5592\n",
      "  [train] step 300/741 | loss=0.5389\n",
      "  [train] step 310/741 | loss=0.7323\n",
      "  [train] step 320/741 | loss=0.5629\n",
      "  [train] step 330/741 | loss=0.5105\n",
      "  [train] step 340/741 | loss=0.5816\n",
      "  [train] step 350/741 | loss=0.6027\n",
      "  [train] step 360/741 | loss=0.5681\n",
      "  [train] step 370/741 | loss=0.5359\n",
      "  [train] step 380/741 | loss=0.5163\n",
      "  [train] step 390/741 | loss=0.5723\n",
      "  [train] step 400/741 | loss=0.5592\n",
      "  [train] step 410/741 | loss=0.5702\n",
      "  [train] step 420/741 | loss=0.6137\n",
      "  [train] step 430/741 | loss=0.5139\n",
      "  [train] step 440/741 | loss=0.5566\n",
      "  [train] step 450/741 | loss=0.6011\n",
      "  [train] step 460/741 | loss=0.5187\n",
      "  [train] step 470/741 | loss=0.5767\n",
      "  [train] step 480/741 | loss=0.6552\n",
      "  [train] step 490/741 | loss=0.5333\n",
      "  [train] step 500/741 | loss=0.5577\n",
      "  [train] step 510/741 | loss=0.6065\n",
      "  [train] step 520/741 | loss=0.6024\n",
      "  [train] step 530/741 | loss=0.5353\n",
      "  [train] step 540/741 | loss=0.5607\n",
      "  [train] step 550/741 | loss=0.5502\n",
      "  [train] step 560/741 | loss=0.5967\n",
      "  [train] step 570/741 | loss=0.4988\n",
      "  [train] step 580/741 | loss=0.5832\n",
      "  [train] step 590/741 | loss=0.5254\n",
      "  [train] step 600/741 | loss=0.6236\n",
      "  [train] step 610/741 | loss=0.5216\n",
      "  [train] step 620/741 | loss=0.5273\n",
      "  [train] step 630/741 | loss=0.6926\n",
      "  [train] step 640/741 | loss=0.5775\n",
      "  [train] step 650/741 | loss=0.6139\n",
      "  [train] step 660/741 | loss=0.5723\n",
      "  [train] step 670/741 | loss=0.5915\n",
      "  [train] step 680/741 | loss=0.5869\n",
      "  [train] step 690/741 | loss=0.5668\n",
      "  [train] step 700/741 | loss=0.5555\n",
      "  [train] step 710/741 | loss=0.5424\n",
      "  [train] step 720/741 | loss=0.5723\n",
      "  [train] step 730/741 | loss=0.4963\n",
      "  [train] step 740/741 | loss=0.6128\n",
      "Train: loss=0.5538, acc=0.965\n",
      "  [val] step 1/733 | loss=1.0249\n",
      "  [val] step 10/733 | loss=0.5600\n",
      "  [val] step 20/733 | loss=0.4836\n",
      "  [val] step 30/733 | loss=2.1590\n",
      "  [val] step 40/733 | loss=2.9342\n",
      "  [val] step 50/733 | loss=4.7667\n",
      "  [val] step 60/733 | loss=0.4628\n",
      "  [val] step 70/733 | loss=0.5428\n",
      "  [val] step 80/733 | loss=0.6872\n",
      "  [val] step 90/733 | loss=0.4837\n",
      "  [val] step 100/733 | loss=0.4595\n",
      "  [val] step 110/733 | loss=0.4605\n",
      "  [val] step 120/733 | loss=1.6999\n",
      "  [val] step 130/733 | loss=1.7537\n",
      "  [val] step 140/733 | loss=3.7348\n",
      "  [val] step 150/733 | loss=1.2863\n",
      "  [val] step 160/733 | loss=0.4704\n",
      "  [val] step 170/733 | loss=2.8292\n",
      "  [val] step 180/733 | loss=3.3825\n",
      "  [val] step 190/733 | loss=0.5988\n",
      "  [val] step 200/733 | loss=0.5286\n",
      "  [val] step 210/733 | loss=1.5919\n",
      "  [val] step 220/733 | loss=1.0097\n",
      "  [val] step 230/733 | loss=0.6681\n",
      "  [val] step 240/733 | loss=0.5321\n",
      "  [val] step 250/733 | loss=0.5417\n",
      "  [val] step 260/733 | loss=1.0514\n",
      "  [val] step 270/733 | loss=0.4802\n",
      "  [val] step 280/733 | loss=0.6350\n",
      "  [val] step 290/733 | loss=0.5759\n",
      "  [val] step 300/733 | loss=1.7743\n",
      "  [val] step 310/733 | loss=2.3785\n",
      "  [val] step 320/733 | loss=2.2433\n",
      "  [val] step 330/733 | loss=2.1704\n",
      "  [val] step 340/733 | loss=0.5563\n",
      "  [val] step 350/733 | loss=4.3670\n",
      "  [val] step 360/733 | loss=0.6079\n",
      "  [val] step 370/733 | loss=0.5727\n",
      "  [val] step 380/733 | loss=0.5675\n",
      "  [val] step 390/733 | loss=0.5803\n",
      "  [val] step 400/733 | loss=0.6951\n",
      "  [val] step 410/733 | loss=0.5962\n",
      "  [val] step 420/733 | loss=0.5904\n",
      "  [val] step 430/733 | loss=0.6273\n",
      "  [val] step 440/733 | loss=1.1815\n",
      "  [val] step 450/733 | loss=0.5725\n",
      "  [val] step 460/733 | loss=0.5037\n",
      "  [val] step 470/733 | loss=1.0602\n",
      "  [val] step 480/733 | loss=1.8030\n",
      "  [val] step 490/733 | loss=3.0721\n",
      "  [val] step 500/733 | loss=0.4856\n",
      "  [val] step 510/733 | loss=0.5885\n",
      "  [val] step 520/733 | loss=0.4521\n",
      "  [val] step 530/733 | loss=0.5173\n",
      "  [val] step 540/733 | loss=0.5181\n",
      "  [val] step 550/733 | loss=0.4488\n",
      "  [val] step 560/733 | loss=4.9344\n",
      "  [val] step 570/733 | loss=5.2727\n",
      "  [val] step 580/733 | loss=6.1652\n",
      "  [val] step 590/733 | loss=0.6889\n",
      "  [val] step 600/733 | loss=0.5057\n",
      "  [val] step 610/733 | loss=0.7616\n",
      "  [val] step 620/733 | loss=0.6645\n",
      "  [val] step 630/733 | loss=0.4905\n",
      "  [val] step 640/733 | loss=0.4770\n",
      "  [val] step 650/733 | loss=0.4582\n",
      "  [val] step 660/733 | loss=2.5190\n",
      "  [val] step 670/733 | loss=0.6666\n",
      "  [val] step 680/733 | loss=0.5791\n",
      "  [val] step 690/733 | loss=0.6422\n",
      "  [val] step 700/733 | loss=0.7071\n",
      "  [val] step 710/733 | loss=0.4602\n",
      "  [val] step 720/733 | loss=4.7642\n",
      "  [val] step 730/733 | loss=1.2232\n",
      "Val:   loss=1.4397, acc=0.687\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0     3     2     0     1     0   673     5     0     0]\n",
      " [    0     0     6     1     0   241     0   144    26     0     6]\n",
      " [   14     0     5     0     0    57     0    72    52     0    12]\n",
      " [    0     1     0     0     0     1     0    12     0     1    21]\n",
      " [    0     0     1     0    11    71     0   381   122     4     0]\n",
      " [    2     0    35     0    10   639     0  1259   214   168    85]\n",
      " [    0     0     2     0    53     6     0   452     2     3     0]\n",
      " [    5     2    41    10     6   217     3 14663   970   173    61]\n",
      " [    1     0     1     0     0     7     2   206   326     0     1]\n",
      " [    0     0    35     0     6   303     0   965     0   422    21]\n",
      " [    0     0     5     0     0     8     0     9    61     0    44]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.037     0.024     0.029       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.128     0.019     0.033       590\n",
      "           5      0.412     0.265     0.322      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.778     0.908     0.838     16151\n",
      "           8      0.183     0.599     0.281       544\n",
      "           9      0.547     0.241     0.335      1752\n",
      "          10      0.175     0.346     0.233       127\n",
      "\n",
      "    accuracy                          0.687     23450\n",
      "   macro avg      0.206     0.218     0.188     23450\n",
      "weighted avg      0.628     0.687     0.644     23450\n",
      "\n",
      "Macro-F1: 0.188 | Balanced Acc: 0.218\n",
      "\n",
      "Training finished!\n",
      "Best validation accuracy: 0.706\n",
      "Elapsed time: 3029.7 sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Tiny ResNet50 sanity trainer (weighted-loss + stratification diagnostics)\n",
    "# \n",
    "# Adds **class-weighted CrossEntropyLoss** to handle class imbalance and a\n",
    "# **stratification report** to quantify how well Train/Val match the global\n",
    "# label distribution (zero-support warnings, per-class deviations, JSD).\n",
    "# Everything else remains identical to the baseline trainer.\n",
    "#\n",
    "# - Uses class-balanced (effective number) or inverse-frequency weights on TRAIN.\n",
    "# - Keeps dataset and DataLoader unchanged (no oversampling).\n",
    "# - Preserves label smoothing.\n",
    "# - Prints confusion matrix + per-class metrics for analysis.\n",
    "# - Saves a CSV summary of stratification to RESULTS_DIR for easy comparisons.\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# important order; !!!\n",
    "# --- Correct order ---\n",
    "import os\n",
    "GPU_INDEX = 1 # choose your GPU\n",
    "\n",
    "# Pin the GPU before importing torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Standard library imports\n",
    "# -------------------------\n",
    "import time, math, warnings\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------\n",
    "# Third-party imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# -------------------------\n",
    "# PyTorch / TorchVision\n",
    "# -------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch import amp\n",
    "\n",
    "# -------------------------\n",
    "# Scikit-learn utilities\n",
    "# -------------------------\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, f1_score\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# ========================\n",
    "# CONFIGURATION CONSTANTS\n",
    "# ========================\n",
    "CSV_PATH      = \"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_filtered.csv\"\n",
    "IMG_ROOT      = \"/home/stud/fwag/bhome/ele670_project/data/raw/labelled_images\"\n",
    "RESULTS_DIR   = \"/home/stud/fwag/bhome/ele670_project/results\"\n",
    "SAVE_PATH     = os.path.join(RESULTS_DIR, \"tiny_resnet50_best_weighted.pt\")\n",
    "LABELS_NPY    = \"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\"\n",
    "\n",
    "\n",
    "# SPLIT_MODE: \"gss\" (GroupShuffleSplit 80/20) or \"grouped_class_balanced\" (greedy, class-coverage aware)\n",
    "SPLIT_MODE = \"grouped_class_balanced\"  # change to \"grouped_class_balanced\" to reduce zero-support classes in VAL\n",
    "\n",
    "# Optional: tag to differentiate experiment variants (appears in saved reports)\n",
    "EXPERIMENT_TAG = f\"weighted_cb_beta0.99_{SPLIT_MODE}\"\n",
    "\n",
    "IMG_SIZE      = 224\n",
    "BATCH_SIZE    = 32\n",
    "NUM_WORKERS   = 6\n",
    "EPOCHS        = 10  # for wiring/debug; consider 5–10 for clearer comparisons\n",
    "LR            = 1e-3\n",
    "WEIGHT_DECAY  = 1e-4\n",
    "LABEL_SMOOTH  = 0.05\n",
    "FREEZE_BACKBONE = True\n",
    "USE_PRETRAINED = True\n",
    "SEED          = 42\n",
    "LOG_EVERY     = 10\n",
    "\n",
    "# ----------------------------\n",
    "# (1) Reproducibility + GPU pinning\n",
    "# ----------------------------\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available() and GPU_INDEX is not None:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ========================\n",
    "# DATASET IMPLEMENTATION\n",
    "# ========================\n",
    "class KvasirDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(self.img_root, row[\"image_path\"])\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, UnidentifiedImageError):\n",
    "            print(f\"[WARN] Missing/corrupt: {path}\")\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        x = self.transform(img)\n",
    "        y = int(row[\"encoded_label\"])\n",
    "        return x, y\n",
    "\n",
    "# ==================\n",
    "# LOAD METADATA\n",
    "# ==================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Loaded metadata:\")\n",
    "print(df.head())\n",
    "\n",
    "num_classes = df[\"encoded_label\"].nunique()\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# ===========================\n",
    "# SPLITTING (Group-safe, with optional class-aware balancing)\n",
    "# ===========================\n",
    "# SPLIT_MODE: \"gss\" (GroupShuffleSplit 80/20) or \"grouped_class_balanced\" (greedy, class-coverage aware)\n",
    "#SPLIT_MODE = \"grouped_class_balanced\"  # change to \"grouped_class_balanced\" to reduce zero-support classes in VAL\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def build_video_targets(df, label_col=\"encoded_label\"):\n",
    "    vids = sorted(df[\"video_id\"].unique())\n",
    "    video_targets = {}\n",
    "    for v, g in df.groupby(\"video_id\"):\n",
    "        labs = g[label_col].unique().astype(int)\n",
    "        video_targets[v] = set(labs.tolist())\n",
    "    return vids, video_targets\n",
    "\n",
    "def grouped_class_balanced_split(df, n_splits=2, val_frac=0.2, seed=SEED, label_col=\"encoded_label\"):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    vids, video_targets = build_video_targets(df, label_col)\n",
    "    K = df[label_col].nunique()\n",
    "\n",
    "    # start with empty folds (we will use fold 0 as VAL)\n",
    "    folds = [set() for _ in range(n_splits)]\n",
    "    fold_counts = [np.zeros(K, dtype=int) for _ in range(n_splits)]\n",
    "\n",
    "    # sort videos by difficulty (more classes first)\n",
    "    vids_sorted = sorted(vids, key=lambda v: len(video_targets[v]), reverse=True)\n",
    "\n",
    "    for v in vids_sorted:\n",
    "        cls_set = video_targets[v]\n",
    "        # score each fold by resulting std of per-class counts if we add v\n",
    "        scores = []\n",
    "        for f in range(n_splits):\n",
    "            sim = fold_counts[f].copy()\n",
    "            for c in cls_set:\n",
    "                sim[c] += 1\n",
    "            scores.append((sim.std(), f))\n",
    "        _, best_f = min(scores, key=lambda t: (t[0], rng.rand()))\n",
    "        folds[best_f].add(v)\n",
    "        for c in cls_set:\n",
    "            fold_counts[best_f][c] += 1\n",
    "\n",
    "    # choose fold with ~val_frac of videos as VAL; else merge smallest folds until size ~= val_frac\n",
    "    fold_sizes = [len(f) for f in folds]\n",
    "    val_f = int(np.argmin([abs(s/len(vids) - val_frac) for s in fold_sizes]))\n",
    "    val_videos = folds[val_f]\n",
    "\n",
    "    df_train = df[~df[\"video_id\"].isin(val_videos)].copy()\n",
    "    df_val   = df[ df[\"video_id\"].isin(val_videos)].copy()\n",
    "    return df_train, df_val\n",
    "\n",
    "if SPLIT_MODE == \"gss\":\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "    train_idx, val_idx = next(gss.split(df, groups=df[\"video_id\"]))\n",
    "    df_train, df_val = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()\n",
    "else:\n",
    "    df_train, df_val = grouped_class_balanced_split(df, n_splits=2, val_frac=0.2, seed=SEED, label_col=\"encoded_label\")\n",
    "\n",
    "print(f\"Train samples: {len(df_train)} | Val samples: {len(df_val)}\")\n",
    "\n",
    "# ===============================\n",
    "# STRATIFICATION DIAGNOSTICS CELL\n",
    "# ===============================\n",
    "\n",
    "def _js_divergence(p, q, eps=1e-12):\n",
    "    p = np.asarray(p, dtype=np.float64); q = np.asarray(q, dtype=np.float64)\n",
    "    p = np.clip(p, eps, 1.0); q = np.clip(q, eps, 1.0)\n",
    "    p /= p.sum(); q /= q.sum(); m = 0.5 * (p + q)\n",
    "    kl_pm = np.sum(p * np.log(p / m)); kl_qm = np.sum(q * np.log(q / m))\n",
    "    return 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "\n",
    "def stratification_report(df_all, df_tr, df_va, label_col=\"encoded_label\", labels_npy_path=None, save_csv=None, tag=None):\n",
    "    # Global distribution\n",
    "    g_counts = df_all[label_col].value_counts().sort_index()\n",
    "    classes = g_counts.index.tolist()\n",
    "    g_probs  = (g_counts / g_counts.sum()).values\n",
    "\n",
    "    # Train distribution\n",
    "    t_counts = df_tr[label_col].value_counts().reindex(classes, fill_value=0)\n",
    "    t_probs  = (t_counts / max(1, t_counts.sum())).values\n",
    "\n",
    "    # Val distribution\n",
    "    v_counts = df_va[label_col].value_counts().reindex(classes, fill_value=0)\n",
    "    v_probs  = (v_counts / max(1, v_counts.sum())).values\n",
    "\n",
    "    # Deviations\n",
    "    t_abs_pp = np.abs(t_probs - g_probs) * 100.0\n",
    "    v_abs_pp = np.abs(v_probs - g_probs) * 100.0\n",
    "    denom = np.where(g_probs > 0, g_probs, np.nan)\n",
    "    t_rel = np.abs(t_probs - g_probs) / denom * 100.0\n",
    "    v_rel = np.abs(v_probs - g_probs) / denom * 100.0\n",
    "\n",
    "    # Optional class names\n",
    "    id2name = {i: f\"class_{i}\" for i in classes}\n",
    "    try:\n",
    "        if labels_npy_path is not None:\n",
    "            names = np.load(labels_npy_path, allow_pickle=True)\n",
    "            id2name = {i: str(names[i]) for i in classes}\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    tbl = pd.DataFrame({\n",
    "        \"label_id\": classes,\n",
    "        \"class_name\": [id2name[i] for i in classes],\n",
    "        \"global_count\": g_counts.values,\n",
    "        \"global_pct\": (g_probs * 100).round(3),\n",
    "        \"train_count\": t_counts.values,\n",
    "        \"train_pct\": (t_probs * 100).round(3),\n",
    "        \"train_abs_dev_pp\": t_abs_pp.round(3),\n",
    "        \"train_rel_dev_%\": np.where(np.isfinite(t_rel), t_rel, np.nan).round(1),\n",
    "        \"val_count\": v_counts.values,\n",
    "        \"val_pct\": (v_probs * 100).round(3),\n",
    "        \"val_abs_dev_pp\": v_abs_pp.round(3),\n",
    "        \"val_rel_dev_%\": np.where(np.isfinite(v_rel), v_rel, np.nan).round(1),\n",
    "    })\n",
    "\n",
    "    # Summary metrics\n",
    "    t_jsd = _js_divergence(g_probs, t_probs)\n",
    "    v_jsd = _js_divergence(g_probs, v_probs)\n",
    "    zero_train = int((t_counts.values == 0).sum())\n",
    "    zero_val   = int((v_counts.values == 0).sum())\n",
    "\n",
    "    print(\"\\n[STRAT] per-class distribution and deviations:\")\n",
    "    print(tbl.to_string(index=False, max_rows=200))\n",
    "\n",
    "    print(\"\\n[STRAT][SUMMARY]\")\n",
    "    print(f\"  Zero-support classes: TRAIN={zero_train} | VAL={zero_val}\")\n",
    "    print(f\"  Train: mean abs dev = {t_abs_pp.mean():.2f} pp | max abs dev = {t_abs_pp.max():.2f} pp | JSD = {t_jsd:.4f}\")\n",
    "    print(f\"  Val  : mean abs dev = {v_abs_pp.mean():.2f} pp | max abs dev = {v_abs_pp.max():.2f} pp | JSD = {v_jsd:.4f}\")\n",
    "    if zero_val > 0:\n",
    "        print(\"  ⚠️  Val split has classes with support=0 — metrics for those classes are undefined. Consider a class-aware grouped split.\")\n",
    "\n",
    "    if save_csv:\n",
    "        out = tbl.copy()\n",
    "        out.insert(0, \"experiment_tag\", tag if tag else \"\")\n",
    "        out.to_csv(save_csv, index=False)\n",
    "        print(f\"[STRAT] saved → {save_csv}\")\n",
    "\n",
    "    return {\n",
    "        \"table\": tbl,\n",
    "        \"train_jsd\": float(t_jsd),\n",
    "        \"val_jsd\": float(v_jsd),\n",
    "        \"train_mean_abs_pp\": float(t_abs_pp.mean()),\n",
    "        \"val_mean_abs_pp\": float(v_abs_pp.mean()),\n",
    "        \"zero_train\": zero_train,\n",
    "        \"zero_val\": zero_val,\n",
    "    }\n",
    "\n",
    "# Run diagnostics and persist CSV for experiment tracking\n",
    "_ = stratification_report(\n",
    "    df_all=df, df_tr=df_train, df_va=df_val,\n",
    "    label_col=\"encoded_label\",\n",
    "    labels_npy_path=LABELS_NPY,\n",
    "    save_csv=os.path.join(RESULTS_DIR, f\"stratification_report_{EXPERIMENT_TAG}.csv\"),\n",
    "    tag=EXPERIMENT_TAG,\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# TRANSFORMS & LOADERS\n",
    "# =====================\n",
    "mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_ds = KvasirDataset(df_train, IMG_ROOT, train_tf)\n",
    "val_ds   = KvasirDataset(df_val,   IMG_ROOT, val_tf)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4\n",
    ")\n",
    "\n",
    "# ==================\n",
    "# MODEL\n",
    "# ==================\n",
    "if USE_PRETRAINED:\n",
    "    try:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "    except AttributeError:\n",
    "        weights = \"IMAGENET1K_V2\"\n",
    "    model = models.resnet50(weights=weights)\n",
    "else:\n",
    "    model = models.resnet50(weights=None)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "if FREEZE_BACKBONE:\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ======================================\n",
    "# COMPUTE CLASS WEIGHTS (TRAIN SPLIT ONLY) — CLEAN & CONSISTENT\n",
    "# ======================================\n",
    "counts = df_train[\"encoded_label\"].value_counts().sort_index()\n",
    "counts_idx_sorted = counts\n",
    "N, K = counts_idx_sorted.sum(), len(counts_idx_sorted)\n",
    "\n",
    "# ----- Class-Balanced (effective number) weights -----\n",
    "beta = 0.99  # try 0.995 or 0.999 if imbalance is extreme\n",
    "eff = 1.0 - np.power(beta, counts_idx_sorted.values)\n",
    "cb_w = ((1.0 - beta) / np.maximum(eff, 1e-12)).astype(np.float32)\n",
    "cb_w = cb_w / cb_w.min()\n",
    "\n",
    "# (Optional) inverse-frequency for reference/ablation\n",
    "inv_w = (N / (K * counts_idx_sorted.values)).astype(np.float32)\n",
    "inv_w = inv_w / inv_w.min()\n",
    "\n",
    "# Pick which to use for training:\n",
    "WEIGHT_MODE = \"class_balanced\"  # or \"invfreq\"\n",
    "w = cb_w if WEIGHT_MODE == \"class_balanced\" else inv_w\n",
    "class_weights = torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "print(f\"[WEIGHTS] mode={WEIGHT_MODE}  ->  min={w.min():.3f}, max={w.max():.3f}\")\n",
    "\n",
    "# ----- Build readable table (aligned with what you actually use) -----\n",
    "try:\n",
    "    classes = np.load(LABELS_NPY, allow_pickle=True)\n",
    "    id2name = {i: str(n) for i, n in enumerate(classes)}\n",
    "except Exception:\n",
    "    id2name = {i: f\"class_{i}\" for i in range(len(w))}\n",
    "\n",
    "weights_table = pd.DataFrame({\n",
    "    \"label_id\": counts_idx_sorted.index,\n",
    "    \"class_name\": [id2name[i] for i in counts_idx_sorted.index],\n",
    "    \"count_train\": counts_idx_sorted.values,\n",
    "    \"weight\": w,\n",
    "    \"invfreq_ref\": inv_w,\n",
    "    \"cb_ref\": cb_w,\n",
    "}).sort_values(\"weight\", ascending=False)\n",
    "\n",
    "print(\"\\n[CHECK] Train counts and weights used by loss:\")\n",
    "print(weights_table[[\"label_id\",\"class_name\",\"count_train\",\"weight\"]].to_string(index=False))\n",
    "\n",
    "# (Optional) persist for reproducibility\n",
    "# weights_csv = os.path.join(RESULTS_DIR, f\"train_class_weights_{WEIGHT_MODE}_{EXPERIMENT_TAG}.csv\")\n",
    "# weights_table.to_csv(weights_csv, index=False)\n",
    "# print(f\"[SAVED] {weights_csv}\")\n",
    "\n",
    "# ======================================\n",
    "# LOSS FUNCTION + OPTIMIZER\n",
    "# ======================================\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = amp.GradScaler('cuda') if DEVICE == 'cuda' else None\n",
    "\n",
    "# ======================\n",
    "# TRAIN / EVAL FUNCTIONS\n",
    "# ======================\n",
    "@torch.no_grad()\n",
    "def _accuracy(logits, labels):\n",
    "    return (logits.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "def run_epoch(loader, train=True, desc=\"train\"):\n",
    "    model.train(train)\n",
    "    total_loss, total_correct, total_seen = 0.0, 0, 0\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader, 1):\n",
    "        images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "        ctx = amp.autocast('cuda', enabled=(DEVICE=='cuda'))\n",
    "        with ctx:\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_seen += labels.size(0)\n",
    "            total_loss += float(loss.item()) * labels.size(0)\n",
    "        if step % LOG_EVERY == 0 or step == 1:\n",
    "            print(f\"  [{desc}] step {step}/{len(loader)} | loss={loss.item():.4f}\")\n",
    "    return total_loss / total_seen, total_correct / total_seen\n",
    "\n",
    "\n",
    "def collect_predictions(loader):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
    "                logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "    return np.concatenate(all_labels), np.concatenate(all_preds)\n",
    "\n",
    "# ============================\n",
    "# MAIN TRAIN LOOP\n",
    "# ============================\n",
    "print(\"\\n==== START TRAINING (Weighted Loss) ====\\n\")\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True, desc=\"train\")\n",
    "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.3f}\")\n",
    "    vl_loss, vl_acc = run_epoch(val_loader, train=False, desc=\"val\")\n",
    "    print(f\"Val:   loss={vl_loss:.4f}, acc={vl_acc:.3f}\")\n",
    "\n",
    "    if vl_acc > best_val_acc:\n",
    "        best_val_acc = vl_acc\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  ✅ New best model saved → {SAVE_PATH} (acc={best_val_acc:.3f})\")\n",
    "\n",
    "    y_true, y_pred = collect_predictions(val_loader)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "    with np.printoptions(threshold=200, linewidth=200):\n",
    "        print(cm)\n",
    "\n",
    "    print(\"\\nPer-class metrics (validation):\")\n",
    "    print(classification_report(\n",
    "        y_true, y_pred, labels=list(range(num_classes)), digits=3\n",
    "    ))\n",
    "\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    bal_acc  = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f\"Macro-F1: {macro_f1:.3f} | Balanced Acc: {bal_acc:.3f}\")\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(\"Best validation accuracy:\", round(best_val_acc, 3))\n",
    "print(\"Elapsed time: %.1f sec\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf43ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3855333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla V100-PCIE-32GB\n",
      "Loaded metadata:\n",
      "                                       image_path        finding_class  \\\n",
      "0  Normal clean mucosa/0728084c8da942d9_22803.jpg  Normal clean mucosa   \n",
      "1  Normal clean mucosa/0728084c8da942d9_22804.jpg  Normal clean mucosa   \n",
      "2  Normal clean mucosa/0728084c8da942d9_22805.jpg  Normal clean mucosa   \n",
      "3  Normal clean mucosa/0728084c8da942d9_22806.jpg  Normal clean mucosa   \n",
      "4  Normal clean mucosa/0728084c8da942d9_22807.jpg  Normal clean mucosa   \n",
      "\n",
      "           video_id  encoded_label  \n",
      "0  0728084c8da942d9              7  \n",
      "1  0728084c8da942d9              7  \n",
      "2  0728084c8da942d9              7  \n",
      "3  0728084c8da942d9              7  \n",
      "4  0728084c8da942d9              7  \n",
      "Number of classes: 11\n",
      "Train samples: 23721 | Val samples: 23450\n",
      "\n",
      "[STRAT] per-class distribution and deviations:\n",
      " label_id           class_name  global_count  global_pct  train_count  train_pct  train_abs_dev_pp  train_rel_dev_%  val_count  val_pct  val_abs_dev_pp  val_rel_dev_%\n",
      "        0          Angiectasia           866       1.836          182      0.767             1.069             58.2        684    2.917           1.081           58.9\n",
      "        1        Blood - fresh           446       0.945           22      0.093             0.853             90.2        424    1.808           0.863           91.2\n",
      "        2              Erosion           507       1.075          295      1.244             0.169             15.7        212    0.904           0.171           15.9\n",
      "        3             Erythema           159       0.337          123      0.519             0.181             53.8         36    0.154           0.184           54.5\n",
      "        4         Foreign Body           776       1.645          186      0.784             0.861             52.3        590    2.516           0.871           52.9\n",
      "        5      Ileocecal valve          4189       8.880         1777      7.491             1.389             15.6       2412   10.286           1.405           15.8\n",
      "        6     Lymphangiectasia           592       1.255           74      0.312             0.943             75.1        518    2.209           0.954           76.0\n",
      "        7  Normal clean mucosa         34338      72.795        18187     76.670             3.876              5.3      16151   68.874           3.921            5.4\n",
      "        8              Pylorus          1538       3.260          994      4.190             0.930             28.5        544    2.320           0.941           28.9\n",
      "        9 Reduced Mucosal View          2906       6.161         1154      4.865             1.296             21.0       1752    7.471           1.311           21.3\n",
      "       10                Ulcer           854       1.810          727      3.065             1.254             69.3        127    0.542           1.269           70.1\n",
      "\n",
      "[STRAT][SUMMARY]\n",
      "  Zero-support classes: TRAIN=0 | VAL=0\n",
      "  Train: mean abs dev = 1.17 pp | max abs dev = 3.88 pp | JSD = 0.0076\n",
      "  Val  : mean abs dev = 1.18 pp | max abs dev = 3.92 pp | JSD = 0.0057\n",
      "[STRAT] saved → /home/stud/fwag/bhome/ele670_project/results/stratification_report_weighted_cb_beta0.99_grouped_class_balanced.csv\n",
      "[WEIGHTS] mode=class_balanced  ->  min=1.000, max=5.041\n",
      "\n",
      "[CHECK] Train counts and weights used by loss:\n",
      " label_id           class_name  count_train   weight\n",
      "        1        Blood - fresh           22 5.041100\n",
      "        6     Lymphangiectasia           74 1.905996\n",
      "        3             Erythema          123 1.409420\n",
      "        0          Angiectasia          182 1.191254\n",
      "        4         Foreign Body          186 1.182343\n",
      "        2              Erosion          295 1.054372\n",
      "       10                Ulcer          727 1.000672\n",
      "        8              Pylorus          994 1.000046\n",
      "        9 Reduced Mucosal View         1154 1.000009\n",
      "        5      Ileocecal valve         1777 1.000000\n",
      "        7  Normal clean mucosa        18187 1.000000\n",
      "\n",
      "==== START TRAINING (Weighted Loss) ====\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "  [train] step 1/741 | loss=2.5551\n",
      "  [train] step 10/741 | loss=1.1989\n",
      "  [train] step 20/741 | loss=1.1858\n",
      "  [train] step 30/741 | loss=0.8017\n",
      "  [train] step 40/741 | loss=0.9152\n",
      "  [train] step 50/741 | loss=0.8032\n",
      "  [train] step 60/741 | loss=1.3371\n",
      "  [train] step 70/741 | loss=0.8056\n",
      "  [train] step 80/741 | loss=1.2193\n",
      "  [train] step 90/741 | loss=0.6096\n",
      "  [train] step 100/741 | loss=0.8777\n",
      "  [train] step 110/741 | loss=0.7435\n",
      "  [train] step 120/741 | loss=1.0622\n",
      "  [train] step 130/741 | loss=0.9329\n",
      "  [train] step 140/741 | loss=0.7711\n",
      "  [train] step 150/741 | loss=1.0246\n",
      "  [train] step 160/741 | loss=0.6201\n",
      "  [train] step 170/741 | loss=0.4924\n",
      "  [train] step 180/741 | loss=0.7574\n",
      "  [train] step 190/741 | loss=0.6588\n",
      "  [train] step 200/741 | loss=0.7241\n",
      "  [train] step 210/741 | loss=0.4837\n",
      "  [train] step 220/741 | loss=0.6959\n",
      "  [train] step 230/741 | loss=0.7308\n",
      "  [train] step 240/741 | loss=0.6953\n",
      "  [train] step 250/741 | loss=0.5424\n",
      "  [train] step 260/741 | loss=0.6792\n",
      "  [train] step 270/741 | loss=0.6719\n",
      "  [train] step 280/741 | loss=0.5284\n",
      "  [train] step 290/741 | loss=0.6382\n",
      "  [train] step 300/741 | loss=0.6640\n",
      "  [train] step 310/741 | loss=0.7022\n",
      "  [train] step 320/741 | loss=0.6546\n",
      "  [train] step 330/741 | loss=0.7375\n",
      "  [train] step 340/741 | loss=0.5969\n",
      "  [train] step 350/741 | loss=0.7432\n",
      "  [train] step 360/741 | loss=0.5236\n",
      "  [train] step 370/741 | loss=0.6476\n",
      "  [train] step 380/741 | loss=0.5484\n",
      "  [train] step 390/741 | loss=0.6024\n",
      "  [train] step 400/741 | loss=0.6191\n",
      "  [train] step 410/741 | loss=0.6126\n",
      "  [train] step 420/741 | loss=0.5921\n",
      "  [train] step 430/741 | loss=0.6063\n",
      "  [train] step 440/741 | loss=0.6986\n",
      "  [train] step 450/741 | loss=0.6403\n",
      "  [train] step 460/741 | loss=0.9218\n",
      "  [train] step 470/741 | loss=0.6647\n",
      "  [train] step 480/741 | loss=0.6048\n",
      "  [train] step 490/741 | loss=0.5479\n",
      "  [train] step 500/741 | loss=0.8996\n",
      "  [train] step 510/741 | loss=0.5830\n",
      "  [train] step 520/741 | loss=0.6692\n",
      "  [train] step 530/741 | loss=0.5181\n",
      "  [train] step 540/741 | loss=0.5912\n",
      "  [train] step 550/741 | loss=0.6527\n",
      "  [train] step 560/741 | loss=0.6405\n",
      "  [train] step 570/741 | loss=0.4853\n",
      "  [train] step 580/741 | loss=0.6394\n",
      "  [train] step 590/741 | loss=0.5657\n",
      "  [train] step 600/741 | loss=0.5548\n",
      "  [train] step 610/741 | loss=0.7681\n",
      "  [train] step 620/741 | loss=0.5058\n",
      "  [train] step 630/741 | loss=0.6276\n",
      "  [train] step 640/741 | loss=0.7689\n",
      "  [train] step 650/741 | loss=0.7013\n",
      "  [train] step 660/741 | loss=0.6759\n",
      "  [train] step 670/741 | loss=0.4904\n",
      "  [train] step 680/741 | loss=0.7537\n",
      "  [train] step 690/741 | loss=0.5759\n",
      "  [train] step 700/741 | loss=0.4846\n",
      "  [train] step 710/741 | loss=0.5831\n",
      "  [train] step 720/741 | loss=0.6539\n",
      "  [train] step 730/741 | loss=0.4789\n",
      "  [train] step 740/741 | loss=0.4941\n",
      "Train: loss=0.6844, acc=0.915\n",
      "  [val] step 1/733 | loss=1.1206\n",
      "  [val] step 10/733 | loss=0.4969\n",
      "  [val] step 20/733 | loss=0.4662\n",
      "  [val] step 30/733 | loss=2.6063\n",
      "  [val] step 40/733 | loss=3.6148\n",
      "  [val] step 50/733 | loss=4.3415\n",
      "  [val] step 60/733 | loss=0.4435\n",
      "  [val] step 70/733 | loss=0.6986\n",
      "  [val] step 80/733 | loss=1.3590\n",
      "  [val] step 90/733 | loss=0.4327\n",
      "  [val] step 100/733 | loss=0.4413\n",
      "  [val] step 110/733 | loss=0.4384\n",
      "  [val] step 120/733 | loss=2.3191\n",
      "  [val] step 130/733 | loss=2.5833\n",
      "  [val] step 140/733 | loss=4.6615\n",
      "  [val] step 150/733 | loss=2.1504\n",
      "  [val] step 160/733 | loss=0.5174\n",
      "  [val] step 170/733 | loss=3.0656\n",
      "  [val] step 180/733 | loss=4.7237\n",
      "  [val] step 190/733 | loss=1.0946\n",
      "  [val] step 200/733 | loss=0.9609\n",
      "  [val] step 210/733 | loss=6.1169\n",
      "  [val] step 220/733 | loss=1.7191\n",
      "  [val] step 230/733 | loss=0.4636\n",
      "  [val] step 240/733 | loss=0.4639\n",
      "  [val] step 250/733 | loss=0.5615\n",
      "  [val] step 260/733 | loss=2.0740\n",
      "  [val] step 270/733 | loss=0.4555\n",
      "  [val] step 280/733 | loss=0.5827\n",
      "  [val] step 290/733 | loss=0.4417\n",
      "  [val] step 300/733 | loss=4.3344\n",
      "  [val] step 310/733 | loss=4.0030\n",
      "  [val] step 320/733 | loss=3.6345\n",
      "  [val] step 330/733 | loss=4.1539\n",
      "  [val] step 340/733 | loss=1.1891\n",
      "  [val] step 350/733 | loss=4.4933\n",
      "  [val] step 360/733 | loss=0.4263\n",
      "  [val] step 370/733 | loss=0.4273\n",
      "  [val] step 380/733 | loss=0.4298\n",
      "  [val] step 390/733 | loss=0.4321\n",
      "  [val] step 400/733 | loss=0.4299\n",
      "  [val] step 410/733 | loss=0.4632\n",
      "  [val] step 420/733 | loss=0.5267\n",
      "  [val] step 430/733 | loss=0.4722\n",
      "  [val] step 440/733 | loss=1.4420\n",
      "  [val] step 450/733 | loss=0.5335\n",
      "  [val] step 460/733 | loss=0.4260\n",
      "  [val] step 470/733 | loss=1.8577\n",
      "  [val] step 480/733 | loss=1.7145\n",
      "  [val] step 490/733 | loss=2.0761\n",
      "  [val] step 500/733 | loss=0.4354\n",
      "  [val] step 510/733 | loss=0.7126\n",
      "  [val] step 520/733 | loss=0.5054\n",
      "  [val] step 530/733 | loss=0.4625\n",
      "  [val] step 540/733 | loss=0.7869\n",
      "  [val] step 550/733 | loss=0.4741\n",
      "  [val] step 560/733 | loss=5.0596\n",
      "  [val] step 570/733 | loss=7.3454\n",
      "  [val] step 580/733 | loss=5.6296\n",
      "  [val] step 590/733 | loss=0.4351\n",
      "  [val] step 600/733 | loss=0.4298\n",
      "  [val] step 610/733 | loss=0.4540\n",
      "  [val] step 620/733 | loss=0.5684\n",
      "  [val] step 630/733 | loss=0.4326\n",
      "  [val] step 640/733 | loss=0.4353\n",
      "  [val] step 650/733 | loss=0.4305\n",
      "  [val] step 660/733 | loss=4.0324\n",
      "  [val] step 670/733 | loss=2.4459\n",
      "  [val] step 680/733 | loss=0.6381\n",
      "  [val] step 690/733 | loss=1.5655\n",
      "  [val] step 700/733 | loss=0.4646\n",
      "  [val] step 710/733 | loss=0.4336\n",
      "  [val] step 720/733 | loss=4.8558\n",
      "  [val] step 730/733 | loss=0.5683\n",
      "Val:   loss=1.6668, acc=0.621\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best_weighted.pt (acc=0.621)\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    0     0    18     7     0     0     0   632     9     0    18]\n",
      " [    5     0     0     0     0    80     0    38   287     0    14]\n",
      " [    0     0     0     0     0     0     0   117    48     0    47]\n",
      " [    0     0     1     0     0     0     0    12     2     0    21]\n",
      " [    0     0     0     0     1     1     0   301   253     9    25]\n",
      " [    0     0     0     0     0    43     0  1750   118   359   142]\n",
      " [    0     0     0     0    16     1     0   406    19    48    28]\n",
      " [    0     0     1     0     0    63     0 13641  1773    35   638]\n",
      " [    0     0     0     0     0     0     0   100   377     0    67]\n",
      " [    0     0     0     0     0    94     0   910    11   416   321]\n",
      " [    0     0     1     0     0     0     0    12    40     0    74]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.000     0.000     0.000       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.059     0.002     0.003       590\n",
      "           5      0.152     0.018     0.032      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.761     0.845     0.801     16151\n",
      "           8      0.128     0.693     0.217       544\n",
      "           9      0.480     0.237     0.318      1752\n",
      "          10      0.053     0.583     0.097       127\n",
      "\n",
      "    accuracy                          0.621     23450\n",
      "   macro avg      0.149     0.216     0.133     23450\n",
      "weighted avg      0.581     0.621     0.584     23450\n",
      "\n",
      "Macro-F1: 0.133 | Balanced Acc: 0.216\n",
      "\n",
      "Epoch 2/10\n",
      "  [train] step 1/741 | loss=0.4919\n",
      "  [train] step 10/741 | loss=0.8372\n",
      "  [train] step 20/741 | loss=0.5568\n",
      "  [train] step 30/741 | loss=0.6054\n",
      "  [train] step 40/741 | loss=0.5158\n",
      "  [train] step 50/741 | loss=0.4464\n",
      "  [train] step 60/741 | loss=0.4875\n",
      "  [train] step 70/741 | loss=0.5309\n",
      "  [train] step 80/741 | loss=0.5409\n",
      "  [train] step 90/741 | loss=0.6645\n",
      "  [train] step 100/741 | loss=0.5074\n",
      "  [train] step 110/741 | loss=0.8945\n",
      "  [train] step 120/741 | loss=0.5184\n",
      "  [train] step 130/741 | loss=0.5099\n",
      "  [train] step 140/741 | loss=0.5866\n",
      "  [train] step 150/741 | loss=0.5539\n",
      "  [train] step 160/741 | loss=0.5479\n",
      "  [train] step 170/741 | loss=0.5181\n",
      "  [train] step 180/741 | loss=0.5130\n",
      "  [train] step 190/741 | loss=0.6427\n",
      "  [train] step 200/741 | loss=0.6767\n",
      "  [train] step 210/741 | loss=0.5413\n",
      "  [train] step 220/741 | loss=0.5650\n",
      "  [train] step 230/741 | loss=0.4936\n",
      "  [train] step 240/741 | loss=0.7401\n",
      "  [train] step 250/741 | loss=0.5676\n",
      "  [train] step 260/741 | loss=0.4549\n",
      "  [train] step 270/741 | loss=0.5160\n",
      "  [train] step 280/741 | loss=0.6916\n",
      "  [train] step 290/741 | loss=0.4502\n",
      "  [train] step 300/741 | loss=0.5117\n",
      "  [train] step 310/741 | loss=0.5406\n",
      "  [train] step 320/741 | loss=0.5196\n",
      "  [train] step 330/741 | loss=0.5663\n",
      "  [train] step 340/741 | loss=0.4800\n",
      "  [train] step 350/741 | loss=0.5643\n",
      "  [train] step 360/741 | loss=0.4813\n",
      "  [train] step 370/741 | loss=0.6273\n",
      "  [train] step 380/741 | loss=0.6624\n",
      "  [train] step 390/741 | loss=0.5243\n",
      "  [train] step 400/741 | loss=0.5286\n",
      "  [train] step 410/741 | loss=0.4872\n",
      "  [train] step 420/741 | loss=0.6059\n",
      "  [train] step 430/741 | loss=0.5423\n",
      "  [train] step 440/741 | loss=0.5933\n",
      "  [train] step 450/741 | loss=0.5395\n",
      "  [train] step 460/741 | loss=0.4730\n",
      "  [train] step 470/741 | loss=0.4984\n",
      "  [train] step 480/741 | loss=0.5263\n",
      "  [train] step 490/741 | loss=0.5198\n",
      "  [train] step 500/741 | loss=0.5052\n",
      "  [train] step 510/741 | loss=0.4585\n",
      "  [train] step 520/741 | loss=0.6270\n",
      "  [train] step 530/741 | loss=0.5100\n",
      "  [train] step 540/741 | loss=0.5170\n",
      "  [train] step 550/741 | loss=0.5621\n",
      "  [train] step 560/741 | loss=0.5313\n",
      "  [train] step 570/741 | loss=0.4860\n",
      "  [train] step 580/741 | loss=0.5121\n",
      "  [train] step 590/741 | loss=0.5145\n",
      "  [train] step 600/741 | loss=0.8033\n",
      "  [train] step 610/741 | loss=0.4507\n",
      "  [train] step 620/741 | loss=0.4844\n",
      "  [train] step 630/741 | loss=0.5352\n",
      "  [train] step 640/741 | loss=0.5477\n",
      "  [train] step 650/741 | loss=0.4806\n",
      "  [train] step 660/741 | loss=0.5165\n",
      "  [train] step 670/741 | loss=0.5508\n",
      "  [train] step 680/741 | loss=0.5397\n",
      "  [train] step 690/741 | loss=0.5868\n",
      "  [train] step 700/741 | loss=0.5697\n",
      "  [train] step 710/741 | loss=0.5644\n",
      "  [train] step 720/741 | loss=0.5725\n",
      "  [train] step 730/741 | loss=0.5430\n",
      "  [train] step 740/741 | loss=0.5108\n",
      "Train: loss=0.5526, acc=0.957\n",
      "  [val] step 1/733 | loss=3.5636\n",
      "  [val] step 10/733 | loss=0.4907\n",
      "  [val] step 20/733 | loss=0.4368\n",
      "  [val] step 30/733 | loss=2.2834\n",
      "  [val] step 40/733 | loss=3.2716\n",
      "  [val] step 50/733 | loss=4.8189\n",
      "  [val] step 60/733 | loss=0.4266\n",
      "  [val] step 70/733 | loss=0.4379\n",
      "  [val] step 80/733 | loss=0.8724\n",
      "  [val] step 90/733 | loss=0.4530\n",
      "  [val] step 100/733 | loss=0.4433\n",
      "  [val] step 110/733 | loss=0.4354\n",
      "  [val] step 120/733 | loss=13.0655\n",
      "  [val] step 130/733 | loss=2.7404\n",
      "  [val] step 140/733 | loss=3.8581\n",
      "  [val] step 150/733 | loss=1.3175\n",
      "  [val] step 160/733 | loss=0.4742\n",
      "  [val] step 170/733 | loss=4.4549\n",
      "  [val] step 180/733 | loss=4.1679\n",
      "  [val] step 190/733 | loss=0.5958\n",
      "  [val] step 200/733 | loss=1.0970\n",
      "  [val] step 210/733 | loss=1.2604\n",
      "  [val] step 220/733 | loss=4.3754\n",
      "  [val] step 230/733 | loss=0.6483\n",
      "  [val] step 240/733 | loss=0.4465\n",
      "  [val] step 250/733 | loss=0.5083\n",
      "  [val] step 260/733 | loss=1.1617\n",
      "  [val] step 270/733 | loss=0.4255\n",
      "  [val] step 280/733 | loss=0.4665\n",
      "  [val] step 290/733 | loss=0.4347\n",
      "  [val] step 300/733 | loss=2.5888\n",
      "  [val] step 310/733 | loss=2.5050\n",
      "  [val] step 320/733 | loss=1.3998\n",
      "  [val] step 330/733 | loss=1.6352\n",
      "  [val] step 340/733 | loss=0.5589\n",
      "  [val] step 350/733 | loss=4.8972\n",
      "  [val] step 360/733 | loss=0.4393\n",
      "  [val] step 370/733 | loss=0.4313\n",
      "  [val] step 380/733 | loss=0.4266\n",
      "  [val] step 390/733 | loss=0.4285\n",
      "  [val] step 400/733 | loss=0.4307\n",
      "  [val] step 410/733 | loss=0.5430\n",
      "  [val] step 420/733 | loss=0.4818\n",
      "  [val] step 430/733 | loss=0.4437\n",
      "  [val] step 440/733 | loss=1.6341\n",
      "  [val] step 450/733 | loss=0.6336\n",
      "  [val] step 460/733 | loss=0.4262\n",
      "  [val] step 470/733 | loss=2.2234\n",
      "  [val] step 480/733 | loss=5.0831\n",
      "  [val] step 490/733 | loss=2.4358\n",
      "  [val] step 500/733 | loss=0.4300\n",
      "  [val] step 510/733 | loss=0.6730\n",
      "  [val] step 520/733 | loss=0.4304\n",
      "  [val] step 530/733 | loss=0.4592\n",
      "  [val] step 540/733 | loss=0.4461\n",
      "  [val] step 550/733 | loss=0.4400\n",
      "  [val] step 560/733 | loss=4.7224\n",
      "  [val] step 570/733 | loss=2.7407\n",
      "  [val] step 580/733 | loss=4.3661\n",
      "  [val] step 590/733 | loss=0.4541\n",
      "  [val] step 600/733 | loss=0.4297\n",
      "  [val] step 610/733 | loss=0.4230\n",
      "  [val] step 620/733 | loss=0.4371\n",
      "  [val] step 630/733 | loss=0.4272\n",
      "  [val] step 640/733 | loss=0.4264\n",
      "  [val] step 650/733 | loss=0.4279\n",
      "  [val] step 660/733 | loss=2.9308\n",
      "  [val] step 670/733 | loss=0.6858\n",
      "  [val] step 680/733 | loss=0.4875\n",
      "  [val] step 690/733 | loss=0.4415\n",
      "  [val] step 700/733 | loss=0.4262\n",
      "  [val] step 710/733 | loss=0.4349\n",
      "  [val] step 720/733 | loss=4.2315\n",
      "  [val] step 730/733 | loss=2.4081\n",
      "Val:   loss=1.6374, acc=0.650\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best_weighted.pt (acc=0.650)\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[    2     0   236     1     0     0     0   432     9     0     4]\n",
      " [    0    13   234     0     0    96     0    45    32     4     0]\n",
      " [   31     0    18     0     0     0     0    39   109     3    12]\n",
      " [    0     0     1     0     0     9     0    14     1     0    11]\n",
      " [    2     1    18     0    58    42     0   348    89    30     2]\n",
      " [    3     0   425     1     3   662     0  1087   118    36    77]\n",
      " [    0     0     3     0    83     7     0   424     1     0     0]\n",
      " [   22     0    13     1    48   283     2 14005  1752    19     6]\n",
      " [    1     0    16     1     0     0     0    94   432     0     0]\n",
      " [    0     0     2     0     9  1025     0   636    28    40    12]\n",
      " [    6     0    91     0     0     0     0     0    24     0     6]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.030     0.003     0.005       684\n",
      "           1      0.929     0.031     0.059       424\n",
      "           2      0.017     0.085     0.028       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.289     0.098     0.147       590\n",
      "           5      0.312     0.274     0.292      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.818     0.867     0.842     16151\n",
      "           8      0.166     0.794     0.275       544\n",
      "           9      0.303     0.023     0.042      1752\n",
      "          10      0.046     0.047     0.047       127\n",
      "\n",
      "    accuracy                          0.650     23450\n",
      "   macro avg      0.264     0.202     0.158     23450\n",
      "weighted avg      0.647     0.650     0.625     23450\n",
      "\n",
      "Macro-F1: 0.158 | Balanced Acc: 0.202\n",
      "\n",
      "Epoch 3/10\n",
      "  [train] step 1/741 | loss=0.4828\n",
      "  [train] step 10/741 | loss=0.5044\n",
      "  [train] step 20/741 | loss=0.4797\n",
      "  [train] step 30/741 | loss=0.4882\n",
      "  [train] step 40/741 | loss=0.4757\n",
      "  [train] step 50/741 | loss=0.5894\n",
      "  [train] step 60/741 | loss=0.5068\n",
      "  [train] step 70/741 | loss=0.4255\n",
      "  [train] step 80/741 | loss=0.4484\n",
      "  [train] step 90/741 | loss=0.4461\n",
      "  [train] step 100/741 | loss=0.4510\n",
      "  [train] step 110/741 | loss=0.4666\n",
      "  [train] step 120/741 | loss=0.5427\n",
      "  [train] step 130/741 | loss=0.4830\n",
      "  [train] step 140/741 | loss=0.6401\n",
      "  [train] step 150/741 | loss=0.4636\n",
      "  [train] step 160/741 | loss=0.5116\n",
      "  [train] step 170/741 | loss=0.4620\n",
      "  [train] step 180/741 | loss=0.5295\n",
      "  [train] step 190/741 | loss=0.4385\n",
      "  [train] step 200/741 | loss=0.5288\n",
      "  [train] step 210/741 | loss=0.5519\n",
      "  [train] step 220/741 | loss=0.8338\n",
      "  [train] step 230/741 | loss=0.5079\n",
      "  [train] step 240/741 | loss=0.5674\n",
      "  [train] step 250/741 | loss=0.5467\n",
      "  [train] step 260/741 | loss=0.4689\n",
      "  [train] step 270/741 | loss=0.5188\n",
      "  [train] step 280/741 | loss=0.5515\n",
      "  [train] step 290/741 | loss=0.4544\n",
      "  [train] step 300/741 | loss=0.5095\n",
      "  [train] step 310/741 | loss=0.4805\n",
      "  [train] step 320/741 | loss=0.5727\n",
      "  [train] step 330/741 | loss=0.5521\n",
      "  [train] step 340/741 | loss=0.4604\n",
      "  [train] step 350/741 | loss=0.5673\n",
      "  [train] step 360/741 | loss=0.5683\n",
      "  [train] step 370/741 | loss=0.4515\n",
      "  [train] step 380/741 | loss=0.4699\n",
      "  [train] step 390/741 | loss=0.4415\n",
      "  [train] step 400/741 | loss=0.4944\n",
      "  [train] step 410/741 | loss=0.5763\n",
      "  [train] step 420/741 | loss=0.5506\n",
      "  [train] step 430/741 | loss=0.4443\n",
      "  [train] step 440/741 | loss=0.6221\n",
      "  [train] step 450/741 | loss=0.5031\n",
      "  [train] step 460/741 | loss=0.4812\n",
      "  [train] step 470/741 | loss=0.5722\n",
      "  [train] step 480/741 | loss=0.5570\n",
      "  [train] step 490/741 | loss=0.5536\n",
      "  [train] step 500/741 | loss=0.6234\n",
      "  [train] step 510/741 | loss=0.5394\n",
      "  [train] step 520/741 | loss=0.5852\n",
      "  [train] step 530/741 | loss=0.4732\n",
      "  [train] step 540/741 | loss=0.4819\n",
      "  [train] step 550/741 | loss=0.5917\n",
      "  [train] step 560/741 | loss=0.4572\n",
      "  [train] step 570/741 | loss=0.5066\n",
      "  [train] step 580/741 | loss=0.6677\n",
      "  [train] step 590/741 | loss=0.4831\n",
      "  [train] step 600/741 | loss=0.4974\n",
      "  [train] step 610/741 | loss=0.4780\n",
      "  [train] step 620/741 | loss=0.6986\n",
      "  [train] step 630/741 | loss=0.4617\n",
      "  [train] step 640/741 | loss=0.4354\n",
      "  [train] step 650/741 | loss=0.5102\n",
      "  [train] step 660/741 | loss=0.4869\n",
      "  [train] step 670/741 | loss=0.5607\n",
      "  [train] step 680/741 | loss=0.4595\n",
      "  [train] step 690/741 | loss=0.4697\n",
      "  [train] step 700/741 | loss=0.4645\n",
      "  [train] step 710/741 | loss=0.4639\n",
      "  [train] step 720/741 | loss=0.4775\n",
      "  [train] step 730/741 | loss=0.4888\n",
      "  [train] step 740/741 | loss=0.5741\n",
      "Train: loss=0.5246, acc=0.966\n",
      "  [val] step 1/733 | loss=1.0306\n",
      "  [val] step 10/733 | loss=0.4454\n",
      "  [val] step 20/733 | loss=0.4396\n",
      "  [val] step 30/733 | loss=1.9334\n",
      "  [val] step 40/733 | loss=2.5129\n",
      "  [val] step 50/733 | loss=4.2144\n",
      "  [val] step 60/733 | loss=0.4381\n",
      "  [val] step 70/733 | loss=0.4223\n",
      "  [val] step 80/733 | loss=0.7150\n",
      "  [val] step 90/733 | loss=0.4954\n",
      "  [val] step 100/733 | loss=0.4178\n",
      "  [val] step 110/733 | loss=0.4175\n",
      "  [val] step 120/733 | loss=9.4340\n",
      "  [val] step 130/733 | loss=2.4381\n",
      "  [val] step 140/733 | loss=5.1114\n",
      "  [val] step 150/733 | loss=1.0658\n",
      "  [val] step 160/733 | loss=0.4747\n",
      "  [val] step 170/733 | loss=1.5570\n",
      "  [val] step 180/733 | loss=3.2548\n",
      "  [val] step 190/733 | loss=0.9362\n",
      "  [val] step 200/733 | loss=0.4636\n",
      "  [val] step 210/733 | loss=0.8260\n",
      "  [val] step 220/733 | loss=0.8875\n",
      "  [val] step 230/733 | loss=1.3844\n",
      "  [val] step 240/733 | loss=0.5913\n",
      "  [val] step 250/733 | loss=0.5716\n",
      "  [val] step 260/733 | loss=1.9760\n",
      "  [val] step 270/733 | loss=0.5522\n",
      "  [val] step 280/733 | loss=0.5386\n",
      "  [val] step 290/733 | loss=0.5588\n",
      "  [val] step 300/733 | loss=2.1085\n",
      "  [val] step 310/733 | loss=3.5011\n",
      "  [val] step 320/733 | loss=1.4804\n",
      "  [val] step 330/733 | loss=3.1952\n",
      "  [val] step 340/733 | loss=0.4622\n",
      "  [val] step 350/733 | loss=4.6567\n",
      "  [val] step 360/733 | loss=0.4283\n",
      "  [val] step 370/733 | loss=0.4722\n",
      "  [val] step 380/733 | loss=0.4425\n",
      "  [val] step 390/733 | loss=0.4413\n",
      "  [val] step 400/733 | loss=0.5064\n",
      "  [val] step 410/733 | loss=0.4172\n",
      "  [val] step 420/733 | loss=0.9628\n",
      "  [val] step 430/733 | loss=0.8302\n",
      "  [val] step 440/733 | loss=1.0676\n",
      "  [val] step 450/733 | loss=0.5487\n",
      "  [val] step 460/733 | loss=0.4137\n",
      "  [val] step 470/733 | loss=1.3473\n",
      "  [val] step 480/733 | loss=2.5584\n",
      "  [val] step 490/733 | loss=1.1406\n",
      "  [val] step 500/733 | loss=0.4988\n",
      "  [val] step 510/733 | loss=0.5551\n",
      "  [val] step 520/733 | loss=0.4294\n",
      "  [val] step 530/733 | loss=0.4174\n",
      "  [val] step 540/733 | loss=0.4543\n",
      "  [val] step 550/733 | loss=0.4382\n",
      "  [val] step 560/733 | loss=4.9217\n",
      "  [val] step 570/733 | loss=3.1158\n",
      "  [val] step 580/733 | loss=2.4555\n",
      "  [val] step 590/733 | loss=0.4243\n",
      "  [val] step 600/733 | loss=0.4173\n",
      "  [val] step 610/733 | loss=0.5228\n",
      "  [val] step 620/733 | loss=0.7698\n",
      "  [val] step 630/733 | loss=0.4290\n",
      "  [val] step 640/733 | loss=0.4181\n",
      "  [val] step 650/733 | loss=0.4179\n",
      "  [val] step 660/733 | loss=2.5901\n",
      "  [val] step 670/733 | loss=1.7859\n",
      "  [val] step 680/733 | loss=0.7072\n",
      "  [val] step 690/733 | loss=0.5866\n",
      "  [val] step 700/733 | loss=0.4724\n",
      "  [val] step 710/733 | loss=0.4901\n",
      "  [val] step 720/733 | loss=4.4405\n",
      "  [val] step 730/733 | loss=0.6351\n",
      "Val:   loss=1.4489, acc=0.665\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best_weighted.pt (acc=0.665)\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   53     1   290     0     0     1     0   323     7     1     8]\n",
      " [    3    38     0     1     0   281     0    43    56     0     2]\n",
      " [   11     0     1     0     0     0     0    75    61    28    36]\n",
      " [    0     0     0     0     0     7     0     6     2     0    21]\n",
      " [    0     5     0    19    11    24     0   339   111    79     2]\n",
      " [    5     2     7    12     8   833     0   708   418   404    15]\n",
      " [    0     0    10     0     1     5     0   501     1     0     0]\n",
      " [   13    11   344    39     3   161     2 13488  1611    96   383]\n",
      " [    2    25     0     0     0     3     0    86   397     1    30]\n",
      " [    0     0    12     0    16    46     0   962    34   681     1]\n",
      " [    6     6     1    11     0     0     0     0    22     0    81]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.570     0.077     0.136       684\n",
      "           1      0.432     0.090     0.148       424\n",
      "           2      0.002     0.005     0.002       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.282     0.019     0.035       590\n",
      "           5      0.612     0.345     0.442      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.816     0.835     0.825     16151\n",
      "           8      0.146     0.730     0.243       544\n",
      "           9      0.528     0.389     0.448      1752\n",
      "          10      0.140     0.638     0.229       127\n",
      "\n",
      "    accuracy                          0.665     23450\n",
      "   macro avg      0.321     0.284     0.228     23450\n",
      "weighted avg      0.700     0.665     0.662     23450\n",
      "\n",
      "Macro-F1: 0.228 | Balanced Acc: 0.284\n",
      "\n",
      "Epoch 4/10\n",
      "  [train] step 1/741 | loss=0.4821\n",
      "  [train] step 10/741 | loss=0.4632\n",
      "  [train] step 20/741 | loss=0.4934\n",
      "  [train] step 30/741 | loss=0.4589\n",
      "  [train] step 40/741 | loss=0.4923\n",
      "  [train] step 50/741 | loss=0.7105\n",
      "  [train] step 60/741 | loss=0.4992\n",
      "  [train] step 70/741 | loss=0.4883\n",
      "  [train] step 80/741 | loss=0.4991\n",
      "  [train] step 90/741 | loss=0.5356\n",
      "  [train] step 100/741 | loss=0.4734\n",
      "  [train] step 110/741 | loss=0.6538\n",
      "  [train] step 120/741 | loss=0.5093\n",
      "  [train] step 130/741 | loss=0.5321\n",
      "  [train] step 140/741 | loss=0.5392\n",
      "  [train] step 150/741 | loss=0.5197\n",
      "  [train] step 160/741 | loss=0.5483\n",
      "  [train] step 170/741 | loss=0.5108\n",
      "  [train] step 180/741 | loss=0.5313\n",
      "  [train] step 190/741 | loss=0.4616\n",
      "  [train] step 200/741 | loss=0.5113\n",
      "  [train] step 210/741 | loss=0.4734\n",
      "  [train] step 220/741 | loss=0.4777\n",
      "  [train] step 230/741 | loss=0.4533\n",
      "  [train] step 240/741 | loss=0.5138\n",
      "  [train] step 250/741 | loss=0.4443\n",
      "  [train] step 260/741 | loss=0.4420\n",
      "  [train] step 270/741 | loss=0.5903\n",
      "  [train] step 280/741 | loss=0.4339\n",
      "  [train] step 290/741 | loss=0.4954\n",
      "  [train] step 300/741 | loss=0.5378\n",
      "  [train] step 310/741 | loss=0.5625\n",
      "  [train] step 320/741 | loss=0.4717\n",
      "  [train] step 330/741 | loss=0.5096\n",
      "  [train] step 340/741 | loss=0.4959\n",
      "  [train] step 350/741 | loss=0.4342\n",
      "  [train] step 360/741 | loss=0.4372\n",
      "  [train] step 370/741 | loss=0.5216\n",
      "  [train] step 380/741 | loss=0.6771\n",
      "  [train] step 390/741 | loss=0.5741\n",
      "  [train] step 400/741 | loss=0.5626\n",
      "  [train] step 410/741 | loss=0.6015\n",
      "  [train] step 420/741 | loss=0.6140\n",
      "  [train] step 430/741 | loss=0.5520\n",
      "  [train] step 440/741 | loss=0.6546\n",
      "  [train] step 450/741 | loss=0.5527\n",
      "  [train] step 460/741 | loss=0.4922\n",
      "  [train] step 470/741 | loss=0.4892\n",
      "  [train] step 480/741 | loss=0.4827\n",
      "  [train] step 490/741 | loss=0.5674\n",
      "  [train] step 500/741 | loss=0.4615\n",
      "  [train] step 510/741 | loss=0.4549\n",
      "  [train] step 520/741 | loss=0.4956\n",
      "  [train] step 530/741 | loss=0.5987\n",
      "  [train] step 540/741 | loss=0.6554\n",
      "  [train] step 550/741 | loss=0.5468\n",
      "  [train] step 560/741 | loss=0.5043\n",
      "  [train] step 570/741 | loss=0.4444\n",
      "  [train] step 580/741 | loss=0.4341\n",
      "  [train] step 590/741 | loss=0.4880\n",
      "  [train] step 600/741 | loss=0.4694\n",
      "  [train] step 610/741 | loss=0.5703\n",
      "  [train] step 620/741 | loss=0.5829\n",
      "  [train] step 630/741 | loss=0.5082\n",
      "  [train] step 640/741 | loss=0.4594\n",
      "  [train] step 650/741 | loss=0.5637\n",
      "  [train] step 660/741 | loss=0.5127\n",
      "  [train] step 670/741 | loss=0.5159\n",
      "  [train] step 680/741 | loss=0.4881\n",
      "  [train] step 690/741 | loss=0.4396\n",
      "  [train] step 700/741 | loss=0.4685\n",
      "  [train] step 710/741 | loss=0.6440\n",
      "  [train] step 720/741 | loss=0.6147\n",
      "  [train] step 730/741 | loss=0.6356\n",
      "  [train] step 740/741 | loss=0.5238\n",
      "Train: loss=0.5104, acc=0.971\n",
      "  [val] step 1/733 | loss=1.8675\n",
      "  [val] step 10/733 | loss=0.4205\n",
      "  [val] step 20/733 | loss=0.4172\n",
      "  [val] step 30/733 | loss=3.0187\n",
      "  [val] step 40/733 | loss=1.5371\n",
      "  [val] step 50/733 | loss=5.2479\n",
      "  [val] step 60/733 | loss=0.4255\n",
      "  [val] step 70/733 | loss=0.4296\n",
      "  [val] step 80/733 | loss=0.5695\n",
      "  [val] step 90/733 | loss=0.4220\n",
      "  [val] step 100/733 | loss=0.4181\n",
      "  [val] step 110/733 | loss=0.4180\n",
      "  [val] step 120/733 | loss=15.6803\n",
      "  [val] step 130/733 | loss=2.2181\n",
      "  [val] step 140/733 | loss=6.2044\n",
      "  [val] step 150/733 | loss=1.5534\n",
      "  [val] step 160/733 | loss=0.4400\n",
      "  [val] step 170/733 | loss=1.9795\n",
      "  [val] step 180/733 | loss=4.0722\n",
      "  [val] step 190/733 | loss=0.4671\n",
      "  [val] step 200/733 | loss=0.6692\n",
      "  [val] step 210/733 | loss=1.0572\n",
      "  [val] step 220/733 | loss=0.9032\n",
      "  [val] step 230/733 | loss=0.5618\n",
      "  [val] step 240/733 | loss=0.4743\n",
      "  [val] step 250/733 | loss=0.4330\n",
      "  [val] step 260/733 | loss=0.7848\n",
      "  [val] step 270/733 | loss=0.4188\n",
      "  [val] step 280/733 | loss=0.4223\n",
      "  [val] step 290/733 | loss=0.4147\n",
      "  [val] step 300/733 | loss=1.3194\n",
      "  [val] step 310/733 | loss=0.7167\n",
      "  [val] step 320/733 | loss=0.6054\n",
      "  [val] step 330/733 | loss=1.6966\n",
      "  [val] step 340/733 | loss=0.4255\n",
      "  [val] step 350/733 | loss=5.2016\n",
      "  [val] step 360/733 | loss=0.4528\n",
      "  [val] step 370/733 | loss=0.4647\n",
      "  [val] step 380/733 | loss=0.4461\n",
      "  [val] step 390/733 | loss=0.4417\n",
      "  [val] step 400/733 | loss=0.4542\n",
      "  [val] step 410/733 | loss=0.4192\n",
      "  [val] step 420/733 | loss=0.6597\n",
      "  [val] step 430/733 | loss=0.5074\n",
      "  [val] step 440/733 | loss=0.7614\n",
      "  [val] step 450/733 | loss=0.4252\n",
      "  [val] step 460/733 | loss=0.4168\n",
      "  [val] step 470/733 | loss=1.0473\n",
      "  [val] step 480/733 | loss=3.4710\n",
      "  [val] step 490/733 | loss=1.0973\n",
      "  [val] step 500/733 | loss=0.4161\n",
      "  [val] step 510/733 | loss=0.4624\n",
      "  [val] step 520/733 | loss=0.4192\n",
      "  [val] step 530/733 | loss=0.4272\n",
      "  [val] step 540/733 | loss=0.4267\n",
      "  [val] step 550/733 | loss=0.4228\n",
      "  [val] step 560/733 | loss=4.4260\n",
      "  [val] step 570/733 | loss=3.7563\n",
      "  [val] step 580/733 | loss=1.5195\n",
      "  [val] step 590/733 | loss=0.4285\n",
      "  [val] step 600/733 | loss=0.4200\n",
      "  [val] step 610/733 | loss=0.4918\n",
      "  [val] step 620/733 | loss=0.5384\n",
      "  [val] step 630/733 | loss=0.4210\n",
      "  [val] step 640/733 | loss=0.4142\n",
      "  [val] step 650/733 | loss=0.4167\n",
      "  [val] step 660/733 | loss=3.7330\n",
      "  [val] step 670/733 | loss=0.4798\n",
      "  [val] step 680/733 | loss=0.4325\n",
      "  [val] step 690/733 | loss=0.4194\n",
      "  [val] step 700/733 | loss=0.4197\n",
      "  [val] step 710/733 | loss=0.4188\n",
      "  [val] step 720/733 | loss=4.0919\n",
      "  [val] step 730/733 | loss=1.1818\n",
      "Val:   loss=1.5080, acc=0.709\n",
      "  ✅ New best model saved → /home/stud/fwag/bhome/ele670_project/results/tiny_resnet50_best_weighted.pt (acc=0.709)\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[  103     0   254     3     0     0     0   319     0     0     5]\n",
      " [   32     2     0     3     0   366     0    16     5     0     0]\n",
      " [   77     0    12     0     0     0     0    80    38     0     5]\n",
      " [    5     0     0     1     0     5     0     5     0     0    20]\n",
      " [    3     0     0     4    64    45     0   437    24     5     8]\n",
      " [    0     0     5     5     1  1277     0  1033     9    80     2]\n",
      " [    0     0     0     7     9     0     0   502     0     0     0]\n",
      " [   20     5     3    22     1   109     5 14648  1264    69     5]\n",
      " [   26    10     1     1     0     1     0   196   306     0     3]\n",
      " [    0     0    27     0     2   691     0   846     0   181     5]\n",
      " [   76     1     2     6     0     0     0     2     6     0    34]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.301     0.151     0.201       684\n",
      "           1      0.111     0.005     0.009       424\n",
      "           2      0.039     0.057     0.047       212\n",
      "           3      0.019     0.028     0.023        36\n",
      "           4      0.831     0.108     0.192       590\n",
      "           5      0.512     0.529     0.521      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.810     0.907     0.856     16151\n",
      "           8      0.185     0.562     0.279       544\n",
      "           9      0.540     0.103     0.173      1752\n",
      "          10      0.391     0.268     0.318       127\n",
      "\n",
      "    accuracy                          0.709     23450\n",
      "   macro avg      0.340     0.247     0.238     23450\n",
      "weighted avg      0.689     0.709     0.675     23450\n",
      "\n",
      "Macro-F1: 0.238 | Balanced Acc: 0.247\n",
      "\n",
      "Epoch 5/10\n",
      "  [train] step 1/741 | loss=0.4757\n",
      "  [train] step 10/741 | loss=0.4494\n",
      "  [train] step 20/741 | loss=0.5672\n",
      "  [train] step 30/741 | loss=0.5108\n",
      "  [train] step 40/741 | loss=0.4459\n",
      "  [train] step 50/741 | loss=0.5986\n",
      "  [train] step 60/741 | loss=0.4452\n",
      "  [train] step 70/741 | loss=0.4556\n",
      "  [train] step 80/741 | loss=0.5377\n",
      "  [train] step 90/741 | loss=0.4254\n",
      "  [train] step 100/741 | loss=0.4730\n",
      "  [train] step 110/741 | loss=0.4566\n",
      "  [train] step 120/741 | loss=0.5519\n",
      "  [train] step 130/741 | loss=0.4527\n",
      "  [train] step 140/741 | loss=0.5437\n",
      "  [train] step 150/741 | loss=0.4959\n",
      "  [train] step 160/741 | loss=0.4376\n",
      "  [train] step 170/741 | loss=0.5512\n",
      "  [train] step 180/741 | loss=0.4788\n",
      "  [train] step 190/741 | loss=0.4457\n",
      "  [train] step 200/741 | loss=0.4394\n",
      "  [train] step 210/741 | loss=0.5143\n",
      "  [train] step 220/741 | loss=0.5204\n",
      "  [train] step 230/741 | loss=0.4400\n",
      "  [train] step 240/741 | loss=0.4515\n",
      "  [train] step 250/741 | loss=0.5348\n",
      "  [train] step 260/741 | loss=0.5852\n",
      "  [train] step 270/741 | loss=0.5134\n",
      "  [train] step 280/741 | loss=0.4592\n",
      "  [train] step 290/741 | loss=0.5432\n",
      "  [train] step 300/741 | loss=0.5993\n",
      "  [train] step 310/741 | loss=0.4436\n",
      "  [train] step 320/741 | loss=0.5463\n",
      "  [train] step 330/741 | loss=0.4558\n",
      "  [train] step 340/741 | loss=0.4464\n",
      "  [train] step 350/741 | loss=0.4986\n",
      "  [train] step 360/741 | loss=0.6503\n",
      "  [train] step 370/741 | loss=0.4684\n",
      "  [train] step 380/741 | loss=0.4736\n",
      "  [train] step 390/741 | loss=0.4025\n",
      "  [train] step 400/741 | loss=0.4726\n",
      "  [train] step 410/741 | loss=0.4944\n",
      "  [train] step 420/741 | loss=0.4941\n",
      "  [train] step 430/741 | loss=0.5055\n",
      "  [train] step 440/741 | loss=0.4747\n",
      "  [train] step 450/741 | loss=0.4467\n",
      "  [train] step 460/741 | loss=0.4351\n",
      "  [train] step 470/741 | loss=0.4977\n",
      "  [train] step 480/741 | loss=0.4555\n",
      "  [train] step 490/741 | loss=0.5056\n",
      "  [train] step 500/741 | loss=0.4507\n",
      "  [train] step 510/741 | loss=0.5781\n",
      "  [train] step 520/741 | loss=0.5190\n",
      "  [train] step 530/741 | loss=0.5318\n",
      "  [train] step 540/741 | loss=0.4355\n",
      "  [train] step 550/741 | loss=0.4409\n",
      "  [train] step 560/741 | loss=0.4572\n",
      "  [train] step 570/741 | loss=0.4672\n",
      "  [train] step 580/741 | loss=0.4468\n",
      "  [train] step 590/741 | loss=0.4676\n",
      "  [train] step 600/741 | loss=0.4933\n",
      "  [train] step 610/741 | loss=0.4885\n",
      "  [train] step 620/741 | loss=0.4852\n",
      "  [train] step 630/741 | loss=0.4617\n",
      "  [train] step 640/741 | loss=0.4670\n",
      "  [train] step 650/741 | loss=0.5879\n",
      "  [train] step 660/741 | loss=0.4675\n",
      "  [train] step 670/741 | loss=0.4403\n",
      "  [train] step 680/741 | loss=0.4629\n",
      "  [train] step 690/741 | loss=0.5012\n",
      "  [train] step 700/741 | loss=0.7284\n",
      "  [train] step 710/741 | loss=0.4721\n",
      "  [train] step 720/741 | loss=0.4891\n",
      "  [train] step 730/741 | loss=0.4909\n",
      "  [train] step 740/741 | loss=0.4978\n",
      "Train: loss=0.5026, acc=0.974\n",
      "  [val] step 1/733 | loss=0.6104\n",
      "  [val] step 10/733 | loss=0.4268\n",
      "  [val] step 20/733 | loss=0.4216\n",
      "  [val] step 30/733 | loss=1.6114\n",
      "  [val] step 40/733 | loss=2.6180\n",
      "  [val] step 50/733 | loss=4.4130\n",
      "  [val] step 60/733 | loss=0.4685\n",
      "  [val] step 70/733 | loss=2.0870\n",
      "  [val] step 80/733 | loss=1.0333\n",
      "  [val] step 90/733 | loss=0.4209\n",
      "  [val] step 100/733 | loss=0.4193\n",
      "  [val] step 110/733 | loss=0.4316\n",
      "  [val] step 120/733 | loss=13.6954\n",
      "  [val] step 130/733 | loss=3.8160\n",
      "  [val] step 140/733 | loss=4.2790\n",
      "  [val] step 150/733 | loss=2.5593\n",
      "  [val] step 160/733 | loss=0.6718\n",
      "  [val] step 170/733 | loss=2.6539\n",
      "  [val] step 180/733 | loss=4.4188\n",
      "  [val] step 190/733 | loss=0.5646\n",
      "  [val] step 200/733 | loss=0.9287\n",
      "  [val] step 210/733 | loss=1.0099\n",
      "  [val] step 220/733 | loss=2.8061\n",
      "  [val] step 230/733 | loss=0.6618\n",
      "  [val] step 240/733 | loss=0.4515\n",
      "  [val] step 250/733 | loss=0.5033\n",
      "  [val] step 260/733 | loss=1.4750\n",
      "  [val] step 270/733 | loss=0.7848\n",
      "  [val] step 280/733 | loss=0.5134\n",
      "  [val] step 290/733 | loss=0.4285\n",
      "  [val] step 300/733 | loss=2.9513\n",
      "  [val] step 310/733 | loss=3.9501\n",
      "  [val] step 320/733 | loss=2.3957\n",
      "  [val] step 330/733 | loss=3.0617\n",
      "  [val] step 340/733 | loss=0.5605\n",
      "  [val] step 350/733 | loss=4.6397\n",
      "  [val] step 360/733 | loss=0.4340\n",
      "  [val] step 370/733 | loss=0.4979\n",
      "  [val] step 380/733 | loss=0.4559\n",
      "  [val] step 390/733 | loss=0.4723\n",
      "  [val] step 400/733 | loss=0.5278\n",
      "  [val] step 410/733 | loss=0.4904\n",
      "  [val] step 420/733 | loss=0.4231\n",
      "  [val] step 430/733 | loss=0.4250\n",
      "  [val] step 440/733 | loss=0.4976\n",
      "  [val] step 450/733 | loss=0.6196\n",
      "  [val] step 460/733 | loss=0.4328\n",
      "  [val] step 470/733 | loss=1.3263\n",
      "  [val] step 480/733 | loss=2.8536\n",
      "  [val] step 490/733 | loss=3.3661\n",
      "  [val] step 500/733 | loss=0.4414\n",
      "  [val] step 510/733 | loss=0.5943\n",
      "  [val] step 520/733 | loss=0.4359\n",
      "  [val] step 530/733 | loss=0.4495\n",
      "  [val] step 540/733 | loss=0.4577\n",
      "  [val] step 550/733 | loss=0.5714\n",
      "  [val] step 560/733 | loss=4.5240\n",
      "  [val] step 570/733 | loss=1.5860\n",
      "  [val] step 580/733 | loss=1.7999\n",
      "  [val] step 590/733 | loss=0.4275\n",
      "  [val] step 600/733 | loss=0.4196\n",
      "  [val] step 610/733 | loss=0.4248\n",
      "  [val] step 620/733 | loss=0.4635\n",
      "  [val] step 630/733 | loss=0.4289\n",
      "  [val] step 640/733 | loss=0.4239\n",
      "  [val] step 650/733 | loss=0.4245\n",
      "  [val] step 660/733 | loss=2.4592\n",
      "  [val] step 670/733 | loss=0.8435\n",
      "  [val] step 680/733 | loss=0.8033\n",
      "  [val] step 690/733 | loss=0.9746\n",
      "  [val] step 700/733 | loss=0.4308\n",
      "  [val] step 710/733 | loss=0.4981\n",
      "  [val] step 720/733 | loss=4.0258\n",
      "  [val] step 730/733 | loss=1.4475\n",
      "Val:   loss=1.5547, acc=0.664\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[  153     0   436    14     0     0     0    74     2     0     5]\n",
      " [    4     0    14    18    18   324     0     7    32     0     7]\n",
      " [   23     0    41     0     0    11     0    68    61     0     8]\n",
      " [    2     0     0     0     0     9     0     0     0     0    25]\n",
      " [    1     0     9     4    83    20     0   354   103     9     7]\n",
      " [    0     0    90     6   234   443     0  1379   141    53    66]\n",
      " [    0     0     4     3   105     0     0   385    21     0     0]\n",
      " [   34     3    33     0   158    91     0 13759  1964    94    15]\n",
      " [    4     2     0     0     0     4     0   103   431     0     0]\n",
      " [    0     0    43     0    59   380     0   628     0   627    15]\n",
      " [   17     0    25     0     0     0     0     2    58     0    25]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.643     0.224     0.332       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.059     0.193     0.090       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.126     0.141     0.133       590\n",
      "           5      0.346     0.184     0.240      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.821     0.852     0.836     16151\n",
      "           8      0.153     0.792     0.257       544\n",
      "           9      0.801     0.358     0.495      1752\n",
      "          10      0.145     0.197     0.167       127\n",
      "\n",
      "    accuracy                          0.664     23450\n",
      "   macro avg      0.281     0.267     0.232     23450\n",
      "weighted avg      0.688     0.664     0.658     23450\n",
      "\n",
      "Macro-F1: 0.232 | Balanced Acc: 0.267\n",
      "\n",
      "Epoch 6/10\n",
      "  [train] step 1/741 | loss=0.5506\n",
      "  [train] step 10/741 | loss=0.5172\n",
      "  [train] step 20/741 | loss=0.4680\n",
      "  [train] step 30/741 | loss=0.5059\n",
      "  [train] step 40/741 | loss=0.4361\n",
      "  [train] step 50/741 | loss=0.4506\n",
      "  [train] step 60/741 | loss=0.4969\n",
      "  [train] step 70/741 | loss=0.4852\n",
      "  [train] step 80/741 | loss=0.4605\n",
      "  [train] step 90/741 | loss=0.4731\n",
      "  [train] step 100/741 | loss=0.4591\n",
      "  [train] step 110/741 | loss=0.4580\n",
      "  [train] step 120/741 | loss=0.4318\n",
      "  [train] step 130/741 | loss=0.4312\n",
      "  [train] step 140/741 | loss=0.4823\n",
      "  [train] step 150/741 | loss=0.4344\n",
      "  [train] step 160/741 | loss=0.4550\n",
      "  [train] step 170/741 | loss=0.4710\n",
      "  [train] step 180/741 | loss=0.5313\n",
      "  [train] step 190/741 | loss=0.4840\n",
      "  [train] step 200/741 | loss=0.4690\n",
      "  [train] step 210/741 | loss=0.4506\n",
      "  [train] step 220/741 | loss=0.4517\n",
      "  [train] step 230/741 | loss=0.4490\n",
      "  [train] step 240/741 | loss=0.5663\n",
      "  [train] step 250/741 | loss=0.4745\n",
      "  [train] step 260/741 | loss=0.4688\n",
      "  [train] step 270/741 | loss=0.5594\n",
      "  [train] step 280/741 | loss=0.4800\n",
      "  [train] step 290/741 | loss=0.4384\n",
      "  [train] step 300/741 | loss=0.4872\n",
      "  [train] step 310/741 | loss=0.5333\n",
      "  [train] step 320/741 | loss=0.5411\n",
      "  [train] step 330/741 | loss=0.5044\n",
      "  [train] step 340/741 | loss=0.4440\n",
      "  [train] step 350/741 | loss=0.4941\n",
      "  [train] step 360/741 | loss=0.4630\n",
      "  [train] step 370/741 | loss=0.4834\n",
      "  [train] step 380/741 | loss=0.4983\n",
      "  [train] step 390/741 | loss=0.5549\n",
      "  [train] step 400/741 | loss=0.4734\n",
      "  [train] step 410/741 | loss=0.4434\n",
      "  [train] step 420/741 | loss=0.5355\n",
      "  [train] step 430/741 | loss=0.5617\n",
      "  [train] step 440/741 | loss=0.4548\n",
      "  [train] step 450/741 | loss=0.4593\n",
      "  [train] step 460/741 | loss=0.4572\n",
      "  [train] step 470/741 | loss=0.4594\n",
      "  [train] step 480/741 | loss=0.5603\n",
      "  [train] step 490/741 | loss=0.4880\n",
      "  [train] step 500/741 | loss=0.5410\n",
      "  [train] step 510/741 | loss=0.6465\n",
      "  [train] step 520/741 | loss=0.5340\n",
      "  [train] step 530/741 | loss=0.5168\n",
      "  [train] step 540/741 | loss=0.5046\n",
      "  [train] step 550/741 | loss=0.5620\n",
      "  [train] step 560/741 | loss=0.4786\n",
      "  [train] step 570/741 | loss=0.5122\n",
      "  [train] step 580/741 | loss=0.4779\n",
      "  [train] step 590/741 | loss=0.4503\n",
      "  [train] step 600/741 | loss=0.4792\n",
      "  [train] step 610/741 | loss=0.4818\n",
      "  [train] step 620/741 | loss=0.4988\n",
      "  [train] step 630/741 | loss=0.4643\n",
      "  [train] step 640/741 | loss=0.5454\n",
      "  [train] step 650/741 | loss=0.4345\n",
      "  [train] step 660/741 | loss=0.4522\n",
      "  [train] step 670/741 | loss=0.5482\n",
      "  [train] step 680/741 | loss=0.5037\n",
      "  [train] step 690/741 | loss=0.4352\n",
      "  [train] step 700/741 | loss=0.4200\n",
      "  [train] step 710/741 | loss=0.5185\n",
      "  [train] step 720/741 | loss=0.4416\n",
      "  [train] step 730/741 | loss=0.5102\n",
      "  [train] step 740/741 | loss=0.5567\n",
      "Train: loss=0.4930, acc=0.977\n",
      "  [val] step 1/733 | loss=2.1729\n",
      "  [val] step 10/733 | loss=0.4278\n",
      "  [val] step 20/733 | loss=0.4227\n",
      "  [val] step 30/733 | loss=3.1851\n",
      "  [val] step 40/733 | loss=2.1410\n",
      "  [val] step 50/733 | loss=4.5845\n",
      "  [val] step 60/733 | loss=0.4210\n",
      "  [val] step 70/733 | loss=0.4240\n",
      "  [val] step 80/733 | loss=1.1674\n",
      "  [val] step 90/733 | loss=0.4247\n",
      "  [val] step 100/733 | loss=0.4173\n",
      "  [val] step 110/733 | loss=0.4239\n",
      "  [val] step 120/733 | loss=11.1028\n",
      "  [val] step 130/733 | loss=3.6999\n",
      "  [val] step 140/733 | loss=5.0321\n",
      "  [val] step 150/733 | loss=0.8379\n",
      "  [val] step 160/733 | loss=0.4334\n",
      "  [val] step 170/733 | loss=2.4756\n",
      "  [val] step 180/733 | loss=3.4570\n",
      "  [val] step 190/733 | loss=0.4476\n",
      "  [val] step 200/733 | loss=0.6340\n",
      "  [val] step 210/733 | loss=1.8462\n",
      "  [val] step 220/733 | loss=0.9288\n",
      "  [val] step 230/733 | loss=0.9155\n",
      "  [val] step 240/733 | loss=0.4479\n",
      "  [val] step 250/733 | loss=0.4414\n",
      "  [val] step 260/733 | loss=0.6738\n",
      "  [val] step 270/733 | loss=0.4303\n",
      "  [val] step 280/733 | loss=0.4338\n",
      "  [val] step 290/733 | loss=0.4273\n",
      "  [val] step 300/733 | loss=1.5619\n",
      "  [val] step 310/733 | loss=3.1450\n",
      "  [val] step 320/733 | loss=1.5861\n",
      "  [val] step 330/733 | loss=3.4396\n",
      "  [val] step 340/733 | loss=0.4168\n",
      "  [val] step 350/733 | loss=4.7421\n",
      "  [val] step 360/733 | loss=0.4620\n",
      "  [val] step 370/733 | loss=0.5451\n",
      "  [val] step 380/733 | loss=0.5114\n",
      "  [val] step 390/733 | loss=0.4934\n",
      "  [val] step 400/733 | loss=0.5259\n",
      "  [val] step 410/733 | loss=0.5404\n",
      "  [val] step 420/733 | loss=0.4199\n",
      "  [val] step 430/733 | loss=0.4202\n",
      "  [val] step 440/733 | loss=0.9556\n",
      "  [val] step 450/733 | loss=0.4634\n",
      "  [val] step 460/733 | loss=0.4306\n",
      "  [val] step 470/733 | loss=0.5988\n",
      "  [val] step 480/733 | loss=1.9124\n",
      "  [val] step 490/733 | loss=0.9382\n",
      "  [val] step 500/733 | loss=0.4315\n",
      "  [val] step 510/733 | loss=0.6869\n",
      "  [val] step 520/733 | loss=0.4189\n",
      "  [val] step 530/733 | loss=0.4968\n",
      "  [val] step 540/733 | loss=0.4236\n",
      "  [val] step 550/733 | loss=0.4281\n",
      "  [val] step 560/733 | loss=4.2537\n",
      "  [val] step 570/733 | loss=4.3114\n",
      "  [val] step 580/733 | loss=4.0141\n",
      "  [val] step 590/733 | loss=0.5061\n",
      "  [val] step 600/733 | loss=0.4230\n",
      "  [val] step 610/733 | loss=0.4303\n",
      "  [val] step 620/733 | loss=0.5081\n",
      "  [val] step 630/733 | loss=0.4201\n",
      "  [val] step 640/733 | loss=0.4188\n",
      "  [val] step 650/733 | loss=0.4322\n",
      "  [val] step 660/733 | loss=2.6604\n",
      "  [val] step 670/733 | loss=0.4288\n",
      "  [val] step 680/733 | loss=0.4404\n",
      "  [val] step 690/733 | loss=0.4217\n",
      "  [val] step 700/733 | loss=0.4533\n",
      "  [val] step 710/733 | loss=0.4542\n",
      "  [val] step 720/733 | loss=4.3278\n",
      "  [val] step 730/733 | loss=1.7819\n",
      "Val:   loss=1.4874, acc=0.690\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   19     0   182     0     0     1     0   446     4     0    32]\n",
      " [    0     0     1     0     0   337     0    55    27     0     4]\n",
      " [    4     0     0     0     0     5     0   107    79     0    17]\n",
      " [    1     0     0     0     0     8     0    22     0     0     5]\n",
      " [    3     0     0     3    69   171     0   275    59     5     5]\n",
      " [    0     0     0     0     3   936     0  1294     0   129    50]\n",
      " [    0     0     0     0    22    12     0   484     0     0     0]\n",
      " [    2     0     4    16    18   274     0 14624  1140    70     3]\n",
      " [    0     0     0     0     0     7     0   177   359     0     1]\n",
      " [    0     0     0     0     7   571     0   968     0   142    64]\n",
      " [   12     3     0     0     0     5     0    12    75     0    20]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.463     0.028     0.052       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.000     0.000     0.000       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.580     0.117     0.195       590\n",
      "           5      0.402     0.388     0.395      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.792     0.905     0.845     16151\n",
      "           8      0.206     0.660     0.314       544\n",
      "           9      0.410     0.081     0.135      1752\n",
      "          10      0.100     0.157     0.122       127\n",
      "\n",
      "    accuracy                          0.690     23450\n",
      "   macro avg      0.268     0.212     0.187     23450\n",
      "weighted avg      0.651     0.690     0.647     23450\n",
      "\n",
      "Macro-F1: 0.187 | Balanced Acc: 0.212\n",
      "\n",
      "Epoch 7/10\n",
      "  [train] step 1/741 | loss=0.4562\n",
      "  [train] step 10/741 | loss=0.4568\n",
      "  [train] step 20/741 | loss=0.4805\n",
      "  [train] step 30/741 | loss=0.5055\n",
      "  [train] step 40/741 | loss=0.4324\n",
      "  [train] step 50/741 | loss=0.4474\n",
      "  [train] step 60/741 | loss=0.4377\n",
      "  [train] step 70/741 | loss=0.4792\n",
      "  [train] step 80/741 | loss=0.4786\n",
      "  [train] step 90/741 | loss=0.5037\n",
      "  [train] step 100/741 | loss=0.4875\n",
      "  [train] step 110/741 | loss=0.4807\n",
      "  [train] step 120/741 | loss=0.5380\n",
      "  [train] step 130/741 | loss=0.4345\n",
      "  [train] step 140/741 | loss=0.4718\n",
      "  [train] step 150/741 | loss=0.4300\n",
      "  [train] step 160/741 | loss=0.4565\n",
      "  [train] step 170/741 | loss=0.4493\n",
      "  [train] step 180/741 | loss=0.5632\n",
      "  [train] step 190/741 | loss=0.4745\n",
      "  [train] step 200/741 | loss=0.5022\n",
      "  [train] step 210/741 | loss=0.4502\n",
      "  [train] step 220/741 | loss=0.4459\n",
      "  [train] step 230/741 | loss=0.4371\n",
      "  [train] step 240/741 | loss=0.4973\n",
      "  [train] step 250/741 | loss=0.5182\n",
      "  [train] step 260/741 | loss=0.6849\n",
      "  [train] step 270/741 | loss=0.4531\n",
      "  [train] step 280/741 | loss=0.5324\n",
      "  [train] step 290/741 | loss=0.4546\n",
      "  [train] step 300/741 | loss=0.4713\n",
      "  [train] step 310/741 | loss=0.4433\n",
      "  [train] step 320/741 | loss=0.4491\n",
      "  [train] step 330/741 | loss=0.4703\n",
      "  [train] step 340/741 | loss=0.4950\n",
      "  [train] step 350/741 | loss=0.4211\n",
      "  [train] step 360/741 | loss=0.4489\n",
      "  [train] step 370/741 | loss=0.5389\n",
      "  [train] step 380/741 | loss=0.4365\n",
      "  [train] step 390/741 | loss=0.5083\n",
      "  [train] step 400/741 | loss=0.5454\n",
      "  [train] step 410/741 | loss=0.4491\n",
      "  [train] step 420/741 | loss=0.4577\n",
      "  [train] step 430/741 | loss=0.4343\n",
      "  [train] step 440/741 | loss=0.4825\n",
      "  [train] step 450/741 | loss=0.4641\n",
      "  [train] step 460/741 | loss=0.5070\n",
      "  [train] step 470/741 | loss=0.4822\n",
      "  [train] step 480/741 | loss=0.4617\n",
      "  [train] step 490/741 | loss=0.4385\n",
      "  [train] step 500/741 | loss=0.4465\n",
      "  [train] step 510/741 | loss=0.4532\n",
      "  [train] step 520/741 | loss=0.3823\n",
      "  [train] step 530/741 | loss=0.4784\n",
      "  [train] step 540/741 | loss=0.4243\n",
      "  [train] step 550/741 | loss=0.4443\n",
      "  [train] step 560/741 | loss=0.4613\n",
      "  [train] step 570/741 | loss=0.4410\n",
      "  [train] step 580/741 | loss=0.4385\n",
      "  [train] step 590/741 | loss=0.4728\n",
      "  [train] step 600/741 | loss=0.4643\n",
      "  [train] step 610/741 | loss=0.5782\n",
      "  [train] step 620/741 | loss=0.5445\n",
      "  [train] step 630/741 | loss=0.4463\n",
      "  [train] step 640/741 | loss=0.4554\n",
      "  [train] step 650/741 | loss=0.4954\n",
      "  [train] step 660/741 | loss=0.4830\n",
      "  [train] step 670/741 | loss=0.4585\n",
      "  [train] step 680/741 | loss=0.5139\n",
      "  [train] step 690/741 | loss=0.4665\n",
      "  [train] step 700/741 | loss=0.5245\n",
      "  [train] step 710/741 | loss=0.4709\n",
      "  [train] step 720/741 | loss=0.5064\n",
      "  [train] step 730/741 | loss=0.5590\n",
      "  [train] step 740/741 | loss=0.4625\n",
      "Train: loss=0.4875, acc=0.978\n",
      "  [val] step 1/733 | loss=1.0682\n",
      "  [val] step 10/733 | loss=0.4627\n",
      "  [val] step 20/733 | loss=0.4257\n",
      "  [val] step 30/733 | loss=1.2433\n",
      "  [val] step 40/733 | loss=2.1289\n",
      "  [val] step 50/733 | loss=4.2085\n",
      "  [val] step 60/733 | loss=0.4277\n",
      "  [val] step 70/733 | loss=0.4429\n",
      "  [val] step 80/733 | loss=1.7166\n",
      "  [val] step 90/733 | loss=0.4623\n",
      "  [val] step 100/733 | loss=0.4181\n",
      "  [val] step 110/733 | loss=0.4277\n",
      "  [val] step 120/733 | loss=9.9112\n",
      "  [val] step 130/733 | loss=4.3846\n",
      "  [val] step 140/733 | loss=3.9640\n",
      "  [val] step 150/733 | loss=1.8640\n",
      "  [val] step 160/733 | loss=0.4409\n",
      "  [val] step 170/733 | loss=2.6750\n",
      "  [val] step 180/733 | loss=2.7125\n",
      "  [val] step 190/733 | loss=0.6029\n",
      "  [val] step 200/733 | loss=0.8084\n",
      "  [val] step 210/733 | loss=1.2024\n",
      "  [val] step 220/733 | loss=0.8505\n",
      "  [val] step 230/733 | loss=0.5180\n",
      "  [val] step 240/733 | loss=0.4620\n",
      "  [val] step 250/733 | loss=0.4753\n",
      "  [val] step 260/733 | loss=1.5538\n",
      "  [val] step 270/733 | loss=0.4306\n",
      "  [val] step 280/733 | loss=0.4815\n",
      "  [val] step 290/733 | loss=0.4475\n",
      "  [val] step 300/733 | loss=4.7059\n",
      "  [val] step 310/733 | loss=3.0815\n",
      "  [val] step 320/733 | loss=1.7340\n",
      "  [val] step 330/733 | loss=3.3623\n",
      "  [val] step 340/733 | loss=0.4363\n",
      "  [val] step 350/733 | loss=4.8462\n",
      "  [val] step 360/733 | loss=0.4539\n",
      "  [val] step 370/733 | loss=0.5573\n",
      "  [val] step 380/733 | loss=0.5051\n",
      "  [val] step 390/733 | loss=0.5255\n",
      "  [val] step 400/733 | loss=0.5500\n",
      "  [val] step 410/733 | loss=0.4201\n",
      "  [val] step 420/733 | loss=0.4246\n",
      "  [val] step 430/733 | loss=0.4249\n",
      "  [val] step 440/733 | loss=1.3361\n",
      "  [val] step 450/733 | loss=0.8151\n",
      "  [val] step 460/733 | loss=0.4314\n",
      "  [val] step 470/733 | loss=2.0657\n",
      "  [val] step 480/733 | loss=3.0744\n",
      "  [val] step 490/733 | loss=1.5556\n",
      "  [val] step 500/733 | loss=0.5010\n",
      "  [val] step 510/733 | loss=0.5793\n",
      "  [val] step 520/733 | loss=0.4267\n",
      "  [val] step 530/733 | loss=0.4384\n",
      "  [val] step 540/733 | loss=0.4292\n",
      "  [val] step 550/733 | loss=0.4278\n",
      "  [val] step 560/733 | loss=4.8176\n",
      "  [val] step 570/733 | loss=2.1537\n",
      "  [val] step 580/733 | loss=2.7207\n",
      "  [val] step 590/733 | loss=1.3694\n",
      "  [val] step 600/733 | loss=0.4456\n",
      "  [val] step 610/733 | loss=0.4436\n",
      "  [val] step 620/733 | loss=0.5638\n",
      "  [val] step 630/733 | loss=0.4396\n",
      "  [val] step 640/733 | loss=0.4460\n",
      "  [val] step 650/733 | loss=0.5929\n",
      "  [val] step 660/733 | loss=2.5548\n",
      "  [val] step 670/733 | loss=0.4948\n",
      "  [val] step 680/733 | loss=0.4221\n",
      "  [val] step 690/733 | loss=0.4270\n",
      "  [val] step 700/733 | loss=0.4190\n",
      "  [val] step 710/733 | loss=0.4341\n",
      "  [val] step 720/733 | loss=5.3413\n",
      "  [val] step 730/733 | loss=0.7911\n",
      "Val:   loss=1.6029, acc=0.653\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   68     0   351     4     0     0     0   248    13     0     0]\n",
      " [    3     0     0     1     0   270     0   113    37     0     0]\n",
      " [    0     0    11     0     0    40     0    57    54     4    46]\n",
      " [    0     0     0     0     0     9     0     4     0     0    23]\n",
      " [    0     0     0    13    18   152     0   311    69    26     1]\n",
      " [    0     0     0     2     2   482     0  1761    70    86     9]\n",
      " [    0     0     5    54    10     0     0   449     0     0     0]\n",
      " [    0     3    79   124     2   434     0 13881  1572    35    21]\n",
      " [    1     0     9     0     0     0     0   107   422     0     5]\n",
      " [    0     0     5     0     3   547     0   809     0   388     0]\n",
      " [    0     0     3     0     0     0     0     0    70     0    54]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.944     0.099     0.180       684\n",
      "           1      0.000     0.000     0.000       424\n",
      "           2      0.024     0.052     0.033       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.514     0.031     0.058       590\n",
      "           5      0.249     0.200     0.222      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.782     0.859     0.819     16151\n",
      "           8      0.183     0.776     0.296       544\n",
      "           9      0.720     0.221     0.339      1752\n",
      "          10      0.340     0.425     0.378       127\n",
      "\n",
      "    accuracy                          0.653     23450\n",
      "   macro avg      0.342     0.242     0.211     23450\n",
      "weighted avg      0.665     0.653     0.628     23450\n",
      "\n",
      "Macro-F1: 0.211 | Balanced Acc: 0.242\n",
      "\n",
      "Epoch 8/10\n",
      "  [train] step 1/741 | loss=0.4416\n",
      "  [train] step 10/741 | loss=0.4823\n",
      "  [train] step 20/741 | loss=0.4409\n",
      "  [train] step 30/741 | loss=0.5417\n",
      "  [train] step 40/741 | loss=0.4464\n",
      "  [train] step 50/741 | loss=0.4828\n",
      "  [train] step 60/741 | loss=0.4480\n",
      "  [train] step 70/741 | loss=0.5021\n",
      "  [train] step 80/741 | loss=0.5929\n",
      "  [train] step 90/741 | loss=0.4366\n",
      "  [train] step 100/741 | loss=0.4694\n",
      "  [train] step 110/741 | loss=0.4406\n",
      "  [train] step 120/741 | loss=0.4682\n",
      "  [train] step 130/741 | loss=0.4524\n",
      "  [train] step 140/741 | loss=0.4004\n",
      "  [train] step 150/741 | loss=0.4330\n",
      "  [train] step 160/741 | loss=0.4749\n",
      "  [train] step 170/741 | loss=0.4602\n",
      "  [train] step 180/741 | loss=0.4742\n",
      "  [train] step 190/741 | loss=0.4481\n",
      "  [train] step 200/741 | loss=0.4435\n",
      "  [train] step 210/741 | loss=0.4952\n",
      "  [train] step 220/741 | loss=0.5546\n",
      "  [train] step 230/741 | loss=0.4470\n",
      "  [train] step 240/741 | loss=0.5403\n",
      "  [train] step 250/741 | loss=0.4686\n",
      "  [train] step 260/741 | loss=0.4467\n",
      "  [train] step 270/741 | loss=0.4839\n",
      "  [train] step 280/741 | loss=0.4662\n",
      "  [train] step 290/741 | loss=0.5811\n",
      "  [train] step 300/741 | loss=0.5488\n",
      "  [train] step 310/741 | loss=0.4680\n",
      "  [train] step 320/741 | loss=0.6430\n",
      "  [train] step 330/741 | loss=0.4375\n",
      "  [train] step 340/741 | loss=0.4826\n",
      "  [train] step 350/741 | loss=0.4278\n",
      "  [train] step 360/741 | loss=0.4434\n",
      "  [train] step 370/741 | loss=0.4538\n",
      "  [train] step 380/741 | loss=0.4556\n",
      "  [train] step 390/741 | loss=0.4342\n",
      "  [train] step 400/741 | loss=0.5821\n",
      "  [train] step 410/741 | loss=0.4344\n",
      "  [train] step 420/741 | loss=0.4564\n",
      "  [train] step 430/741 | loss=0.5540\n",
      "  [train] step 440/741 | loss=0.4538\n",
      "  [train] step 450/741 | loss=0.4706\n",
      "  [train] step 460/741 | loss=0.5064\n",
      "  [train] step 470/741 | loss=0.4456\n",
      "  [train] step 480/741 | loss=0.4732\n",
      "  [train] step 490/741 | loss=0.6940\n",
      "  [train] step 500/741 | loss=0.5236\n",
      "  [train] step 510/741 | loss=0.4976\n",
      "  [train] step 520/741 | loss=0.4579\n",
      "  [train] step 530/741 | loss=0.4639\n",
      "  [train] step 540/741 | loss=0.4454\n",
      "  [train] step 550/741 | loss=0.4853\n",
      "  [train] step 560/741 | loss=0.4508\n",
      "  [train] step 570/741 | loss=0.4585\n",
      "  [train] step 580/741 | loss=0.5197\n",
      "  [train] step 590/741 | loss=0.4466\n",
      "  [train] step 600/741 | loss=0.4996\n",
      "  [train] step 610/741 | loss=0.5102\n",
      "  [train] step 620/741 | loss=0.4520\n",
      "  [train] step 630/741 | loss=0.5977\n",
      "  [train] step 640/741 | loss=0.4620\n",
      "  [train] step 650/741 | loss=0.6118\n",
      "  [train] step 660/741 | loss=0.4762\n",
      "  [train] step 670/741 | loss=0.7191\n",
      "  [train] step 680/741 | loss=0.5692\n",
      "  [train] step 690/741 | loss=0.5466\n",
      "  [train] step 700/741 | loss=0.4825\n",
      "  [train] step 710/741 | loss=0.5967\n",
      "  [train] step 720/741 | loss=0.5458\n",
      "  [train] step 730/741 | loss=0.4392\n",
      "  [train] step 740/741 | loss=0.4464\n",
      "Train: loss=0.4805, acc=0.981\n",
      "  [val] step 1/733 | loss=1.9052\n",
      "  [val] step 10/733 | loss=0.4184\n",
      "  [val] step 20/733 | loss=0.4201\n",
      "  [val] step 30/733 | loss=1.3422\n",
      "  [val] step 40/733 | loss=1.6224\n",
      "  [val] step 50/733 | loss=5.3314\n",
      "  [val] step 60/733 | loss=0.4290\n",
      "  [val] step 70/733 | loss=0.4382\n",
      "  [val] step 80/733 | loss=2.3450\n",
      "  [val] step 90/733 | loss=0.4327\n",
      "  [val] step 100/733 | loss=0.4381\n",
      "  [val] step 110/733 | loss=0.4430\n",
      "  [val] step 120/733 | loss=8.0264\n",
      "  [val] step 130/733 | loss=2.4911\n",
      "  [val] step 140/733 | loss=4.4552\n",
      "  [val] step 150/733 | loss=1.2750\n",
      "  [val] step 160/733 | loss=0.4365\n",
      "  [val] step 170/733 | loss=2.4127\n",
      "  [val] step 180/733 | loss=3.0449\n",
      "  [val] step 190/733 | loss=0.9462\n",
      "  [val] step 200/733 | loss=0.8929\n",
      "  [val] step 210/733 | loss=1.3255\n",
      "  [val] step 220/733 | loss=0.7177\n",
      "  [val] step 230/733 | loss=0.6436\n",
      "  [val] step 240/733 | loss=0.5563\n",
      "  [val] step 250/733 | loss=0.5282\n",
      "  [val] step 260/733 | loss=0.9511\n",
      "  [val] step 270/733 | loss=0.4213\n",
      "  [val] step 280/733 | loss=0.4491\n",
      "  [val] step 290/733 | loss=0.4209\n",
      "  [val] step 300/733 | loss=3.6862\n",
      "  [val] step 310/733 | loss=3.1667\n",
      "  [val] step 320/733 | loss=1.5371\n",
      "  [val] step 330/733 | loss=3.3411\n",
      "  [val] step 340/733 | loss=0.4657\n",
      "  [val] step 350/733 | loss=4.2646\n",
      "  [val] step 360/733 | loss=0.4231\n",
      "  [val] step 370/733 | loss=0.4227\n",
      "  [val] step 380/733 | loss=0.4227\n",
      "  [val] step 390/733 | loss=0.4215\n",
      "  [val] step 400/733 | loss=0.4274\n",
      "  [val] step 410/733 | loss=0.4303\n",
      "  [val] step 420/733 | loss=0.5484\n",
      "  [val] step 430/733 | loss=0.4693\n",
      "  [val] step 440/733 | loss=2.7560\n",
      "  [val] step 450/733 | loss=0.4459\n",
      "  [val] step 460/733 | loss=0.4163\n",
      "  [val] step 470/733 | loss=0.5746\n",
      "  [val] step 480/733 | loss=0.9302\n",
      "  [val] step 490/733 | loss=1.2969\n",
      "  [val] step 500/733 | loss=0.4284\n",
      "  [val] step 510/733 | loss=0.6352\n",
      "  [val] step 520/733 | loss=0.4492\n",
      "  [val] step 530/733 | loss=0.4246\n",
      "  [val] step 540/733 | loss=0.4977\n",
      "  [val] step 550/733 | loss=0.8190\n",
      "  [val] step 560/733 | loss=4.9815\n",
      "  [val] step 570/733 | loss=2.8381\n",
      "  [val] step 580/733 | loss=4.2388\n",
      "  [val] step 590/733 | loss=0.5341\n",
      "  [val] step 600/733 | loss=0.4273\n",
      "  [val] step 610/733 | loss=1.3290\n",
      "  [val] step 620/733 | loss=0.6190\n",
      "  [val] step 630/733 | loss=0.4491\n",
      "  [val] step 640/733 | loss=0.4222\n",
      "  [val] step 650/733 | loss=0.4284\n",
      "  [val] step 660/733 | loss=2.7483\n",
      "  [val] step 670/733 | loss=0.5525\n",
      "  [val] step 680/733 | loss=0.4812\n",
      "  [val] step 690/733 | loss=0.4215\n",
      "  [val] step 700/733 | loss=0.4176\n",
      "  [val] step 710/733 | loss=0.4237\n",
      "  [val] step 720/733 | loss=3.9355\n",
      "  [val] step 730/733 | loss=2.9943\n",
      "Val:   loss=1.4410, acc=0.664\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   15     0   546     0     0     0     0   117     6     0     0]\n",
      " [   11    20     6     0     0   256     0    90    23    18     0]\n",
      " [   18     0     0     0     0     0     0   130    56     7     1]\n",
      " [    0     0     0     0     0     8     0    28     0     0     0]\n",
      " [    0    12     4     2    72   164     4   201    94    35     2]\n",
      " [    0     0     7     1    16   658     0  1164   202   237   127]\n",
      " [    0     0     7     4    57    16     0   432     0     1     1]\n",
      " [   14     5   281    13    57   204    10 14069  1095   381    22]\n",
      " [    5     1     0     0     0     0     1   166   368     0     3]\n",
      " [    0     0     0     0    14   747     0   529     0   363    99]\n",
      " [    0     2     0     0     0     0     0    24    99     0     2]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.238     0.022     0.040       684\n",
      "           1      0.500     0.047     0.086       424\n",
      "           2      0.000     0.000     0.000       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.333     0.122     0.179       590\n",
      "           5      0.321     0.273     0.295      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.830     0.871     0.850     16151\n",
      "           8      0.189     0.676     0.296       544\n",
      "           9      0.348     0.207     0.260      1752\n",
      "          10      0.008     0.016     0.010       127\n",
      "\n",
      "    accuracy                          0.664     23450\n",
      "   macro avg      0.252     0.203     0.183     23450\n",
      "weighted avg      0.659     0.664     0.649     23450\n",
      "\n",
      "Macro-F1: 0.183 | Balanced Acc: 0.203\n",
      "\n",
      "Epoch 9/10\n",
      "  [train] step 1/741 | loss=0.4474\n",
      "  [train] step 10/741 | loss=0.5621\n",
      "  [train] step 20/741 | loss=0.4484\n",
      "  [train] step 30/741 | loss=0.5094\n",
      "  [train] step 40/741 | loss=0.5409\n",
      "  [train] step 50/741 | loss=0.4164\n",
      "  [train] step 60/741 | loss=0.5810\n",
      "  [train] step 70/741 | loss=0.4348\n",
      "  [train] step 80/741 | loss=0.4589\n",
      "  [train] step 90/741 | loss=0.4486\n",
      "  [train] step 100/741 | loss=0.4435\n",
      "  [train] step 110/741 | loss=0.4782\n",
      "  [train] step 120/741 | loss=0.4366\n",
      "  [train] step 130/741 | loss=0.4241\n",
      "  [train] step 140/741 | loss=0.5103\n",
      "  [train] step 150/741 | loss=0.4630\n",
      "  [train] step 160/741 | loss=0.4391\n",
      "  [train] step 170/741 | loss=0.4437\n",
      "  [train] step 180/741 | loss=0.4799\n",
      "  [train] step 190/741 | loss=0.4595\n",
      "  [train] step 200/741 | loss=0.4393\n",
      "  [train] step 210/741 | loss=0.4760\n",
      "  [train] step 220/741 | loss=0.4752\n",
      "  [train] step 230/741 | loss=0.4868\n",
      "  [train] step 240/741 | loss=0.5204\n",
      "  [train] step 250/741 | loss=0.4440\n",
      "  [train] step 260/741 | loss=0.4527\n",
      "  [train] step 270/741 | loss=0.4392\n",
      "  [train] step 280/741 | loss=0.4538\n",
      "  [train] step 290/741 | loss=0.4357\n",
      "  [train] step 300/741 | loss=0.4633\n",
      "  [train] step 310/741 | loss=0.5030\n",
      "  [train] step 320/741 | loss=0.4808\n",
      "  [train] step 330/741 | loss=0.4839\n",
      "  [train] step 340/741 | loss=0.4392\n",
      "  [train] step 350/741 | loss=0.4557\n",
      "  [train] step 360/741 | loss=0.4381\n",
      "  [train] step 370/741 | loss=0.4546\n",
      "  [train] step 380/741 | loss=0.5160\n",
      "  [train] step 390/741 | loss=0.4975\n",
      "  [train] step 400/741 | loss=0.4828\n",
      "  [train] step 410/741 | loss=0.4764\n",
      "  [train] step 420/741 | loss=0.5006\n",
      "  [train] step 430/741 | loss=0.5254\n",
      "  [train] step 440/741 | loss=0.4442\n",
      "  [train] step 450/741 | loss=0.4744\n",
      "  [train] step 460/741 | loss=0.4451\n",
      "  [train] step 470/741 | loss=0.6790\n",
      "  [train] step 480/741 | loss=0.4315\n",
      "  [train] step 490/741 | loss=0.4415\n",
      "  [train] step 500/741 | loss=0.5178\n",
      "  [train] step 510/741 | loss=0.5412\n",
      "  [train] step 520/741 | loss=0.4514\n",
      "  [train] step 530/741 | loss=0.4518\n",
      "  [train] step 540/741 | loss=0.4266\n",
      "  [train] step 550/741 | loss=0.4284\n",
      "  [train] step 560/741 | loss=0.4342\n",
      "  [train] step 570/741 | loss=0.4520\n",
      "  [train] step 580/741 | loss=0.4849\n",
      "  [train] step 590/741 | loss=0.4742\n",
      "  [train] step 600/741 | loss=0.5105\n",
      "  [train] step 610/741 | loss=0.4914\n",
      "  [train] step 620/741 | loss=0.5483\n",
      "  [train] step 630/741 | loss=0.4367\n",
      "  [train] step 640/741 | loss=0.4502\n",
      "  [train] step 650/741 | loss=0.5643\n",
      "  [train] step 660/741 | loss=0.4287\n",
      "  [train] step 670/741 | loss=0.4783\n",
      "  [train] step 680/741 | loss=0.4603\n",
      "  [train] step 690/741 | loss=0.4509\n",
      "  [train] step 700/741 | loss=0.4954\n",
      "  [train] step 710/741 | loss=0.4986\n",
      "  [train] step 720/741 | loss=0.4303\n",
      "  [train] step 730/741 | loss=0.4411\n",
      "  [train] step 740/741 | loss=0.4992\n",
      "Train: loss=0.4743, acc=0.983\n",
      "  [val] step 1/733 | loss=2.4913\n",
      "  [val] step 10/733 | loss=0.4315\n",
      "  [val] step 20/733 | loss=0.4169\n",
      "  [val] step 30/733 | loss=3.5194\n",
      "  [val] step 40/733 | loss=3.7858\n",
      "  [val] step 50/733 | loss=4.6112\n",
      "  [val] step 60/733 | loss=0.4159\n",
      "  [val] step 70/733 | loss=0.4256\n",
      "  [val] step 80/733 | loss=1.1619\n",
      "  [val] step 90/733 | loss=0.4198\n",
      "  [val] step 100/733 | loss=0.4165\n",
      "  [val] step 110/733 | loss=0.4223\n",
      "  [val] step 120/733 | loss=25.8138\n",
      "  [val] step 130/733 | loss=4.2863\n",
      "  [val] step 140/733 | loss=5.3434\n",
      "  [val] step 150/733 | loss=2.3435\n",
      "  [val] step 160/733 | loss=0.4397\n",
      "  [val] step 170/733 | loss=2.5000\n",
      "  [val] step 180/733 | loss=3.6962\n",
      "  [val] step 190/733 | loss=0.5400\n",
      "  [val] step 200/733 | loss=0.5851\n",
      "  [val] step 210/733 | loss=0.5903\n",
      "  [val] step 220/733 | loss=1.3638\n",
      "  [val] step 230/733 | loss=0.5340\n",
      "  [val] step 240/733 | loss=0.4538\n",
      "  [val] step 250/733 | loss=0.4438\n",
      "  [val] step 260/733 | loss=1.3715\n",
      "  [val] step 270/733 | loss=0.4229\n",
      "  [val] step 280/733 | loss=0.4983\n",
      "  [val] step 290/733 | loss=0.4162\n",
      "  [val] step 300/733 | loss=2.4171\n",
      "  [val] step 310/733 | loss=2.6464\n",
      "  [val] step 320/733 | loss=1.3581\n",
      "  [val] step 330/733 | loss=2.6494\n",
      "  [val] step 340/733 | loss=0.4289\n",
      "  [val] step 350/733 | loss=4.7583\n",
      "  [val] step 360/733 | loss=0.4216\n",
      "  [val] step 370/733 | loss=0.4226\n",
      "  [val] step 380/733 | loss=0.4240\n",
      "  [val] step 390/733 | loss=0.4263\n",
      "  [val] step 400/733 | loss=0.4290\n",
      "  [val] step 410/733 | loss=0.4359\n",
      "  [val] step 420/733 | loss=0.4232\n",
      "  [val] step 430/733 | loss=0.4257\n",
      "  [val] step 440/733 | loss=0.9356\n",
      "  [val] step 450/733 | loss=0.5058\n",
      "  [val] step 460/733 | loss=0.4139\n",
      "  [val] step 470/733 | loss=1.1623\n",
      "  [val] step 480/733 | loss=4.7004\n",
      "  [val] step 490/733 | loss=1.8032\n",
      "  [val] step 500/733 | loss=0.4569\n",
      "  [val] step 510/733 | loss=0.6115\n",
      "  [val] step 520/733 | loss=0.4588\n",
      "  [val] step 530/733 | loss=0.4292\n",
      "  [val] step 540/733 | loss=0.6305\n",
      "  [val] step 550/733 | loss=0.5307\n",
      "  [val] step 560/733 | loss=4.7071\n",
      "  [val] step 570/733 | loss=4.2734\n",
      "  [val] step 580/733 | loss=3.8423\n",
      "  [val] step 590/733 | loss=0.4392\n",
      "  [val] step 600/733 | loss=0.4212\n",
      "  [val] step 610/733 | loss=0.4365\n",
      "  [val] step 620/733 | loss=0.4199\n",
      "  [val] step 630/733 | loss=0.4205\n",
      "  [val] step 640/733 | loss=0.4217\n",
      "  [val] step 650/733 | loss=0.4169\n",
      "  [val] step 660/733 | loss=1.8257\n",
      "  [val] step 670/733 | loss=0.5956\n",
      "  [val] step 680/733 | loss=0.4711\n",
      "  [val] step 690/733 | loss=0.5530\n",
      "  [val] step 700/733 | loss=0.4177\n",
      "  [val] step 710/733 | loss=0.4228\n",
      "  [val] step 720/733 | loss=4.3544\n",
      "  [val] step 730/733 | loss=1.0547\n",
      "Val:   loss=1.8252, acc=0.658\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   12     0   285     0     0     0     0   372    15     0     0]\n",
      " [    1     5     9     7     0   360     0     7    35     0     0]\n",
      " [   23     1    33     0     0     0     0    72    64     0    19]\n",
      " [    0     4     0     0     0     9     0    21     0     0     2]\n",
      " [    0     3     2     0    52    15     0   346   164     4     4]\n",
      " [    2     0    12     0     0   624     0  1328   288   156     2]\n",
      " [    0     0     2     0    16     5     0   482    13     0     0]\n",
      " [    4     8   123     0     5   133     1 14129  1697    46     5]\n",
      " [    1     3     3     0     0     0     1    77   457     0     2]\n",
      " [    0     0     4     0     7   798     0   860     1    77     5]\n",
      " [    8     4    22     0     0     0     0     0    53     0    40]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.235     0.018     0.033       684\n",
      "           1      0.179     0.012     0.022       424\n",
      "           2      0.067     0.156     0.093       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.650     0.088     0.155       590\n",
      "           5      0.321     0.259     0.287      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.799     0.875     0.835     16151\n",
      "           8      0.164     0.840     0.274       544\n",
      "           9      0.272     0.044     0.076      1752\n",
      "          10      0.506     0.315     0.388       127\n",
      "\n",
      "    accuracy                          0.658     23450\n",
      "   macro avg      0.290     0.237     0.197     23450\n",
      "weighted avg      0.637     0.658     0.625     23450\n",
      "\n",
      "Macro-F1: 0.197 | Balanced Acc: 0.237\n",
      "\n",
      "Epoch 10/10\n",
      "  [train] step 1/741 | loss=0.4361\n",
      "  [train] step 10/741 | loss=0.4965\n",
      "  [train] step 20/741 | loss=0.4691\n",
      "  [train] step 30/741 | loss=0.5224\n",
      "  [train] step 40/741 | loss=0.4926\n",
      "  [train] step 50/741 | loss=0.4697\n",
      "  [train] step 60/741 | loss=0.4438\n",
      "  [train] step 70/741 | loss=0.5240\n",
      "  [train] step 80/741 | loss=0.5157\n",
      "  [train] step 90/741 | loss=0.4320\n",
      "  [train] step 100/741 | loss=0.4331\n",
      "  [train] step 110/741 | loss=0.3894\n",
      "  [train] step 120/741 | loss=0.4996\n",
      "  [train] step 130/741 | loss=0.4918\n",
      "  [train] step 140/741 | loss=0.4606\n",
      "  [train] step 150/741 | loss=0.4515\n",
      "  [train] step 160/741 | loss=0.4747\n",
      "  [train] step 170/741 | loss=0.4730\n",
      "  [train] step 180/741 | loss=0.4640\n",
      "  [train] step 190/741 | loss=0.4899\n",
      "  [train] step 200/741 | loss=0.4350\n",
      "  [train] step 210/741 | loss=0.4326\n",
      "  [train] step 220/741 | loss=0.4315\n",
      "  [train] step 230/741 | loss=0.5360\n",
      "  [train] step 240/741 | loss=0.5754\n",
      "  [train] step 250/741 | loss=0.4423\n",
      "  [train] step 260/741 | loss=0.4514\n",
      "  [train] step 270/741 | loss=0.4639\n",
      "  [train] step 280/741 | loss=0.4476\n",
      "  [train] step 290/741 | loss=0.4400\n",
      "  [train] step 300/741 | loss=0.4302\n",
      "  [train] step 310/741 | loss=0.6100\n",
      "  [train] step 320/741 | loss=0.4596\n",
      "  [train] step 330/741 | loss=0.4375\n",
      "  [train] step 340/741 | loss=0.4389\n",
      "  [train] step 350/741 | loss=0.4476\n",
      "  [train] step 360/741 | loss=0.4552\n",
      "  [train] step 370/741 | loss=0.5363\n",
      "  [train] step 380/741 | loss=0.4668\n",
      "  [train] step 390/741 | loss=0.6571\n",
      "  [train] step 400/741 | loss=0.4376\n",
      "  [train] step 410/741 | loss=0.5633\n",
      "  [train] step 420/741 | loss=0.6090\n",
      "  [train] step 430/741 | loss=0.4322\n",
      "  [train] step 440/741 | loss=0.5404\n",
      "  [train] step 450/741 | loss=0.4685\n",
      "  [train] step 460/741 | loss=0.4715\n",
      "  [train] step 470/741 | loss=0.4283\n",
      "  [train] step 480/741 | loss=0.4732\n",
      "  [train] step 490/741 | loss=0.4296\n",
      "  [train] step 500/741 | loss=0.4930\n",
      "  [train] step 510/741 | loss=0.4976\n",
      "  [train] step 520/741 | loss=0.4812\n",
      "  [train] step 530/741 | loss=0.4533\n",
      "  [train] step 540/741 | loss=0.4476\n",
      "  [train] step 550/741 | loss=0.4285\n",
      "  [train] step 560/741 | loss=0.4489\n",
      "  [train] step 570/741 | loss=0.4610\n",
      "  [train] step 580/741 | loss=0.5452\n",
      "  [train] step 590/741 | loss=0.4374\n",
      "  [train] step 600/741 | loss=0.5128\n",
      "  [train] step 610/741 | loss=0.4626\n",
      "  [train] step 620/741 | loss=0.4347\n",
      "  [train] step 630/741 | loss=0.4551\n",
      "  [train] step 640/741 | loss=0.4249\n",
      "  [train] step 650/741 | loss=0.4494\n",
      "  [train] step 660/741 | loss=0.4977\n",
      "  [train] step 670/741 | loss=0.5166\n",
      "  [train] step 680/741 | loss=0.4522\n",
      "  [train] step 690/741 | loss=0.4790\n",
      "  [train] step 700/741 | loss=0.4610\n",
      "  [train] step 710/741 | loss=0.5104\n",
      "  [train] step 720/741 | loss=0.4351\n",
      "  [train] step 730/741 | loss=0.4327\n",
      "  [train] step 740/741 | loss=0.6173\n",
      "Train: loss=0.4699, acc=0.984\n",
      "  [val] step 1/733 | loss=3.4307\n",
      "  [val] step 10/733 | loss=0.4222\n",
      "  [val] step 20/733 | loss=0.4226\n",
      "  [val] step 30/733 | loss=2.0417\n",
      "  [val] step 40/733 | loss=2.9827\n",
      "  [val] step 50/733 | loss=4.4535\n",
      "  [val] step 60/733 | loss=0.4208\n",
      "  [val] step 70/733 | loss=0.4214\n",
      "  [val] step 80/733 | loss=1.1802\n",
      "  [val] step 90/733 | loss=0.4231\n",
      "  [val] step 100/733 | loss=0.4252\n",
      "  [val] step 110/733 | loss=0.4267\n",
      "  [val] step 120/733 | loss=25.9668\n",
      "  [val] step 130/733 | loss=1.9928\n",
      "  [val] step 140/733 | loss=5.1868\n",
      "  [val] step 150/733 | loss=0.4297\n",
      "  [val] step 160/733 | loss=0.4661\n",
      "  [val] step 170/733 | loss=2.5497\n",
      "  [val] step 180/733 | loss=4.1172\n",
      "  [val] step 190/733 | loss=0.4605\n",
      "  [val] step 200/733 | loss=0.8439\n",
      "  [val] step 210/733 | loss=1.8328\n",
      "  [val] step 220/733 | loss=0.7387\n",
      "  [val] step 230/733 | loss=1.0678\n",
      "  [val] step 240/733 | loss=0.4298\n",
      "  [val] step 250/733 | loss=0.4203\n",
      "  [val] step 260/733 | loss=0.8734\n",
      "  [val] step 270/733 | loss=0.4193\n",
      "  [val] step 280/733 | loss=0.4203\n",
      "  [val] step 290/733 | loss=0.4235\n",
      "  [val] step 300/733 | loss=1.7546\n",
      "  [val] step 310/733 | loss=1.5265\n",
      "  [val] step 320/733 | loss=0.8585\n",
      "  [val] step 330/733 | loss=1.7014\n",
      "  [val] step 340/733 | loss=0.4219\n",
      "  [val] step 350/733 | loss=4.8278\n",
      "  [val] step 360/733 | loss=0.4289\n",
      "  [val] step 370/733 | loss=0.4380\n",
      "  [val] step 380/733 | loss=0.4535\n",
      "  [val] step 390/733 | loss=0.4524\n",
      "  [val] step 400/733 | loss=0.4970\n",
      "  [val] step 410/733 | loss=0.4285\n",
      "  [val] step 420/733 | loss=0.4411\n",
      "  [val] step 430/733 | loss=0.4276\n",
      "  [val] step 440/733 | loss=0.7450\n",
      "  [val] step 450/733 | loss=0.4251\n",
      "  [val] step 460/733 | loss=0.4175\n",
      "  [val] step 470/733 | loss=0.5793\n",
      "  [val] step 480/733 | loss=3.9682\n",
      "  [val] step 490/733 | loss=1.2314\n",
      "  [val] step 500/733 | loss=0.4275\n",
      "  [val] step 510/733 | loss=0.4618\n",
      "  [val] step 520/733 | loss=0.4254\n",
      "  [val] step 530/733 | loss=0.4197\n",
      "  [val] step 540/733 | loss=0.4391\n",
      "  [val] step 550/733 | loss=0.4639\n",
      "  [val] step 560/733 | loss=4.6768\n",
      "  [val] step 570/733 | loss=4.3670\n",
      "  [val] step 580/733 | loss=3.1689\n",
      "  [val] step 590/733 | loss=2.7096\n",
      "  [val] step 600/733 | loss=0.6151\n",
      "  [val] step 610/733 | loss=0.4851\n",
      "  [val] step 620/733 | loss=0.4893\n",
      "  [val] step 630/733 | loss=0.4508\n",
      "  [val] step 640/733 | loss=0.4410\n",
      "  [val] step 650/733 | loss=0.6532\n",
      "  [val] step 660/733 | loss=1.6270\n",
      "  [val] step 670/733 | loss=0.4411\n",
      "  [val] step 680/733 | loss=0.4254\n",
      "  [val] step 690/733 | loss=0.4211\n",
      "  [val] step 700/733 | loss=0.4362\n",
      "  [val] step 710/733 | loss=0.4364\n",
      "  [val] step 720/733 | loss=4.4210\n",
      "  [val] step 730/733 | loss=1.9631\n",
      "Val:   loss=1.7211, acc=0.672\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[   49     0   327     0     0     1     0   307     0     0     0]\n",
      " [   10     1     2     1     0   353     0    30    27     0     0]\n",
      " [   16     0    14     0     0     0     0    84    95     0     3]\n",
      " [    0     0     0     0     0     3     0    32     0     0     1]\n",
      " [    0     0     0     3    33   214     0   285    55     0     0]\n",
      " [    0     3     4     1     2  1036     0  1269    45    51     1]\n",
      " [    0     0     0     0     5     3     0   510     0     0     0]\n",
      " [    8     0     1     0     1   605     0 14195  1294    45     2]\n",
      " [    0     0     2     0     0     0     0   173   368     0     1]\n",
      " [    0     0     0     0     1   976     0   737     0    38     0]\n",
      " [   55     2    15     0     0     4     0     5    27     0    19]]\n",
      "\n",
      "Per-class metrics (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.355     0.072     0.119       684\n",
      "           1      0.167     0.002     0.005       424\n",
      "           2      0.038     0.066     0.049       212\n",
      "           3      0.000     0.000     0.000        36\n",
      "           4      0.786     0.056     0.104       590\n",
      "           5      0.324     0.430     0.370      2412\n",
      "           6      0.000     0.000     0.000       518\n",
      "           7      0.805     0.879     0.840     16151\n",
      "           8      0.193     0.676     0.300       544\n",
      "           9      0.284     0.022     0.040      1752\n",
      "          10      0.704     0.150     0.247       127\n",
      "\n",
      "    accuracy                          0.672     23450\n",
      "   macro avg      0.332     0.214     0.189     23450\n",
      "weighted avg      0.651     0.672     0.635     23450\n",
      "\n",
      "Macro-F1: 0.189 | Balanced Acc: 0.214\n",
      "\n",
      "Training finished!\n",
      "Best validation accuracy: 0.709\n",
      "Elapsed time: 3034.7 sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Tiny ResNet50 sanity trainer (weighted-loss + stratification diagnostics)\n",
    "# \n",
    "# Adds **class-weighted CrossEntropyLoss** to handle class imbalance and a\n",
    "# **stratification report** to quantify how well Train/Val match the global\n",
    "# label distribution (zero-support warnings, per-class deviations, JSD).\n",
    "# Everything else remains identical to the baseline trainer.\n",
    "#\n",
    "# - Uses class-balanced (effective number) or inverse-frequency weights on TRAIN.\n",
    "# - Keeps dataset and DataLoader unchanged (no oversampling).\n",
    "# - Preserves label smoothing.\n",
    "# - Prints confusion matrix + per-class metrics for analysis.\n",
    "# - Saves a CSV summary of stratification to RESULTS_DIR for easy comparisons.\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# important order; !!!\n",
    "# --- Correct order ---\n",
    "import os\n",
    "GPU_INDEX = 1 # choose your GPU\n",
    "\n",
    "# Pin the GPU before importing torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Standard library imports\n",
    "# -------------------------\n",
    "import time, math, warnings\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------\n",
    "# Third-party imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# -------------------------\n",
    "# PyTorch / TorchVision\n",
    "# -------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch import amp\n",
    "\n",
    "# -------------------------\n",
    "# Scikit-learn utilities\n",
    "# -------------------------\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, f1_score\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# ========================\n",
    "# CONFIGURATION CONSTANTS\n",
    "# ========================\n",
    "CSV_PATH      = \"/home/stud/fwag/bhome/ele670_project/data/processed/metadata_filtered.csv\"\n",
    "IMG_ROOT      = \"/home/stud/fwag/bhome/ele670_project/data/raw/labelled_images\"\n",
    "RESULTS_DIR   = \"/home/stud/fwag/bhome/ele670_project/results\"\n",
    "SAVE_PATH     = os.path.join(RESULTS_DIR, \"tiny_resnet50_best_weighted.pt\")\n",
    "LABELS_NPY    = \"/home/stud/fwag/bhome/ele670_project/data/processed/label_classes_filtered.npy\"\n",
    "\n",
    "\n",
    "# SPLIT_MODE: \"gss\" (GroupShuffleSplit 80/20) or \"grouped_class_balanced\" (greedy, class-coverage aware)\n",
    "SPLIT_MODE = \"grouped_class_balanced\"  # change to \"grouped_class_balanced\" to reduce zero-support classes in VAL\n",
    "\n",
    "# Optional: tag to differentiate experiment variants (appears in saved reports)\n",
    "EXPERIMENT_TAG = f\"weighted_cb_beta0.99_{SPLIT_MODE}\"\n",
    "\n",
    "IMG_SIZE      = 224\n",
    "BATCH_SIZE    = 32\n",
    "NUM_WORKERS   = 6\n",
    "EPOCHS        = 10  # for wiring/debug; consider 5–10 for clearer comparisons\n",
    "LR            = 1e-3\n",
    "WEIGHT_DECAY  = 1e-4\n",
    "LABEL_SMOOTH  = 0.05\n",
    "FREEZE_BACKBONE = False\n",
    "USE_PRETRAINED = True\n",
    "SEED          = 42\n",
    "LOG_EVERY     = 10\n",
    "\n",
    "# ----------------------------\n",
    "# (1) Reproducibility + GPU pinning\n",
    "# ----------------------------\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available() and GPU_INDEX is not None:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_INDEX)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ========================\n",
    "# DATASET IMPLEMENTATION\n",
    "# ========================\n",
    "class KvasirDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_root: str, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(self.img_root, row[\"image_path\"])\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except (FileNotFoundError, UnidentifiedImageError):\n",
    "            print(f\"[WARN] Missing/corrupt: {path}\")\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        x = self.transform(img)\n",
    "        y = int(row[\"encoded_label\"])\n",
    "        return x, y\n",
    "\n",
    "# ==================\n",
    "# LOAD METADATA\n",
    "# ==================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Loaded metadata:\")\n",
    "print(df.head())\n",
    "\n",
    "num_classes = df[\"encoded_label\"].nunique()\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# ===========================\n",
    "# SPLITTING (Group-safe, with optional class-aware balancing)\n",
    "# ===========================\n",
    "# SPLIT_MODE: \"gss\" (GroupShuffleSplit 80/20) or \"grouped_class_balanced\" (greedy, class-coverage aware)\n",
    "#SPLIT_MODE = \"grouped_class_balanced\"  # change to \"grouped_class_balanced\" to reduce zero-support classes in VAL\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def build_video_targets(df, label_col=\"encoded_label\"):\n",
    "    vids = sorted(df[\"video_id\"].unique())\n",
    "    video_targets = {}\n",
    "    for v, g in df.groupby(\"video_id\"):\n",
    "        labs = g[label_col].unique().astype(int)\n",
    "        video_targets[v] = set(labs.tolist())\n",
    "    return vids, video_targets\n",
    "\n",
    "def grouped_class_balanced_split(df, n_splits=2, val_frac=0.2, seed=SEED, label_col=\"encoded_label\"):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    vids, video_targets = build_video_targets(df, label_col)\n",
    "    K = df[label_col].nunique()\n",
    "\n",
    "    # start with empty folds (we will use fold 0 as VAL)\n",
    "    folds = [set() for _ in range(n_splits)]\n",
    "    fold_counts = [np.zeros(K, dtype=int) for _ in range(n_splits)]\n",
    "\n",
    "    # sort videos by difficulty (more classes first)\n",
    "    vids_sorted = sorted(vids, key=lambda v: len(video_targets[v]), reverse=True)\n",
    "\n",
    "    for v in vids_sorted:\n",
    "        cls_set = video_targets[v]\n",
    "        # score each fold by resulting std of per-class counts if we add v\n",
    "        scores = []\n",
    "        for f in range(n_splits):\n",
    "            sim = fold_counts[f].copy()\n",
    "            for c in cls_set:\n",
    "                sim[c] += 1\n",
    "            scores.append((sim.std(), f))\n",
    "        _, best_f = min(scores, key=lambda t: (t[0], rng.rand()))\n",
    "        folds[best_f].add(v)\n",
    "        for c in cls_set:\n",
    "            fold_counts[best_f][c] += 1\n",
    "\n",
    "    # choose fold with ~val_frac of videos as VAL; else merge smallest folds until size ~= val_frac\n",
    "    fold_sizes = [len(f) for f in folds]\n",
    "    val_f = int(np.argmin([abs(s/len(vids) - val_frac) for s in fold_sizes]))\n",
    "    val_videos = folds[val_f]\n",
    "\n",
    "    df_train = df[~df[\"video_id\"].isin(val_videos)].copy()\n",
    "    df_val   = df[ df[\"video_id\"].isin(val_videos)].copy()\n",
    "    return df_train, df_val\n",
    "\n",
    "if SPLIT_MODE == \"gss\":\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "    train_idx, val_idx = next(gss.split(df, groups=df[\"video_id\"]))\n",
    "    df_train, df_val = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()\n",
    "else:\n",
    "    df_train, df_val = grouped_class_balanced_split(df, n_splits=2, val_frac=0.2, seed=SEED, label_col=\"encoded_label\")\n",
    "\n",
    "print(f\"Train samples: {len(df_train)} | Val samples: {len(df_val)}\")\n",
    "\n",
    "# ===============================\n",
    "# STRATIFICATION DIAGNOSTICS CELL\n",
    "# ===============================\n",
    "\n",
    "def _js_divergence(p, q, eps=1e-12):\n",
    "    p = np.asarray(p, dtype=np.float64); q = np.asarray(q, dtype=np.float64)\n",
    "    p = np.clip(p, eps, 1.0); q = np.clip(q, eps, 1.0)\n",
    "    p /= p.sum(); q /= q.sum(); m = 0.5 * (p + q)\n",
    "    kl_pm = np.sum(p * np.log(p / m)); kl_qm = np.sum(q * np.log(q / m))\n",
    "    return 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "\n",
    "def stratification_report(df_all, df_tr, df_va, label_col=\"encoded_label\", labels_npy_path=None, save_csv=None, tag=None):\n",
    "    # Global distribution\n",
    "    g_counts = df_all[label_col].value_counts().sort_index()\n",
    "    classes = g_counts.index.tolist()\n",
    "    g_probs  = (g_counts / g_counts.sum()).values\n",
    "\n",
    "    # Train distribution\n",
    "    t_counts = df_tr[label_col].value_counts().reindex(classes, fill_value=0)\n",
    "    t_probs  = (t_counts / max(1, t_counts.sum())).values\n",
    "\n",
    "    # Val distribution\n",
    "    v_counts = df_va[label_col].value_counts().reindex(classes, fill_value=0)\n",
    "    v_probs  = (v_counts / max(1, v_counts.sum())).values\n",
    "\n",
    "    # Deviations\n",
    "    t_abs_pp = np.abs(t_probs - g_probs) * 100.0\n",
    "    v_abs_pp = np.abs(v_probs - g_probs) * 100.0\n",
    "    denom = np.where(g_probs > 0, g_probs, np.nan)\n",
    "    t_rel = np.abs(t_probs - g_probs) / denom * 100.0\n",
    "    v_rel = np.abs(v_probs - g_probs) / denom * 100.0\n",
    "\n",
    "    # Optional class names\n",
    "    id2name = {i: f\"class_{i}\" for i in classes}\n",
    "    try:\n",
    "        if labels_npy_path is not None:\n",
    "            names = np.load(labels_npy_path, allow_pickle=True)\n",
    "            id2name = {i: str(names[i]) for i in classes}\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    tbl = pd.DataFrame({\n",
    "        \"label_id\": classes,\n",
    "        \"class_name\": [id2name[i] for i in classes],\n",
    "        \"global_count\": g_counts.values,\n",
    "        \"global_pct\": (g_probs * 100).round(3),\n",
    "        \"train_count\": t_counts.values,\n",
    "        \"train_pct\": (t_probs * 100).round(3),\n",
    "        \"train_abs_dev_pp\": t_abs_pp.round(3),\n",
    "        \"train_rel_dev_%\": np.where(np.isfinite(t_rel), t_rel, np.nan).round(1),\n",
    "        \"val_count\": v_counts.values,\n",
    "        \"val_pct\": (v_probs * 100).round(3),\n",
    "        \"val_abs_dev_pp\": v_abs_pp.round(3),\n",
    "        \"val_rel_dev_%\": np.where(np.isfinite(v_rel), v_rel, np.nan).round(1),\n",
    "    })\n",
    "\n",
    "    # Summary metrics\n",
    "    t_jsd = _js_divergence(g_probs, t_probs)\n",
    "    v_jsd = _js_divergence(g_probs, v_probs)\n",
    "    zero_train = int((t_counts.values == 0).sum())\n",
    "    zero_val   = int((v_counts.values == 0).sum())\n",
    "\n",
    "    print(\"\\n[STRAT] per-class distribution and deviations:\")\n",
    "    print(tbl.to_string(index=False, max_rows=200))\n",
    "\n",
    "    print(\"\\n[STRAT][SUMMARY]\")\n",
    "    print(f\"  Zero-support classes: TRAIN={zero_train} | VAL={zero_val}\")\n",
    "    print(f\"  Train: mean abs dev = {t_abs_pp.mean():.2f} pp | max abs dev = {t_abs_pp.max():.2f} pp | JSD = {t_jsd:.4f}\")\n",
    "    print(f\"  Val  : mean abs dev = {v_abs_pp.mean():.2f} pp | max abs dev = {v_abs_pp.max():.2f} pp | JSD = {v_jsd:.4f}\")\n",
    "    if zero_val > 0:\n",
    "        print(\"  ⚠️  Val split has classes with support=0 — metrics for those classes are undefined. Consider a class-aware grouped split.\")\n",
    "\n",
    "    if save_csv:\n",
    "        out = tbl.copy()\n",
    "        out.insert(0, \"experiment_tag\", tag if tag else \"\")\n",
    "        out.to_csv(save_csv, index=False)\n",
    "        print(f\"[STRAT] saved → {save_csv}\")\n",
    "\n",
    "    return {\n",
    "        \"table\": tbl,\n",
    "        \"train_jsd\": float(t_jsd),\n",
    "        \"val_jsd\": float(v_jsd),\n",
    "        \"train_mean_abs_pp\": float(t_abs_pp.mean()),\n",
    "        \"val_mean_abs_pp\": float(v_abs_pp.mean()),\n",
    "        \"zero_train\": zero_train,\n",
    "        \"zero_val\": zero_val,\n",
    "    }\n",
    "\n",
    "# Run diagnostics and persist CSV for experiment tracking\n",
    "_ = stratification_report(\n",
    "    df_all=df, df_tr=df_train, df_va=df_val,\n",
    "    label_col=\"encoded_label\",\n",
    "    labels_npy_path=LABELS_NPY,\n",
    "    save_csv=os.path.join(RESULTS_DIR, f\"stratification_report_{EXPERIMENT_TAG}.csv\"),\n",
    "    tag=EXPERIMENT_TAG,\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# TRANSFORMS & LOADERS\n",
    "# =====================\n",
    "mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_ds = KvasirDataset(df_train, IMG_ROOT, train_tf)\n",
    "val_ds   = KvasirDataset(df_val,   IMG_ROOT, val_tf)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4\n",
    ")\n",
    "\n",
    "# ==================\n",
    "# MODEL\n",
    "# ==================\n",
    "if USE_PRETRAINED:\n",
    "    try:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "    except AttributeError:\n",
    "        weights = \"IMAGENET1K_V2\"\n",
    "    model = models.resnet50(weights=weights)\n",
    "else:\n",
    "    model = models.resnet50(weights=None)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "if FREEZE_BACKBONE:\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ======================================\n",
    "# COMPUTE CLASS WEIGHTS (TRAIN SPLIT ONLY) — CLEAN & CONSISTENT\n",
    "# ======================================\n",
    "counts = df_train[\"encoded_label\"].value_counts().sort_index()\n",
    "counts_idx_sorted = counts\n",
    "N, K = counts_idx_sorted.sum(), len(counts_idx_sorted)\n",
    "\n",
    "# ----- Class-Balanced (effective number) weights -----\n",
    "beta = 0.99  # try 0.995 or 0.999 if imbalance is extreme\n",
    "eff = 1.0 - np.power(beta, counts_idx_sorted.values)\n",
    "cb_w = ((1.0 - beta) / np.maximum(eff, 1e-12)).astype(np.float32)\n",
    "cb_w = cb_w / cb_w.min()\n",
    "\n",
    "# (Optional) inverse-frequency for reference/ablation\n",
    "inv_w = (N / (K * counts_idx_sorted.values)).astype(np.float32)\n",
    "inv_w = inv_w / inv_w.min()\n",
    "\n",
    "# Pick which to use for training:\n",
    "WEIGHT_MODE = \"class_balanced\"  # or \"invfreq\"\n",
    "w = cb_w if WEIGHT_MODE == \"class_balanced\" else inv_w\n",
    "class_weights = torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "print(f\"[WEIGHTS] mode={WEIGHT_MODE}  ->  min={w.min():.3f}, max={w.max():.3f}\")\n",
    "\n",
    "# ----- Build readable table (aligned with what you actually use) -----\n",
    "try:\n",
    "    classes = np.load(LABELS_NPY, allow_pickle=True)\n",
    "    id2name = {i: str(n) for i, n in enumerate(classes)}\n",
    "except Exception:\n",
    "    id2name = {i: f\"class_{i}\" for i in range(len(w))}\n",
    "\n",
    "weights_table = pd.DataFrame({\n",
    "    \"label_id\": counts_idx_sorted.index,\n",
    "    \"class_name\": [id2name[i] for i in counts_idx_sorted.index],\n",
    "    \"count_train\": counts_idx_sorted.values,\n",
    "    \"weight\": w,\n",
    "    \"invfreq_ref\": inv_w,\n",
    "    \"cb_ref\": cb_w,\n",
    "}).sort_values(\"weight\", ascending=False)\n",
    "\n",
    "print(\"\\n[CHECK] Train counts and weights used by loss:\")\n",
    "print(weights_table[[\"label_id\",\"class_name\",\"count_train\",\"weight\"]].to_string(index=False))\n",
    "\n",
    "# (Optional) persist for reproducibility\n",
    "# weights_csv = os.path.join(RESULTS_DIR, f\"train_class_weights_{WEIGHT_MODE}_{EXPERIMENT_TAG}.csv\")\n",
    "# weights_table.to_csv(weights_csv, index=False)\n",
    "# print(f\"[SAVED] {weights_csv}\")\n",
    "\n",
    "# ======================================\n",
    "# LOSS FUNCTION + OPTIMIZER\n",
    "# ======================================\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = amp.GradScaler('cuda') if DEVICE == 'cuda' else None\n",
    "\n",
    "# ======================\n",
    "# TRAIN / EVAL FUNCTIONS\n",
    "# ======================\n",
    "@torch.no_grad()\n",
    "def _accuracy(logits, labels):\n",
    "    return (logits.argmax(dim=1) == labels).float().mean().item()\n",
    "\n",
    "def run_epoch(loader, train=True, desc=\"train\"):\n",
    "    model.train(train)\n",
    "    total_loss, total_correct, total_seen = 0.0, 0, 0\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader, 1):\n",
    "        images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "        ctx = amp.autocast('cuda', enabled=(DEVICE=='cuda'))\n",
    "        with ctx:\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_seen += labels.size(0)\n",
    "            total_loss += float(loss.item()) * labels.size(0)\n",
    "        if step % LOG_EVERY == 0 or step == 1:\n",
    "            print(f\"  [{desc}] step {step}/{len(loader)} | loss={loss.item():.4f}\")\n",
    "    return total_loss / total_seen, total_correct / total_seen\n",
    "\n",
    "\n",
    "def collect_predictions(loader):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
    "                logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "    return np.concatenate(all_labels), np.concatenate(all_preds)\n",
    "\n",
    "# ============================\n",
    "# MAIN TRAIN LOOP\n",
    "# ============================\n",
    "print(\"\\n==== START TRAINING (Weighted Loss) ====\\n\")\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True, desc=\"train\")\n",
    "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.3f}\")\n",
    "    vl_loss, vl_acc = run_epoch(val_loader, train=False, desc=\"val\")\n",
    "    print(f\"Val:   loss={vl_loss:.4f}, acc={vl_acc:.3f}\")\n",
    "\n",
    "    if vl_acc > best_val_acc:\n",
    "        best_val_acc = vl_acc\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  ✅ New best model saved → {SAVE_PATH} (acc={best_val_acc:.3f})\")\n",
    "\n",
    "    y_true, y_pred = collect_predictions(val_loader)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "    with np.printoptions(threshold=200, linewidth=200):\n",
    "        print(cm)\n",
    "\n",
    "    print(\"\\nPer-class metrics (validation):\")\n",
    "    print(classification_report(\n",
    "        y_true, y_pred, labels=list(range(num_classes)), digits=3\n",
    "    ))\n",
    "\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    bal_acc  = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f\"Macro-F1: {macro_f1:.3f} | Balanced Acc: {bal_acc:.3f}\")\n",
    "\n",
    "print(\"\\nTraining finished!\")\n",
    "print(\"Best validation accuracy:\", round(best_val_acc, 3))\n",
    "print(\"Elapsed time: %.1f sec\" % (time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ele670)",
   "language": "python",
   "name": "ele670"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
